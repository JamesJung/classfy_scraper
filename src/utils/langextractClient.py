"""
LangExtract + Ollamaë¥¼ ì´ìš©í•œ í•„ë“œë³„ ì •ë³´ ì¶”ì¶œ ìœ í‹¸ë¦¬í‹°

ê° í•„ë“œë³„ë¡œ ì „ë¬¸í™”ëœ ì¶”ì¶œì„ ìˆ˜í–‰í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤:
- ì§€ì›ëŒ€ìƒ, ì‹œí–‰ê¸°ê´€, ì œëª©, ì§€ì›ë‚´ìš©, ì§€ì›ê¸ˆì•¡, ë“±ë¡ì¼, ì ‘ìˆ˜ê¸°ê°„, ëª¨ì§‘ì¼ì •
"""

import os
import logging
import langextract as lx
import requests
import json
from typing import Dict, Any, Optional, List
from pathlib import Path

try:
    from src.config.logConfig import setup_logging
except ImportError:
    # ì ˆëŒ€ import ì‹œë„
    import sys
    from pathlib import Path

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))

    from src.config.logConfig import setup_logging

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œê·¸ ë ˆë²¨ ì½ê¸°
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

log_level = getattr(logging, os.getenv('LOG_LEVEL', 'INFO').upper(), logging.INFO)
logger = setup_logging(__name__, log_level)


class LangExtractFieldAnalyzer:
    """LangExtractë¥¼ ì´ìš©í•œ í•„ë“œë³„ ì •ë³´ ì¶”ì¶œê¸°"""
    
    def __init__(self):
        # Ollama ì„¤ì • - í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ gemma2:latest ì‚¬ìš© (LangExtract í˜¸í™˜ì„±)
        self.model_id = os.getenv("OLLAMA_MODEL", "gemma2:latest")
        self.model_url = os.getenv("OLLAMA_API_URL", "http://localhost:11434").rstrip("/").rstrip("/api")
        self.timeout = int(os.getenv("OLLAMA_TIMEOUT", "300"))
        
        # gpt-oss ëª¨ë¸ì˜ thinking í•„ë“œ ë¬¸ì œë¡œ ì¸í•´ gemma2 ì‚¬ìš© ê¶Œì¥
        if "gpt-oss" in self.model_id:
            logger.warning(f"gpt-oss ëª¨ë¸ì€ LangExtractì™€ í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. gemma2:latest ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            print(f"âš ï¸  {self.model_id} ëª¨ë¸ ì‚¬ìš© ì¤‘ - LangExtract í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥")
        
        # LangExtract Ollama ì„¤ì • - ëª¨ë¸ëª…ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
        self.language_model_params = {
            "model_url": f"{self.model_url}/api",
            "model_name": self.model_id,
            "timeout": self.timeout,
            "options": {
                "temperature": 0.1,
                "top_p": 0.9
            }
        }
        
        logger.info(f"LangExtract ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {self.model_id}, URL: {self.model_url}")
    
    def extract_all_fields(self, content: str) -> Dict[str, Any]:
        """
        ê³µê³  ë‚´ìš©ì—ì„œ ëª¨ë“  í•„ë“œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            content: ë¶„ì„í•  ê³µê³  ë‚´ìš© (content.md + ì²¨ë¶€íŒŒì¼)
            
        Returns:
            ì¶”ì¶œëœ ëª¨ë“  í•„ë“œ ì •ë³´
        """
        logger.info("LangExtract í•„ë“œë³„ ì¶”ì¶œ ì‹œì‘")
        
        results = {}
        
        # ê° í•„ë“œë³„ë¡œ ìˆœì°¨ ì¶”ì¶œ
        fields = [
            "ì§€ì›ëŒ€ìƒ", "ì‹œí–‰ê¸°ê´€", "ì œëª©", "ì§€ì›ë‚´ìš©", 
            "ì§€ì›ê¸ˆì•¡", "ë“±ë¡ì¼", "ì ‘ìˆ˜ê¸°ê°„", "ëª¨ì§‘ì¼ì •"
        ]
        
        for field in fields:
            try:
                logger.info(f"  ğŸ“‹ {field} ì¶”ì¶œ ì¤‘...")
                
                extracted_value = self._extract_single_field(field, content)
                results[field] = extracted_value
                
                # ê²°ê³¼ ë¡œê¹…
                if extracted_value and extracted_value.strip() and extracted_value != "ì°¾ì„ ìˆ˜ ì—†ìŒ":
                    logger.info(f"  âœ“ {field} ì¶”ì¶œ ì„±ê³µ: {extracted_value[:50]}...")
                else:
                    logger.warning(f"  âš  {field} ì¶”ì¶œ ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"  âŒ {field} ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                results[field] = "ì°¾ì„ ìˆ˜ ì—†ìŒ"
        
        logger.info("LangExtract í•„ë“œë³„ ì¶”ì¶œ ì™„ë£Œ")
        return results
    
    def _extract_with_ollama_direct(self, field_name: str, content: str) -> str:
        """
        Ollamaë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ íŠ¹ì • í•„ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        try:
            prompt = self._build_extraction_prompt(field_name, content)
            
            response = requests.post(
                f"{self.model_url}/api/chat",
                json={
                    "model": self.model_id,
                    "messages": [{"role": "user", "content": prompt}],
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "top_p": 0.9,
                        "num_predict": 256
                    }
                },
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                extracted = result.get("message", {}).get("content", "").strip()
                
                if not extracted or extracted.lower() in ["ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", "ì •ë³´ì—†ìŒ", "ì°¾ì„ ìˆ˜ ì—†ìŒ", ""]:
                    return "ì°¾ì„ ìˆ˜ ì—†ìŒ"
                    
                return extracted
            else:
                logger.error(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                return "ì°¾ì„ ìˆ˜ ì—†ìŒ"
                
        except Exception as e:
            logger.error(f"Ollama ì§ì ‘ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return "ì°¾ì„ ìˆ˜ ì—†ìŒ"
    
    def _build_extraction_prompt(self, field_name: str, content: str) -> str:
        """í•„ë“œë³„ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        field_description = self._get_field_prompt(field_name)
        
        prompt = f"""ë‹¤ìŒ ê³µê³  ë‚´ìš©ì—ì„œ {field_name}ë¥¼ ì •í™•íˆ ì°¾ì•„ì„œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

{field_description}

ê³µê³  ë‚´ìš©:
{content}

{field_name}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ "ì°¾ì„ ìˆ˜ ì—†ìŒ"ì´ë¼ê³  ë‹µí•˜ì„¸ìš”.
ë‹µë³€ì€ ì¶”ì¶œí•œ ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        return prompt
    

    def _extract_single_field(self, field_name: str, content: str) -> str:
        """
        íŠ¹ì • í•„ë“œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            field_name: ì¶”ì¶œí•  í•„ë“œëª…
            content: ë¶„ì„í•  ë‚´ìš©
            
        Returns:
            ì¶”ì¶œëœ ê°’ ë˜ëŠ” "ì°¾ì„ ìˆ˜ ì—†ìŒ"
        """
        try:
            print(f"    ğŸ” {field_name} ì¶”ì¶œ ì¤‘...")
            
            # í•„ë“œë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ì™€ ì˜ˆì‹œ ìƒì„±
            prompt_description = self._get_field_prompt(field_name)
            examples = self._get_field_examples(field_name)
            
            # LangExtractë¡œ ì¶”ì¶œ ìˆ˜í–‰ - Ollama ì „ìš© ì„¤ì •
            result = lx.extract(
                text_or_documents=content,
                prompt_description=prompt_description,
                examples=examples[:1],  # ì˜ˆì‹œë¥¼ 1ê°œë¡œ ì œí•œ
                model_id=self.model_id,
                model_url=self.model_url,
                fence_output=False,  # Ollamaìš© ì„¤ì •
                use_schema_constraints=False  # Ollamaìš© ì„¤ì •
            )
            
            # ê²°ê³¼ ì²˜ë¦¬
            if result and hasattr(result, 'extractions') and result.extractions:
                first_extraction = result.extractions[0]
                
                if hasattr(first_extraction, 'extraction_text'):
                    extracted = first_extraction.extraction_text.strip()
                elif hasattr(first_extraction, 'text'):
                    extracted = first_extraction.text.strip()
                else:
                    extracted = str(first_extraction).strip()
                    
                if extracted and extracted != "ì°¾ì„ ìˆ˜ ì—†ìŒ":
                    return extracted
                    
            return "ì°¾ì„ ìˆ˜ ì—†ìŒ"
            
        except Exception as e:
            print(f"    âŒ {field_name} ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            logger.error(f"{field_name} ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì°¾ì„ ìˆ˜ ì—†ìŒ"
    
    def _get_field_prompt(self, field_name: str) -> str:
        """í•„ë“œë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        prompts = {
            "ì§€ì›ëŒ€ìƒ": """ê³µê³  ë¬¸ì„œì—ì„œ ì§€ì› ëŒ€ìƒì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”. 
ëˆ„ê°€ ì´ ì§€ì›ì‚¬ì—…ì— ì‹ ì²­í•  ìˆ˜ ìˆëŠ”ì§€ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆ: ì¤‘ì†Œê¸°ì—…, ì†Œìƒê³µì¸, ê°œì¸ì‚¬ì—…ì, ìŠ¤íƒ€íŠ¸ì—…, ì²­ë…„ ë“±""",
            
            "ì‹œí–‰ê¸°ê´€": """ê³µê³  ë¬¸ì„œì—ì„œ ì‹œí–‰ê¸°ê´€(ì£¼ê´€ê¸°ê´€)ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
ì–´ëŠ ê¸°ê´€ì—ì„œ ì´ ì§€ì›ì‚¬ì—…ì„ ì£¼ê´€í•˜ëŠ”ì§€ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆ: ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€, ì„œìš¸ì‹œ, ê²½ê¸°ë„, í•œêµ­ì‚°ì—…ê¸°ìˆ ì§„í¥ì› ë“±""",
            
            "ì œëª©": """ê³µê³  ë¬¸ì„œì—ì„œ ì •í™•í•œ ì œëª©ì„ ì¶”ì¶œí•˜ì„¸ìš”.
ê³µê³ ì˜ ê³µì‹ ì œëª©ì´ë‚˜ ì‚¬ì—…ëª…ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ë¶ˆí•„ìš”í•œ ê¸°í˜¸ë‚˜ ë²ˆí˜¸ëŠ” ì œì™¸í•˜ê³  í•µì‹¬ ì œëª©ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.""",
            
            "ì§€ì›ë‚´ìš©": """ê³µê³  ë¬¸ì„œì—ì„œ ì§€ì› ë‚´ìš©ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì¢…ë¥˜ì˜ ì§€ì›ì„ ì œê³µí•˜ëŠ”ì§€ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆ: ì‚¬ì—…ë¹„ ì§€ì›, êµìœ¡ ì§€ì›, ì»¨ì„¤íŒ… ì§€ì›, ì‹œì„¤ë¹„ ì§€ì› ë“±""",
            
            "ì§€ì›ê¸ˆì•¡": """ê³µê³  ë¬¸ì„œì—ì„œ ì§€ì› ê¸ˆì•¡ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
êµ¬ì²´ì ì¸ ì§€ì› ê¸ˆì•¡ì´ë‚˜ ë²”ìœ„ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆ: ìµœëŒ€ 5,000ë§Œì›, 3ì²œë§Œì› ì´ë‚´, 1ì–µì› í•œë„ ë“±""",
            
            "ë“±ë¡ì¼": """ê³µê³  ë¬¸ì„œì—ì„œ ê³µê³  ë“±ë¡ì¼(ê³µê³ ì¼)ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
ì–¸ì œ ì´ ê³µê³ ê°€ ë“±ë¡ë˜ì—ˆëŠ”ì§€ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ì ‘ìˆ˜ê¸°ê°„ì´ë‚˜ ì‹¬ì‚¬ì¼ì •ì´ ì•„ë‹Œ ê³µê³  ìì²´ì˜ ë“±ë¡ì¼ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.""",
            
            "ì ‘ìˆ˜ê¸°ê°„": """ê³µê³  ë¬¸ì„œì—ì„œ ì ‘ìˆ˜ ê¸°ê°„ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
ì‹ ì²­ì„œë¥¼ ì–¸ì œë¶€í„° ì–¸ì œê¹Œì§€ ë°›ëŠ”ì§€ë§Œ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.
ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ëª¨ë‘ í¬í•¨í•´ì„œ ë°˜í™˜í•˜ì„¸ìš”.""",
            
            "ëª¨ì§‘ì¼ì •": """ê³µê³  ë¬¸ì„œì—ì„œ ì „ì²´ ëª¨ì§‘ ì¼ì •ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
ì ‘ìˆ˜ê¸°ê°„, ì‹¬ì‚¬ì¼ì •, ë°œí‘œì¼ ë“± ì „ì²´ì ì¸ ì¼ì • ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”."""
        }
        
        return prompts.get(field_name, f"{field_name}ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.")
    
    def _get_field_examples(self, field_name: str) -> List[lx.data.ExampleData]:
        """í•„ë“œë³„ ì¶”ì¶œ ì˜ˆì‹œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        examples = {
            "ì§€ì›ëŒ€ìƒ": [
                lx.data.ExampleData(
                    text="ì§€ì›ëŒ€ìƒ: ì¤‘ì†Œê¸°ì—… ë° ì†Œìƒê³µì¸",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ëŒ€ìƒ", extraction_text="ì¤‘ì†Œê¸°ì—…, ì†Œìƒê³µì¸")]
                ),
                lx.data.ExampleData(
                    text="ì‹ ì²­ìê²©: ê°œì¸ì‚¬ì—…ì, ì˜ˆë¹„ì°½ì—…ì", 
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ëŒ€ìƒ", extraction_text="ê°œì¸ì‚¬ì—…ì, ì˜ˆë¹„ì°½ì—…ì")]
                ),
                lx.data.ExampleData(
                    text="â—‹ ëŒ€ìƒ : ìŠ¤íƒ€íŠ¸ì—…, ë²¤ì²˜ê¸°ì—…",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ëŒ€ìƒ", extraction_text="ìŠ¤íƒ€íŠ¸ì—…, ë²¤ì²˜ê¸°ì—…")]
                )
            ],
            
            "ì‹œí–‰ê¸°ê´€": [
                lx.data.ExampleData(
                    text="ì£¼ê´€: ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€",
                    extractions=[lx.data.Extraction(extraction_class="ì‹œí–‰ê¸°ê´€", extraction_text="ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€")]
                ),
                lx.data.ExampleData(
                    text="ì‹œí–‰ê¸°ê´€: ì„œìš¸íŠ¹ë³„ì‹œ",
                    extractions=[lx.data.Extraction(extraction_class="ì‹œí–‰ê¸°ê´€", extraction_text="ì„œìš¸íŠ¹ë³„ì‹œ")]
                ),
                lx.data.ExampleData(
                    text="ì£¼ìµœ: í•œêµ­ì‚°ì—…ê¸°ìˆ ì§„í¥ì›",
                    extractions=[lx.data.Extraction(extraction_class="ì‹œí–‰ê¸°ê´€", extraction_text="í•œêµ­ì‚°ì—…ê¸°ìˆ ì§„í¥ì›")]
                )
            ],
            
            "ì œëª©": [
                lx.data.ExampleData(
                    text="2024ë…„ ì¤‘ì†Œê¸°ì—… ê¸°ìˆ ê°œë°œì§€ì›ì‚¬ì—… ê³µê³ ",
                    extractions=[lx.data.Extraction(extraction_class="ì œëª©", extraction_text="2024ë…„ ì¤‘ì†Œê¸°ì—… ê¸°ìˆ ê°œë°œì§€ì›ì‚¬ì—…")]
                ),
                lx.data.ExampleData(
                    text="â–¡ ì†Œìƒê³µì¸ ì°½ì—…ì§€ì› í”„ë¡œê·¸ë¨ ì•ˆë‚´",
                    extractions=[lx.data.Extraction(extraction_class="ì œëª©", extraction_text="ì†Œìƒê³µì¸ ì°½ì—…ì§€ì› í”„ë¡œê·¸ë¨")]
                )
            ],
            
            "ì§€ì›ë‚´ìš©": [
                lx.data.ExampleData(
                    text="ì§€ì›ë‚´ìš©: ê¸°ìˆ ê°œë°œë¹„, ì¸ê±´ë¹„, ì¥ë¹„êµ¬ì…ë¹„ ì§€ì›",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ë‚´ìš©", extraction_text="ê¸°ìˆ ê°œë°œë¹„, ì¸ê±´ë¹„, ì¥ë¹„êµ¬ì…ë¹„ ì§€ì›")]
                ),
                lx.data.ExampleData(
                    text="â—‹ ì§€ì›ì‚¬í•­: ì‚¬ì—…ë¹„ ì§€ì›, êµìœ¡ ë° ì»¨ì„¤íŒ…",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ë‚´ìš©", extraction_text="ì‚¬ì—…ë¹„ ì§€ì›, êµìœ¡ ë° ì»¨ì„¤íŒ…")]
                )
            ],
            
            "ì§€ì›ê¸ˆì•¡": [
                lx.data.ExampleData(
                    text="ì§€ì›ê¸ˆì•¡: ìµœëŒ€ 5,000ë§Œì›",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ê¸ˆì•¡", extraction_text="ìµœëŒ€ 5,000ë§Œì›")]
                ),
                lx.data.ExampleData(
                    text="â—‹ ì§€ì›ê·œëª¨: 3ì²œë§Œì› ì´ë‚´",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ê¸ˆì•¡", extraction_text="3ì²œë§Œì› ì´ë‚´")]
                )
            ],
            
            "ë“±ë¡ì¼": [
                lx.data.ExampleData(
                    text="ê³µê³ ì¼: 2024ë…„ 3ì›” 15ì¼",
                    extractions=[lx.data.Extraction(extraction_class="ë“±ë¡ì¼", extraction_text="2024ë…„ 3ì›” 15ì¼")]
                ),
                lx.data.ExampleData(
                    text="ì‘ì„±ì¼: 2025.05.30",
                    extractions=[lx.data.Extraction(extraction_class="ë“±ë¡ì¼", extraction_text="2025.05.30")]
                )
            ],
            
            "ì ‘ìˆ˜ê¸°ê°„": [
                lx.data.ExampleData(
                    text="ì ‘ìˆ˜ê¸°ê°„: 2025ë…„ 3ì›” 1ì¼ ~ 2025ë…„ 3ì›” 31ì¼",
                    extractions=[lx.data.Extraction(extraction_class="ì ‘ìˆ˜ê¸°ê°„", extraction_text="2025ë…„ 3ì›” 1ì¼ ~ 2025ë…„ 3ì›” 31ì¼")]
                ),
                lx.data.ExampleData(
                    text="â—‹ ì‹ ì²­ê¸°í•œ: 2024.12.01 ~ 2024.12.31",
                    extractions=[lx.data.Extraction(extraction_class="ì ‘ìˆ˜ê¸°ê°„", extraction_text="2024.12.01 ~ 2024.12.31")]
                )
            ],
            
            "ëª¨ì§‘ì¼ì •": [
                lx.data.ExampleData(
                    text="ëª¨ì§‘ì¼ì •: ì ‘ìˆ˜(3.1~3.31), ì‹¬ì‚¬(4.1~4.15), ë°œí‘œ(4.30)",
                    extractions=[lx.data.Extraction(extraction_class="ëª¨ì§‘ì¼ì •", extraction_text="ì ‘ìˆ˜(3.1~3.31), ì‹¬ì‚¬(4.1~4.15), ë°œí‘œ(4.30)")]
                ),
                lx.data.ExampleData(
                    text="ì¼ì •ì•ˆë‚´: ì‹ ì²­ì ‘ìˆ˜ 12ì›”, ì„œë¥˜ì‹¬ì‚¬ 1ì›”, ìµœì¢…ë°œí‘œ 2ì›”",
                    extractions=[lx.data.Extraction(extraction_class="ëª¨ì§‘ì¼ì •", extraction_text="ì‹ ì²­ì ‘ìˆ˜ 12ì›”, ì„œë¥˜ì‹¬ì‚¬ 1ì›”, ìµœì¢…ë°œí‘œ 2ì›”")]
                )
            ],
            
            "ì§€ì›ë‚´ìš©": [
                lx.data.ExampleData(
                    text="ì§€ì›ë‚´ìš©: ê¸°ìˆ ê°œë°œë¹„, ì¸ê±´ë¹„, ì¥ë¹„êµ¬ì…ë¹„ ì§€ì›",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ë‚´ìš©", extraction_text="ê¸°ìˆ ê°œë°œë¹„, ì¸ê±´ë¹„, ì¥ë¹„êµ¬ì…ë¹„ ì§€ì›")]
                ),
                lx.data.ExampleData(
                    text="â—‹ ì§€ì›í˜•íƒœ: ì»¨ì„¤íŒ… ë° êµìœ¡ ì§€ì›",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ë‚´ìš©", extraction_text="ì»¨ì„¤íŒ… ë° êµìœ¡ ì§€ì›")]
                )
            ],
            
            "ì§€ì›ê¸ˆì•¡": [
                lx.data.ExampleData(
                    text="ì§€ì›ê¸ˆì•¡: ìµœëŒ€ 5,000ë§Œì›",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ê¸ˆì•¡", extraction_text="ìµœëŒ€ 5,000ë§Œì›")]
                ),
                lx.data.ExampleData(
                    text="â—‹ ì§€ì›í•œë„: 3ì²œë§Œì› ì´ë‚´",
                    extractions=[lx.data.Extraction(extraction_class="ì§€ì›ê¸ˆì•¡", extraction_text="3ì²œë§Œì› ì´ë‚´")]
                )
            ],
            
            "ì ‘ìˆ˜ê¸°ê°„": [
                lx.data.ExampleData(
                    text="ì ‘ìˆ˜ê¸°ê°„: 2025ë…„ 3ì›” 1ì¼ ~ 2025ë…„ 3ì›” 31ì¼",
                    extractions=[lx.data.Extraction(extraction_class="ì ‘ìˆ˜ê¸°ê°„", extraction_text="2025ë…„ 3ì›” 1ì¼ ~ 2025ë…„ 3ì›” 31ì¼")]
                ),
                lx.data.ExampleData(
                    text="ì‹ ì²­ì¼ì •: 2025.06.01 ~ 2025.06.30",
                    extractions=[lx.data.Extraction(extraction_class="ì ‘ìˆ˜ê¸°ê°„", extraction_text="2025.06.01 ~ 2025.06.30")]
                )
            ],
            
            "ëª¨ì§‘ì¼ì •": [
                lx.data.ExampleData(
                    text="ëª¨ì§‘ì¼ì •: ì ‘ìˆ˜(3.1~3.31) â†’ ì‹¬ì‚¬(4.1~4.15) â†’ ë°œí‘œ(4.20)",
                    extractions=[lx.data.Extraction(extraction_class="ëª¨ì§‘ì¼ì •", extraction_text="ì ‘ìˆ˜(3.1~3.31) â†’ ì‹¬ì‚¬(4.1~4.15) â†’ ë°œí‘œ(4.20)")]
                ),
                lx.data.ExampleData(
                    text="ì „ì²´ì¼ì •: ëª¨ì§‘ê³µê³ (5ì›”) - ì ‘ìˆ˜(6ì›”) - ì„ ì •í‰ê°€(7ì›”) - ìµœì¢…ë°œí‘œ(8ì›”)",
                    extractions=[lx.data.Extraction(extraction_class="ëª¨ì§‘ì¼ì •", extraction_text="ëª¨ì§‘ê³µê³ (5ì›”) - ì ‘ìˆ˜(6ì›”) - ì„ ì •í‰ê°€(7ì›”) - ìµœì¢…ë°œí‘œ(8ì›”)")]
                )
            ]
        }
        
        return examples.get(field_name, [])
    
    def test_ollama_connection(self) -> bool:
        """Ollama ì—°ê²° ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        try:
            print(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘ - ëª¨ë¸: {self.model_id}, URL: {self.model_url}")
            
            # LangExtract + Ollama í…ŒìŠ¤íŠ¸
            try:
                test_result = lx.extract(
                    text_or_documents="í…ŒìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ 2025ë…„ì…ë‹ˆë‹¤.",
                    prompt_description="ì´ ë¬¸ì„œì—ì„œ ì—°ë„ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜í•˜ì„¸ìš”.",
                    examples=[
                        lx.data.ExampleData(
                            text="2024ë…„ ì‚¬ì—…ì•ˆë‚´",
                            extractions=[lx.data.Extraction(extraction_class="ì—°ë„", extraction_text="2024ë…„")]
                        )
                    ],
                    model_id=self.model_id,
                    model_url=self.model_url,
                    fence_output=False,  # Ollamaìš© ì„¤ì •
                    use_schema_constraints=False  # Ollamaìš© ì„¤ì •
                )
                
                print(f"LangExtract í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_result}")
                print("âœ“ LangExtract + Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
                
            except Exception as e:
                print(f"âŒ LangExtract í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                logger.error(f"LangExtract ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                return False
            
        except Exception as e:
            print(f"âŒ ëª¨ë“  ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False


def extract_announcement_fields(content: str) -> Dict[str, str]:
    """
    ê³µê³  ë‚´ìš©ì—ì„œ ëª¨ë“  í•„ë“œë¥¼ LangExtractë¡œ ì¶”ì¶œí•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        content: ë¶„ì„í•  ê³µê³  ë‚´ìš©
        
    Returns:
        í•„ë“œë³„ ì¶”ì¶œ ê²°ê³¼
    """
    analyzer = LangExtractFieldAnalyzer()
    return analyzer.extract_all_fields(content)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš©
    test_content = """
    2025ë…„ ì¤‘ì†Œê¸°ì—… ê¸°ìˆ ê°œë°œì§€ì›ì‚¬ì—… ê³µê³ 
    
    â—‹ ì‹œí–‰ê¸°ê´€: ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€
    â—‹ ì§€ì›ëŒ€ìƒ: ì¤‘ì†Œê¸°ì—…, ì†Œìƒê³µì¸
    â—‹ ì§€ì›ê¸ˆì•¡: ìµœëŒ€ 5,000ë§Œì›
    â—‹ ì ‘ìˆ˜ê¸°ê°„: 2025ë…„ 3ì›” 1ì¼ ~ 2025ë…„ 3ì›” 31ì¼
    â—‹ ì§€ì›ë‚´ìš©: ê¸°ìˆ ê°œë°œë¹„, ì¸ê±´ë¹„, ì¥ë¹„êµ¬ì…ë¹„ ì§€ì›
    â—‹ ë“±ë¡ì¼: 2025ë…„ 2ì›” 15ì¼
    """

    # LangExtract + Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
    analyzer = LangExtractFieldAnalyzer()
    
    if analyzer.test_ollama_connection():
        print("âœ“ LangExtract + Ollama ì—°ê²° ì„±ê³µ")
        
        # í•„ë“œë³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        print("\n=== í•„ë“œë³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ===")
        results = extract_announcement_fields(test_content)
        
        for field, value in results.items():
            status = "âœ“" if value != "ì°¾ì„ ìˆ˜ ì—†ìŒ" else "âœ—"
            print(f"{status} {field}: {value}")
            
    else:
        print("âŒ LangExtract + Ollama ì—°ê²° ì‹¤íŒ¨")
        print("ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print("1. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("2. ollama serve ëª…ë ¹ìœ¼ë¡œ ì„œë²„ ì‹œì‘")
        print(f"3. ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€: ollama pull {analyzer.model_id}")
        print(f"4. API URLì´ ì˜¬ë°”ë¥¸ì§€: {analyzer.model_url}")