import json
import os
import re
import shutil
import sys
import traceback
from contextlib import closing
from pathlib import Path

from src.config.config import ConfigManager
from src.config.constants import (
    APL_MTHD_CD,
    INDST_CD,
    PRF_RSTR_DV_CD,
    RCPT_INST_CD,
    RCPT_INST_CTGR_CD,
    SPOT_TRG_AREA_CD,
    SPOT_TRG_DV_CD,
    SPOT_TRG_STRTUP_DV_CD,
    SPOT_TYP_DV_CD,
)
from src.config.logConfig import setup_logging
from src.utils.lazy_imports import get_hwp_libraries

# hwp5 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì»¤ìŠ¤í…€ íŒ¨ì¹˜ ì ìš© (UnderlineStyle ê°’ 15 ì§€ì›)
try:
    from src.utils import hwp5_custom
    # import ì‹œ ìë™ìœ¼ë¡œ íŒ¨ì¹˜ ì ìš©ë¨
except Exception as e:
    # íŒ¨ì¹˜ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (fallback ë°©ë²• ì‚¬ìš© ê°€ëŠ¥)
    import logging
    logging.getLogger(__name__).warning(f"hwp5 ì»¤ìŠ¤í…€ íŒ¨ì¹˜ ì ìš© ì‹¤íŒ¨: {e}")

# hwp5 FILETIME í´ë˜ìŠ¤ íŒ¨ì¹˜ (ì˜ëª»ëœ ë‚ ì§œ ë©”íƒ€ë°ì´í„°ë¡œ ì¸í•œ OverflowError ë°©ì§€)
def _patch_hwp5_filetime():
    """
    hwp5 ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ FILETIME í´ë˜ìŠ¤ íŒ¨ì¹˜.

    ì¼ë¶€ HWP íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°(PIDSI_LASTPRINTED ë“±)ì— ì˜ëª»ëœ ë‚ ì§œ ê°’ì´
    ì €ì¥ë˜ì–´ ìˆì„ ê²½ìš° datetime ë³€í™˜ ì‹œ OverflowErrorê°€ ë°œìƒí•©ë‹ˆë‹¤.
    ì´ íŒ¨ì¹˜ëŠ” ì˜ëª»ëœ FILETIME ê°’ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        from hwp5 import msoleprops
        from datetime import datetime, timedelta

        original_datetime_getter = msoleprops.FILETIME.datetime.fget

        def safe_datetime(self):
            try:
                # ìœ íš¨ ë²”ìœ„ ì²´í¬: 1970ë…„ ~ 2100ë…„ (FILETIME ê°’ ê¸°ì¤€)
                # 1970-01-01: 116444736000000000
                # 2100-01-01: 159000000000000000 (ëŒ€ëµ)
                MIN_VALID_FILETIME = 116444736000000000
                MAX_VALID_FILETIME = 159000000000000000

                if self.value < MIN_VALID_FILETIME or self.value > MAX_VALID_FILETIME:
                    # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œëŠ” None ëŒ€ì‹  ê¸°ë³¸ê°’ ë°˜í™˜
                    return datetime(1970, 1, 1, 0, 0, 0)

                return original_datetime_getter(self)
            except (OverflowError, OSError, ValueError):
                # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
                return datetime(1970, 1, 1, 0, 0, 0)

        # ê¸°ì¡´ propertyë¥¼ ìƒˆë¡œìš´ safe_datetimeìœ¼ë¡œ êµì²´
        msoleprops.FILETIME.datetime = property(safe_datetime)

    except ImportError:
        pass  # hwp5ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ë¬´ì‹œ
    except Exception as e:
        import logging
        logging.getLogger(__name__).warning(f"hwp5 FILETIME íŒ¨ì¹˜ ì ìš© ì‹¤íŒ¨: {e}")

# ëª¨ë“ˆ ë¡œë“œ ì‹œ FILETIME íŒ¨ì¹˜ ì ìš©
_patch_hwp5_filetime()

# Heavy libraries moved to lazy imports for faster startup
# These will be imported only when the respective functions are called:
# - markitdown.MarkItDown
# - pdfminer.*
# - marker.*
# - langchain_community.*
# - hwp5.*
# - gethwp
from src.utils.timerUtil import Timer

# Constants moved to lazy import for faster startup


def remove_javascript_content(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ JavaScript ê´€ë ¨ ë‚´ìš©ì„ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        JavaScript ë‚´ìš©ì´ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    # JavaScript ì½”ë“œ ë¸”ë¡ ì œê±° (```javascript ë˜ëŠ” ```js)
    text = re.sub(
        r"```(?:javascript|js)\s*\n.*?\n```", "", text, flags=re.DOTALL | re.IGNORECASE
    )

    # ì¸ë¼ì¸ JavaScript ì½”ë“œ ì œê±° (`javascript` ë˜ëŠ” `js`)
    text = re.sub(r"`(?:javascript|js):[^`]*`", "", text, flags=re.IGNORECASE)

    # <script> íƒœê·¸ ì œê±°
    text = re.sub(
        r"<script\b[^>]*>.*?</script>", "", text, flags=re.DOTALL | re.IGNORECASE
    )

    # JavaScript ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ ì œê±°
    js_keywords = [
        "function",
        "var ",
        "let ",
        "const ",
        "document.",
        "window.",
        "console.",
        "alert(",
        "addEventListener",
    ]
    lines = text.split("\n")
    filtered_lines = []

    for line in lines:
        line_lower = line.lower().strip()
        # JavaScript í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ì¸ì§€ í™•ì¸
        contains_js = any(keyword in line_lower for keyword in js_keywords)

        # JavaScript ê´€ë ¨ ë¼ì¸ì´ ì•„ë‹ˆê±°ë‚˜, ë¬¸ì„œ ë‚´ìš©ì˜ ì¼ë¶€ì¸ ê²½ìš° ìœ ì§€
        if (
            not contains_js
            or line.strip().startswith("#")
            or line.strip().startswith("-")
        ):
            filtered_lines.append(line)

    return "\n".join(filtered_lines)


# ë¡œê¹… ì„¤ì •
logger = setup_logging(__name__)
config = ConfigManager().get_config()

# íŒŒì¼ ì²˜ë¦¬ ê´€ë ¨ ìƒìˆ˜
OUTPUT_DIR = Path(config["directories"]["output_dir"])


def get_converted_pdf_path(md_file: Path) -> Path | None:
    """
    ë³€í™˜ëœ PDF íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        md_file: ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ

    Returns:
        ë³€í™˜ëœ PDF íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        temp_dir = md_file.parent / "temp"
        converted_files = list(temp_dir.glob(f"pdf_{md_file.stem}_*.md"))
        return converted_files[0] if converted_files else None
    except Exception as e:
        logger.error(
            f"PDF ë³€í™˜ ê²½ë¡œ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {md_file} - {str(e)}\n{traceback.format_exc()}"
        )
        return None


def get_converted_hwp_path(md_file: Path) -> Path | None:
    """
    ë³€í™˜ëœ HWP íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        md_file: ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ

    Returns:
        ë³€í™˜ëœ HWP íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        temp_dir = md_file.parent / "temp"
        converted_files = list(temp_dir.glob(f"hwp_{md_file.stem}_*.html"))
        return converted_files[0] if converted_files else None
    except Exception as e:
        logger.error(
            f"HWP ë³€í™˜ ê²½ë¡œ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {md_file} - {str(e)}\n{traceback.format_exc()}"
        )
        return None


def read_json_file(file_path: Path) -> str:
    """
    JSON íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        file_path: JSON íŒŒì¼ ê²½ë¡œ

    Returns:
        JSON ë¬¸ìì—´
    """
    try:
        with open(file_path, encoding="utf-8") as f:
            raw_data = json.load(f)
            if "originalData" in raw_data:
                del raw_data["originalData"]
            data = json.dumps(raw_data, ensure_ascii=False, indent=2)
            return data
    except Exception as e:
        logger.error(
            f"Error reading json file {file_path}: {e}\n{traceback.format_exc()}"
        )
        sys.exit(1)


def read_md_file(file_path: Path, enable_ocr: bool = True) -> str:
    """
    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    OCRì´ í™œì„±í™”ëœ ê²½ìš° ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.

    Args:
        file_path: ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ
        enable_ocr: ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ì—¬ë¶€

    Returns:
        ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´ (OCR í…ìŠ¤íŠ¸ í¬í•¨, íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ë¨)
    """
    try:
        from src.utils.lazy_imports import get_langchain_libraries
        from src.utils.textCleaner import clean_extracted_text

        # ProcessedDataManager handles text saving now

        try:
            langchain_libs = get_langchain_libraries()
            UnstructuredMarkdownLoader = langchain_libs["UnstructuredMarkdownLoader"]

            loader = UnstructuredMarkdownLoader(file_path)
            documents = loader.load()

            # Document ê°ì²´ë“¤ì˜ page_contentë¥¼ ê²°í•©
            data = "\n".join([doc.page_content for doc in documents])
        except Exception as langchain_error:
            logger.warning(
                f"LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ì‹¤íŒ¨, ì§ì ‘ íŒŒì¼ ì½ê¸°ë¡œ í´ë°±: {langchain_error}"
            )
            # í´ë°±: ì§ì ‘ íŒŒì¼ ì½ê¸°
            with open(file_path, encoding="utf-8") as f:
                data = f.read()

        # JavaScript ê´€ë ¨ ë‚´ìš© ì œê±°
        data = remove_javascript_content(data)

        # MD íŒŒì¼ ì „ìš© ë‚´ìš© ì •ë¦¬ (í—¤ë”, í‘¸í„°, ë„¤ë¹„ê²Œì´ì…˜ ë“± ì œê±°)
        try:
            from src.utils.mdContentCleaner import clean_md_content

            data = clean_md_content(data)
            logger.debug(f"MD ë‚´ìš© ì •ë¦¬ ì™„ë£Œ: {file_path.name}")
        except Exception as md_clean_error:
            logger.warning(f"MD ë‚´ìš© ì •ë¦¬ ì‹¤íŒ¨, ê¸°ë³¸ ì²˜ë¦¬ ì§„í–‰: {md_clean_error}")

        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (EXTRACTED_TEXTìš©)
        data = clean_extracted_text(data)

        # ProcessedDataManagerê°€ ì´ì œ í…ìŠ¤íŠ¸ ì €ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤

        # OCR ì²˜ë¦¬ê°€ í™œì„±í™”ëœ ê²½ìš°
        if enable_ocr:
            try:
                from src.utils.imageOcrUtil import (
                    _has_images_in_markdown,
                    extract_images_from_markdown,
                )

                # ì›ë³¸ ë§ˆí¬ë‹¤ìš´ ë‚´ìš© ì½ê¸°
                with open(file_path, encoding="utf-8") as f:
                    md_content = f.read()

                # ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
                if _has_images_in_markdown(md_content, file_path):
                    logger.info(
                        f"MD íŒŒì¼ì— ì´ë¯¸ì§€ ë°œê²¬: {file_path.name} - OCR ì²˜ë¦¬ ì‹œì‘"
                    )

                    # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    ocr_texts = extract_images_from_markdown(md_content, file_path)

                    if ocr_texts:
                        # OCR í…ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ ëì— ì¶”ê°€ (ì •ë¦¬ëœ í…ìŠ¤íŠ¸ë¡œ)
                        ocr_section = "\n\n## ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸\n\n"
                        for i, text in enumerate(ocr_texts, 1):
                            # OCR í…ìŠ¤íŠ¸ë„ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
                            cleaned_ocr_text = clean_extracted_text(text)
                            ocr_section += f"### ì´ë¯¸ì§€ {i}\n{cleaned_ocr_text}\n\n"

                        data += ocr_section
                        logger.info(
                            f"MD íŒŒì¼ì— OCR í…ìŠ¤íŠ¸ ì¶”ê°€: {len(ocr_texts)}ê°œ ì´ë¯¸ì§€"
                        )
                    else:
                        logger.info(
                            f"MD íŒŒì¼ì— ì´ë¯¸ì§€ê°€ ìˆì§€ë§Œ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {file_path.name}"
                        )
                else:
                    logger.debug(
                        f"MD íŒŒì¼ì— ì´ë¯¸ì§€ê°€ ì—†ì–´ì„œ OCR ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°: {file_path.name}"
                    )

            except Exception as ocr_error:
                logger.warning(f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {ocr_error}")

        logger.debug(f"Successfully read attachment md file: {file_path}")
        return data
    except Exception as e:
        logger.error(f"Error reading attachment md file {file_path}: {e}")
        logger.warning(f"MD íŒŒì¼ ì½ê¸° ì‹¤íŒ¨, ë¹ˆ ë¬¸ìì—´ ë°˜í™˜: {file_path}")
        return ""  # ì—ëŸ¬ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ìœ¼ë¡œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨ ë°©ì§€


def read_txt_file(file_path: Path) -> str:
    """
    TXT íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        file_path: TXT íŒŒì¼ ê²½ë¡œ

    Returns:
        TXT íŒŒì¼ ë‚´ìš© ë¬¸ìì—´
    """
    try:
        with open(file_path, encoding="utf-8") as f:
            content = f.read()

        # í…ìŠ¤íŠ¸ ì •ë¦¬
        from src.utils.textCleaner import clean_extracted_text

        cleaned_content = clean_extracted_text(content)

        # ProcessedDataManagerê°€ ì´ì œ í…ìŠ¤íŠ¸ ì €ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤

        logger.debug(
            f"TXT íŒŒì¼ ì½ê¸° ì„±ê³µ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(cleaned_content)}ì): {file_path}"
        )
        return cleaned_content

    except Exception as e:
        logger.error(f"TXT íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path} - {e}")
        return ""


def read_html_file(file_path: Path) -> str:
    """
    HTML/XHTML íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    MarkItDownì„ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì‹¤íŒ¨ ì‹œ UnstructuredHTMLLoaderë¥¼ ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©

    Args:
        file_path: HTML/XHTML íŒŒì¼ ê²½ë¡œ

    Returns:
        HTMLì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    try:
        # 1ì°¨ ì‹œë„: MarkItDown ì‚¬ìš© (ë©”ì¸ ë°©ë²•)
        logger.debug(f"MarkItDownìœ¼ë¡œ HTML ë³€í™˜ ì‹œë„: {file_path}")

        try:
            from markitdown import MarkItDown
            markitdown = MarkItDown()
            result = markitdown.convert(str(file_path))
        except (ImportError, AttributeError) as e:
            # NumPy ë²„ì „ ì¶©ëŒ ë“±ìœ¼ë¡œ markitdown import ì‹¤íŒ¨ ì‹œ
            logger.warning(f"MarkItDown import ì‹¤íŒ¨ (NumPy í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥): {e}")
            logger.info("BeautifulSoupë¡œ ëŒ€ì²´í•˜ì—¬ HTML ì²˜ë¦¬")
            result = None

        if result and result.text_content and len(result.text_content.strip()) > 50:
            content = result.text_content.strip()

            # í…ìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì¦
            korean_chars = sum(1 for c in content if 0xAC00 <= ord(c) <= 0xD7AF)
            chinese_chars = sum(1 for c in content if 0x4E00 <= ord(c) <= 0x9FFF)
            # í‚¤ë¦´ ë¬¸ì ë²”ìœ„ ì¶”ê°€ (U+0400~U+04FF: Cyrillic, U+0500~U+052F: Cyrillic Supplement)
            cyrillic_chars = sum(1 for c in content if 0x0400 <= ord(c) <= 0x052F)
            total_meaningful_chars = len(
                [c for c in content if c.strip() and c.isalpha()]
            )

            if total_meaningful_chars > 0:
                korean_ratio = korean_chars / total_meaningful_chars
                chinese_ratio = chinese_chars / total_meaningful_chars
                cyrillic_ratio = cyrillic_chars / total_meaningful_chars

                # ì¤‘êµ­ì–´ ë˜ëŠ” í‚¤ë¦´ ë¬¸ì ê°ì§€ ì‹œ ì¸ì½”ë”© ë¬¸ì œë¡œ íŒë‹¨ (ì„ê³„ê°’ ë‚®ì¶¤: 10% -> 1%)
                if (chinese_ratio > korean_ratio and chinese_ratio > 0.01) or \
                   (cyrillic_ratio > 0.01):  # í‚¤ë¦´ì€ 1%ë§Œ ìˆì–´ë„ ë³µêµ¬ ì‹œë„
                    logger.warning(
                        f"ì¸ì½”ë”© ë¬¸ì œ ê°ì§€ë¨ - í•œê¸€: {korean_ratio:.2%}, ì¤‘êµ­ì–´: {chinese_ratio:.2%}, í‚¤ë¦´: {cyrillic_ratio:.2%}: {file_path}"
                    )
                    # ì¸ì½”ë”© ë³µêµ¬ ì‹œë„
                    content = fix_hwp_encoding(content)

            logger.info(
                f"MarkItDownìœ¼ë¡œ HTML ë³€í™˜ ì„±ê³µ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)}ì): {file_path}"
            )
            return content
        else:
            logger.warning(f"MarkItDown ë³€í™˜ ê²°ê³¼ê°€ ë¶€ì¡±í•¨: {file_path}")

    except Exception as e:
        logger.warning(f"MarkItDown HTML ë³€í™˜ ì‹¤íŒ¨: {file_path} - {e}")

    # 2ì°¨ ì‹œë„: UnstructuredHTMLLoader ì‚¬ìš© (í´ë°± ë°©ë²•)
    try:
        logger.debug(f"UnstructuredHTMLLoaderë¡œ HTML ë³€í™˜ ì‹œë„ (í´ë°±): {file_path}")

        # Heavy library - lazy import for performance
        from langchain_community.document_loaders import UnstructuredHTMLLoader

        loader = UnstructuredHTMLLoader(file_path)
        documents = loader.load()

        # Document ê°ì²´ë“¤ì˜ page_contentë¥¼ ê²°í•©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if documents:
            content = "\n".join([doc.page_content for doc in documents])

            # í…ìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì¦
            if len(content.strip()) > 50:
                # í•œê¸€ ë¬¸ì ë¹„ìœ¨ í™•ì¸ (ì¸ì½”ë”© ë¬¸ì œ ê°ì§€)
                korean_chars = sum(1 for c in content if 0xAC00 <= ord(c) <= 0xD7AF)
                chinese_chars = sum(1 for c in content if 0x4E00 <= ord(c) <= 0x9FFF)
                # í‚¤ë¦´ ë¬¸ì ë²”ìœ„ ì¶”ê°€ (U+0400~U+04FF: Cyrillic, U+0500~U+052F: Cyrillic Supplement)
                cyrillic_chars = sum(1 for c in content if 0x0400 <= ord(c) <= 0x052F)
                total_meaningful_chars = len(
                    [c for c in content if c.strip() and c.isalpha()]
                )

                if total_meaningful_chars > 0:
                    korean_ratio = korean_chars / total_meaningful_chars
                    chinese_ratio = chinese_chars / total_meaningful_chars
                    cyrillic_ratio = cyrillic_chars / total_meaningful_chars

                    # ì¤‘êµ­ì–´ ë˜ëŠ” í‚¤ë¦´ ë¬¸ì ê°ì§€ ì‹œ ì¸ì½”ë”© ë¬¸ì œë¡œ íŒë‹¨ (ì„ê³„ê°’ ë‚®ì¶¤: 10% -> 1%)
                    if (chinese_ratio > korean_ratio and chinese_ratio > 0.01) or \
                       (cyrillic_ratio > 0.01):  # í‚¤ë¦´ì€ 1%ë§Œ ìˆì–´ë„ ë³µêµ¬ ì‹œë„
                        logger.warning(
                            f"ì¸ì½”ë”© ë¬¸ì œ ê°ì§€ë¨ - í•œê¸€: {korean_ratio:.2%}, ì¤‘êµ­ì–´: {chinese_ratio:.2%}, í‚¤ë¦´: {cyrillic_ratio:.2%}: {file_path}"
                        )

                        # ì¸ì½”ë”© ë³µêµ¬ ì‹œë„
                        content = fix_hwp_encoding(content)

                logger.info(
                    f"UnstructuredHTMLLoaderë¡œ HTML ë³€í™˜ ì„±ê³µ (í´ë°±) (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)}ì): {file_path}"
                )
                return content
            else:
                logger.warning(
                    f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ ({len(content)}ì): {file_path}"
                )
                return content
        else:
            logger.warning(f"HTML ë¡œë”ì—ì„œ Document ê°ì²´ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ: {file_path}")
            return ""

    except Exception as e:
        logger.error(f"UnstructuredHTMLLoader HTML íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path} - {e}")
        return ""


def fix_hwp_encoding(text: str) -> str:
    """
    HWP íŒŒì¼ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì˜ ì¸ì½”ë”© ë¬¸ì œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    í•œê¸€ì´ ì¤‘êµ­ì–´ ë¬¸ì ë˜ëŠ” í‚¤ë¦´ ë¬¸ìë¡œ ì˜ëª» ë³€í™˜ëœ ê²½ìš° ë³µêµ¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.

    Args:
        text: ì¸ì½”ë”© ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸

    Returns:
        ì¸ì½”ë”©ì´ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸
    """
    try:
        # ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if len(text.strip()) < 10:
            return text

        # í‚¤ë¦´ ë¬¸ì ë¹„ìœ¨ í™•ì¸
        cyrillic_chars = sum(1 for c in text if 0x0400 <= ord(c) <= 0x052F)
        total_chars = len([c for c in text if c.strip() and c.isalpha()])
        cyrillic_ratio = cyrillic_chars / total_chars if total_chars > 0 else 0.0

        # ì—¬ëŸ¬ ì¸ì½”ë”© ë³µêµ¬ ë°©ë²• ì‹œë„
        recovery_methods = [
            # ë°©ë²• 1: UTF-8 -> EUC-KR -> UTF-8 ì¬ë³€í™˜
            lambda t: t.encode("latin1").decode("euc-kr", errors="ignore"),
            # ë°©ë²• 2: CP949 ì¬ë³€í™˜
            lambda t: t.encode("latin1").decode("cp949", errors="ignore"),
            # ë°©ë²• 3: ë°”ì´íŠ¸ ë ˆë²¨ì—ì„œ ì§ì ‘ ë³€í™˜
            lambda t: _direct_byte_conversion(t),
        ]

        # í‚¤ë¦´ ë¬¸ìê°€ ìˆìœ¼ë©´ í‚¤ë¦´ ë³µêµ¬ ì‹œë„ë¥¼ ë¨¼ì € ì¶”ê°€ (ì„ê³„ê°’ ë‚®ì¶¤: 10% -> 1%)
        if cyrillic_ratio > 0.01:
            logger.info(f"í‚¤ë¦´ ë¬¸ì ê°ì§€ë¨ ({cyrillic_ratio:.2%}), í‚¤ë¦´->í•œê¸€ ë³µêµ¬ ì‹œë„")
            recovery_methods.insert(0, lambda t: _recover_from_cyrillic(t))

        best_text = text
        best_korean_ratio = _calculate_korean_ratio(text)

        for method in recovery_methods:
            try:
                recovered_text = method(text)
                if (
                    recovered_text and len(recovered_text) > len(text) * 0.8
                ):  # ë„ˆë¬´ ë§ì´ ì†ì‹¤ë˜ì§€ ì•Šì•˜ë‹¤ë©´
                    korean_ratio = _calculate_korean_ratio(recovered_text)

                    # í•œê¸€ ë¹„ìœ¨ì´ ê°œì„ ë˜ì—ˆë‹¤ë©´ ì±„íƒ
                    if korean_ratio > best_korean_ratio + 0.1:  # 10% ì´ìƒ ê°œì„ 
                        best_text = recovered_text
                        best_korean_ratio = korean_ratio
                        logger.info(
                            f"ì¸ì½”ë”© ë³µêµ¬ ì„±ê³µ - í•œê¸€ ë¹„ìœ¨: {best_korean_ratio:.2%}"
                        )

            except Exception as e:
                logger.debug(f"ì¸ì½”ë”© ë³µêµ¬ ë°©ë²• ì‹¤íŒ¨: {e}")
                continue

        return best_text

    except Exception as e:
        logger.error(f"ì¸ì½”ë”© ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return text


def _calculate_korean_ratio(text: str) -> float:
    """í…ìŠ¤íŠ¸ì—ì„œ í•œê¸€ ë¬¸ìì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if not text:
        return 0.0

    korean_chars = sum(1 for c in text if 0xAC00 <= ord(c) <= 0xD7AF)
    total_chars = len([c for c in text if c.strip() and c.isalpha()])

    return korean_chars / total_chars if total_chars > 0 else 0.0


def _detect_pdf_encoding(pdf_path: str) -> str:
    """
    PDF íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ

    Returns:
        ê°ì§€ëœ ì¸ì½”ë”© ì´ë¦„ (ì˜ˆ: 'utf-8', 'euc-kr', 'cp949' ë“±) ë˜ëŠ” None
    """
    try:
        # chardet ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (ì„¤ì¹˜ í•„ìš”: pip install chardet)
        try:
            import chardet
        except ImportError:
            logger.debug("chardet ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ê¸°ë³¸ ì¸ì½”ë”© ê°ì§€ë§Œ ìˆ˜í–‰")
            # chardet ì—†ì´ë„ ì‘ë™í•˜ë„ë¡ ê¸°ë³¸ ì¸ì½”ë”© ëª©ë¡ ì‹œë„
            return _detect_encoding_fallback(pdf_path)

        # PDF íŒŒì¼ì˜ ì¼ë¶€ë¥¼ ì½ì–´ì„œ ì¸ì½”ë”© ê°ì§€
        with open(pdf_path, 'rb') as f:
            # PDF í—¤ë” ê±´ë„ˆë›°ê¸°
            raw_data = f.read(10240)  # ì²˜ìŒ 10KB ì½ê¸°

            # PDF ìŠ¤íŠ¸ë¦¼ ê°ì²´ ì°¾ê¸° (ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš©)
            stream_start = raw_data.find(b'stream')
            if stream_start > 0:
                # stream ì´í›„ ë°ì´í„°ë¶€í„° ë¶„ì„
                raw_data = raw_data[stream_start:]

            # chardetë¡œ ì¸ì½”ë”© ê°ì§€
            result = chardet.detect(raw_data)
            detected_encoding = result['encoding']
            confidence = result['confidence']

            if detected_encoding and confidence > 0.7:
                logger.info(f"PDF ì¸ì½”ë”© ê°ì§€ ì„±ê³µ: {detected_encoding} (ì‹ ë¢°ë„: {confidence:.2%})")
                return detected_encoding
            else:
                logger.warning(f"PDF ì¸ì½”ë”© ê°ì§€ ì‹ ë¢°ë„ ë‚®ìŒ: {detected_encoding} ({confidence:.2%})")
                # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ í´ë°± ë°©ì‹ ì‹œë„
                return _detect_encoding_fallback(pdf_path)

    except Exception as e:
        logger.warning(f"PDF ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨: {e}")
        return _detect_encoding_fallback(pdf_path)


def _detect_encoding_fallback(pdf_path: str) -> str:
    """
    chardet ì—†ì´ ì¼ë°˜ì ì¸ ì¸ì½”ë”©ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ê°ì§€í•©ë‹ˆë‹¤.

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ

    Returns:
        ì‘ë™í•˜ëŠ” ì¸ì½”ë”© ì´ë¦„ ë˜ëŠ” None
    """
    # í•œêµ­ì–´ PDFì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¸ì½”ë”© ìˆœì„œ
    encodings_to_try = [
        'utf-8',
        'cp949',      # Windows í•œê¸€ (EUC-KR í™•ì¥)
        'euc-kr',     # ìœ ë‹‰ìŠ¤/ë¦¬ëˆ…ìŠ¤ í•œê¸€
        'utf-16',
        'iso-8859-1', # Latin-1
        'cp1252',     # Windows Western Europe
        'gbk',        # ì¤‘êµ­ì–´ ê°„ì²´
        'big5',       # ì¤‘êµ­ì–´ ë²ˆì²´
        'shift-jis',  # ì¼ë³¸ì–´
    ]

    try:
        with open(pdf_path, 'rb') as f:
            raw_data = f.read(10240)

            # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•  ìƒ˜í”Œ ì¶”ì¶œ
            for encoding in encodings_to_try:
                try:
                    # ë””ì½”ë”© ì‹œë„
                    decoded = raw_data.decode(encoding, errors='strict')

                    # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    korean_ratio = _calculate_korean_ratio(decoded)

                    if korean_ratio > 0.1:  # 10% ì´ìƒ í•œê¸€ì´ë©´ ì„±ê³µ
                        logger.info(f"í´ë°± ì¸ì½”ë”© ê°ì§€ ì„±ê³µ: {encoding} (í•œê¸€ ë¹„ìœ¨: {korean_ratio:.2%})")
                        return encoding
                    elif encoding == 'utf-8' and not any(ord(c) > 127 for c in decoded if c.strip()):
                        # ASCII ë²”ìœ„ë§Œ ìˆìœ¼ë©´ UTF-8ë¡œ ê°„ì£¼
                        logger.info(f"ASCII ì „ìš© íŒŒì¼, UTF-8 ì‚¬ìš©: {encoding}")
                        return encoding

                except (UnicodeDecodeError, UnicodeError):
                    # ì´ ì¸ì½”ë”©ì€ ë§ì§€ ì•ŠìŒ, ë‹¤ìŒ ì‹œë„
                    continue

        logger.warning("ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨, UTF-8 ê¸°ë³¸ê°’ ì‚¬ìš©")
        return 'utf-8'

    except Exception as e:
        logger.error(f"í´ë°± ì¸ì½”ë”© ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
        return 'utf-8'


def _direct_byte_conversion(text: str) -> str:
    """ë°”ì´íŠ¸ ë ˆë²¨ì—ì„œ ì§ì ‘ ë³€í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤."""
    try:
        # ì‹¤ì œ HWP íŒŒì¼ì—ì„œ ë°œê²¬ëœ ì¤‘êµ­ì–´ ë¬¸ìë¥¼ í•œê¸€ë¡œ ì§ì ‘ ë§¤í•‘
        chinese_to_korean_map = {
            # ì‹¤ì œ íŒŒì¼ì—ì„œ ë°œê²¬ëœ ì˜¤ë¥˜ ì‚¬ë¡€ë“¤
            "æ¤": "ì²¨",
            "ç¥": "ë¶€",
            "æ±¤": "íƒ•",
            "æ¯": "ë„",
            "æ‘‚": "ì„­",
            "æµ§": "ì˜",
            # ì¶”ê°€ ë§¤í•‘ (ì¼ë°˜ì ì¸ ì˜¤ë¥˜ íŒ¨í„´)
            "æ° ": "",  # ë¹ˆ ë¬¸ìë¡œ ì²˜ë¦¬
            "ç‘¢": "",  # ë¹ˆ ë¬¸ìë¡œ ì²˜ë¦¬
            "æ¼ ": "",  # ë¹ˆ ë¬¸ìë¡œ ì²˜ë¦¬
            "æ³": "",
            "æ° ç‘¢": "",  # íŒ¨í„´ìœ¼ë¡œ ì œê±°
            "æ° ç‘¢    ": "",  # ê³µë°± í¬í•¨ íŒ¨í„´
            "    æ±¤æ¯": "",  # ê³µë°± í¬í•¨ íŒ¨í„´
            "æ¼ æ³": "",  # íŒ¨í„´ìœ¼ë¡œ ì œê±°
            # í•œê¸€ ë§¤í•‘ (ìì£¼ ë°œê²¬ë˜ëŠ” íŒ¨í„´)
            "ì¬": "ì¬",
            "ë‹¨": "ë‹¨",
            "ë²•": "ë²•",
            "ì¸": "ì¸",
            "ë¶€": "ë¶€",
            "ì‚°": "ì‚°",
            "í…Œ": "í…Œ",
            "í¬": "í¬",
            "ë…¸": "ë…¸",
            "íŒŒ": "íŒŒ",
            "ê³µ": "ê³µ",
            "ê³ ": "ê³ ",
            "ì œ": "ì œ",
            "í˜¸": "í˜¸",
            # ì¼ë°˜ì ì¸ ì¤‘êµ­ì–´-í•œê¸€ ë§¤í•‘
            "ä¸­": "ì¤‘",
            "å›½": "êµ­",
            "ä¼": "ê¸°",
            "ä¸š": "ì—…",
            "æŠ€": "ê¸°",
            "æœ¯": "ìˆ ",
            "æ”¯": "ì§€",
            "æŒ": "ì§€",
            "é‡‘": "ê¸ˆ",
            "é¢": "ì•¡",
            "é¡¹": "í•­",
            "ç›®": "ëª©",
            "ç”³": "ì‹ ",
            "è¯·": "ì²­",
            "æ–¹": "ë°©",
            "æ³•": "ë²•",
            "é€‰": "ì„ ",
            "æ‹©": "íƒ",
            "æ¡": "ì¡°",
            "ä»¶": "ê±´",
            "å†…": "ë‚´",
            "å®¹": "ìš©",
            "è¦": "ìš”",
            "æ±‚": "êµ¬",
        }

        result = text

        # íŒ¨í„´ë³„ë¡œ ì œê±°/êµì²´
        for chinese, korean in chinese_to_korean_map.items():
            result = result.replace(chinese, korean)

        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        import re

        result = re.sub(r"\s+", " ", result)
        result = result.strip()

        return result

    except Exception:
        return text


def _recover_from_cyrillic(text: str) -> str:
    """
    í‚¤ë¦´ ë¬¸ìë¡œ ì˜ëª» ì¸ì½”ë”©ëœ í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ë³µêµ¬í•©ë‹ˆë‹¤.

    HWP íŒŒì¼ì—ì„œ HTML ë³€í™˜ ì‹œ í•œê¸€ EUC-KR/CP949 ë°”ì´íŠ¸ê°€
    í‚¤ë¦´ ë¬¸ì(Cyrillic)ë¡œ ì˜ëª» í•´ì„ëœ ê²½ìš°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    ì˜ˆ: 'Ğ»Ò¸â€¦Ğ¼Ò›Ñ˜ ĞºÓ©Ó¯Ğ¼ Ò£' (í‚¤ë¦´) -> 'ë…ì¼ ì¡°ëª… ë°' (í•œê¸€)

    Args:
        text: í‚¤ë¦´ ë¬¸ìê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸

    Returns:
        ë³µêµ¬ëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ ì›ë³¸)
    """
    try:
        # UTF-8 ë°”ì´íŠ¸ë¥¼ ì–»ìŒ
        utf8_bytes = text.encode('utf-8')

        # ë°©ë²• 1: UTF-8 ë°”ì´íŠ¸ë¥¼ ISO-8859-1ë¡œ ë””ì½”ë”© í›„ EUC-KRë¡œ ì¬í•´ì„
        try:
            # UTF-8 -> ISO-8859-1 (ë°”ì´íŠ¸ ê°’ ë³´ì¡´) -> EUC-KR
            latin1_text = utf8_bytes.decode('iso-8859-1')
            recovered = latin1_text.encode('iso-8859-1').decode('euc-kr', errors='ignore')

            # ë³µêµ¬ ê²°ê³¼ ê²€ì¦ - í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì„ê³„ê°’ ë‚®ì¶¤: 10ì -> 1ì)
            korean_chars = sum(1 for c in recovered if 0xAC00 <= ord(c) <= 0xD7AF)
            if korean_chars > 1:  # ìµœì†Œ 1ì ì´ìƒ í•œê¸€ì´ ìˆì–´ì•¼ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                logger.info(f"í‚¤ë¦´->í•œê¸€ ë³µêµ¬ ì„±ê³µ (ë°©ë²•1: ISO-8859-1->EUC-KR): {korean_chars}ì í•œê¸€ ë³µêµ¬")
                return recovered
        except Exception as e:
            logger.debug(f"í‚¤ë¦´ ë³µêµ¬ ë°©ë²•1 ì‹¤íŒ¨: {e}")

        # ë°©ë²• 2: CP949 ì‹œë„
        try:
            latin1_text = utf8_bytes.decode('iso-8859-1')
            recovered = latin1_text.encode('iso-8859-1').decode('cp949', errors='ignore')

            korean_chars = sum(1 for c in recovered if 0xAC00 <= ord(c) <= 0xD7AF)
            if korean_chars > 1:  # ì„ê³„ê°’ ë‚®ì¶¤: 10ì -> 1ì
                logger.info(f"í‚¤ë¦´->í•œê¸€ ë³µêµ¬ ì„±ê³µ (ë°©ë²•2: ISO-8859-1->CP949): {korean_chars}ì í•œê¸€ ë³µêµ¬")
                return recovered
        except Exception as e:
            logger.debug(f"í‚¤ë¦´ ë³µêµ¬ ë°©ë²•2 ì‹¤íŒ¨: {e}")

        # ë°©ë²• 3: Windows-1251 (í‚¤ë¦´ ì¸ì½”ë”©) -> EUC-KR
        try:
            # í˜„ì¬ UTF-8 ë¬¸ìì—´ì„ Windows-1251 ë°”ì´íŠ¸ë¡œ ì¬í•´ì„
            cp1251_bytes = text.encode('cp1251', errors='ignore')
            recovered = cp1251_bytes.decode('euc-kr', errors='ignore')

            korean_chars = sum(1 for c in recovered if 0xAC00 <= ord(c) <= 0xD7AF)
            if korean_chars > 1:  # ì„ê³„ê°’ ë‚®ì¶¤: 10ì -> 1ì
                logger.info(f"í‚¤ë¦´->í•œê¸€ ë³µêµ¬ ì„±ê³µ (ë°©ë²•3: CP1251->EUC-KR): {korean_chars}ì í•œê¸€ ë³µêµ¬")
                return recovered
        except Exception as e:
            logger.debug(f"í‚¤ë¦´ ë³µêµ¬ ë°©ë²•3 ì‹¤íŒ¨: {e}")

        logger.warning("í‚¤ë¦´ ë³µêµ¬ ì‹¤íŒ¨ - ì›ë³¸ ë°˜í™˜")
        return text

    except Exception as e:
        logger.error(f"í‚¤ë¦´ ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return text


def should_exclude_file(file_path: Path) -> bool:
    """
    âš ï¸ DEPRECATED (2025-11-14): ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    ê·œì¹™ ê¸°ë°˜ íŒŒì¼ ì„ ë³„ ì‹œìŠ¤í…œ(rule_based_file_selection)ìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.
    ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ì—ˆìœ¼ë‚˜, ìƒˆë¡œìš´ ì½”ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

    ëŒ€ì‹  ì‚¬ìš©: rule_based_file_selection(all_files, announcement_title)

    ---

    íŒŒì¼ëª…ì— ì œì™¸ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        file_path: ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ì œì™¸í•´ì•¼ í•˜ëŠ” íŒŒì¼ì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    import re

    filename = file_path.name
    filename_lower = filename.lower()

    # 1. ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ (ì¤‘ìš”í•œ íŒŒì¼ì€ ì œì™¸í•˜ì§€ ì•ŠìŒ)
    # ê°€ì¥ ë¨¼ì € ì²´í¬í•˜ì—¬ ì¤‘ìš” íŒŒì¼ì´ ì œì™¸ë˜ì§€ ì•Šë„ë¡ ë³´í˜¸
    # êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¶€í„° ë¨¼ì € ì²´í¬í•˜ì—¬ ì •í™•í•œ ë§¤ì¹­ ì •ë³´ í™•ë³´
    priority_keywords = [
        # ê³µê³  ê´€ë ¨ (ìµœìš°ì„ ) - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ëª¨ì§‘ê³µê³ ",
        "ì„ ì •ê³µê³ ",
        "ë°œí‘œê³µê³ ",
        "ê³µê³ ë¬¸",
        "ê³µê³ ",
        "ê³µë¬¸",
        # ì‚¬ì—… ê´€ë ¨ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ì‚¬ì—…ê³„íš",
        "ì§€ì›ì‚¬ì—…",
        "ë³´ì¡°ì‚¬ì—…",
        "ì‚¬ì—…",
        # ë³´ì¡°ê¸ˆ ê´€ë ¨
        "ë³´ì¡°ê¸ˆ",
        # ì‹ ì²­/ëª¨ì§‘/ì§€ì› ê´€ë ¨ - ë³µí•©ì–´ë§Œ í¬í•¨ (ë‹¨ë… "ì‹ ì²­"ì€ ì œì™¸)
        "ì§€ì›ì‹ ì²­",
        "ì°¸ê°€ì‹ ì²­",
        "ì…ì£¼ì‹ ì²­",
        "ì ‘ìˆ˜ì‹ ì²­",
        "ëª¨ì§‘",
        "ì§€ì›",
        "ì°¸ì—¬",
        "ì ‘ìˆ˜",
        # ê³„íš/ì œì•ˆ ê´€ë ¨
        "ì‚¬ì—…ê³„íšì„œ",
        "ì¶”ì§„ê³„íšì„œ",
        "ê³„íšì„œ",
        "ì œì•ˆì„œ",
        "ì¶”ì§„ê³„íš",
    ]

    # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì œì™¸í•˜ì§€ ì•ŠìŒ
    for priority in priority_keywords:
        if priority in filename_lower:
            logger.info(f"íŒŒì¼ í¬í•¨ - ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë°œê²¬: {filename} -> [{priority}]")
            return False

    # 2. ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ë³µì¡í•œ íŒ¨í„´ ê²€ì‚¬
    # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ì œì™¸ ê²€ì‚¬
    regex_patterns = [
        # r"ë¶™ì„\s*\d+",  # ë¶™ì„1, ë¶™ì„ 1, ë¶™ì„2 ë“±
        # r"ë³„ì²¨\s*\d+",  # ë³„ì²¨1, ë³„ì²¨ 1, ë³„ì²¨2 ë“±
        r"ë³„ì§€\s*\d+",  # ë³„ì§€1, ë³„ì§€ 1, ë³„ì§€2 ë“±
        r"ë¶€ë¡\s*\d+",  # ë¶€ë¡1, ë¶€ë¡ 1, ë¶€ë¡2 ë“±
        # r"\[ì„œì‹\d*[-\d]*\]",  # [ì„œì‹1], [ì„œì‹2], [ì„œì‹2-7] ë“±
        # r"\(ì„œì‹\d*[-\d]*\)",  # (ì„œì‹1), (ì„œì‹2), (ì„œì‹2-7) ë“±
        # r"ì„œì‹\s*\d+[-\d]*",  # ì„œì‹1, ì„œì‹2, ì„œì‹2-7 ë“±
        r"ì–‘ì‹\s*\d+[-\d]*",  # ì–‘ì‹1, ì–‘ì‹2, ì–‘ì‹2-7 ë“±
        r"ì²¨ë¶€\s*ë¬¸ì„œ",  # ì²¨ë¶€ë¬¸ì„œ, ì²¨ë¶€ ë¬¸ì„œ
        r"ì²¨ë¶€\s*ì„œë¥˜",  # ì²¨ë¶€ì„œë¥˜, ì²¨ë¶€ ì„œë¥˜
        r"ì²¨ë¶€\s*ìë£Œ",  # ì²¨ë¶€ìë£Œ, ì²¨ë¶€ ìë£Œ
        r"ë§¤ë‰´ì–¼\s*\d+",  # ë§¤ë‰´ì–¼1
    ]

    found_patterns = []
    for pattern in regex_patterns:
        if re.search(pattern, filename, re.IGNORECASE):
            found_patterns.append(pattern)

    if found_patterns:
        logger.info(f"íŒŒì¼ ì œì™¸ - íŒ¨í„´ ë§¤ì¹­: {filename} -> {found_patterns}")
        return True

    # 3. ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ì‚¬ (ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
    # êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¶€í„° ë¨¼ì € ì²´í¬í•˜ì—¬ ì •í™•í•œ ë§¤ì¹­ ì •ë³´ í™•ë³´
    exclude_keywords = [
        # ì‹ ì²­ì„œ ê´€ë ¨ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„° (ìš°ì„ ìˆœìœ„ì—ì„œ ì œì™¸ëœ ë‹¨ë… ì‹ ì²­ì„œ í¬í•¨)
        "ì‹ ì²­ì„œì–‘ì‹",
        "ì…ì£¼ì‹ ì²­ì„œ",
        "ì°¸ê°€ì‹ ì²­ì„œ",
        "ì§€ì›ì‹ ì²­ì„œ",
        "ì ‘ìˆ˜ì‹ ì²­ì„œ",
        "ë“±ë¡ì‹ ì²­ì„œ",
        "íšŒì›ì‹ ì²­ì„œ",
        "ê°€ì…ì‹ ì²­ì„œ",
        "ì‹ ì²­ì–‘ì‹",
        "ì‹ ì²­ì„œ",
        # ì²¨ë¶€ ê´€ë ¨ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ì²¨ë¶€ë¬¸ì„œ",
        "ì²¨ë¶€ì„œë¥˜",
        "ì²¨ë¶€ìë£Œ",
        "ì²¨ë¶€",
        # í…œí”Œë¦¿ ê´€ë ¨ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ê³„íšì„œí…œí”Œë¦¿",
        "ì œì•ˆì„œí…œí”Œë¦¿",
        "ë³´ê³ ì„œí…œí”Œë¦¿",
        "í…œí”Œë¦¿",
        "template",
        # ê¸°ë³¸ ì„œì‹/ì–‘ì‹ ê´€ë ¨
        "ì„œì‹",
        "ì–‘ì‹",
        "form",
        # ì²¨ë¶€/ë³„ì²¨ ê´€ë ¨
        "ë³„ì²¨",
        "ë³„í‘œ",
        "ì°¸ê³ ìë£Œ",
        "ì°¸ì¡°",
        "ë³„ì§€",
        "ë¶€ë¡",
        # ê¸°íƒ€ ì œì™¸ ëŒ€ìƒ
        "ì²´í¬ë¦¬ìŠ¤íŠ¸",
        "checklist",
        "ì ê²€í‘œ",
        "ì•ˆë‚´ì„œ",
        "ê°€ì´ë“œ",
        "guide",
        "ë§¤ë‰´ì–¼",
        "manual",
        "ìƒ˜í”Œ",
        "sample",
        "ì˜ˆì‹œ",
        "example",
        # FAQëŠ” ë” êµ¬ì²´ì ìœ¼ë¡œ (ë‹¨ë… FAQ íŒŒì¼ë§Œ)
        "ìì£¼ë¬»ëŠ”ì§ˆë¬¸",
        "faq.",
        "_faq",
        "faq_",
    ]

    found_exclude_keywords = []
    for exclude in exclude_keywords:
        if exclude in filename_lower:
            found_exclude_keywords.append(exclude)

    if found_exclude_keywords:
        logger.info(
            f"íŒŒì¼ ì œì™¸ - ì œì™¸ í‚¤ì›Œë“œ ë°œê²¬: {filename} -> {found_exclude_keywords}"
        )
        return True

    return False


def normalize_text(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤ (ì†Œë¬¸ìí™”, ê³µë°± ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°).

    Args:
        text: ì •ê·œí™”í•  í…ìŠ¤íŠ¸

    Returns:
        ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""

    # ì†Œë¬¸ìí™” ë° ê³µë°± ì œê±°
    normalized = text.lower().replace(" ", "")

    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³, ìˆ«ì, í•œê¸€ë§Œ ìœ ì§€)
    normalized = "".join(c for c in normalized if c.isalnum() or c in "ê°€-í£")

    return normalized


def calculate_title_similarity(filename: str, announcement_title: str) -> float:
    """
    íŒŒì¼ëª…ê³¼ ê³µê³  ì œëª©ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        filename: ë¹„êµí•  íŒŒì¼ëª… (í™•ì¥ì í¬í•¨ ê°€ëŠ¥)
        announcement_title: ê³µê³  ì œëª©

    Returns:
        float: ìœ ì‚¬ë„ ì ìˆ˜ (0.0 ~ 1.0)
    """
    from difflib import SequenceMatcher

    if not filename or not announcement_title:
        return 0.0

    # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
    filename_stem = Path(filename).stem

    # í…ìŠ¤íŠ¸ ì •ê·œí™”
    normalized_filename = normalize_text(filename_stem)
    normalized_title = normalize_text(announcement_title)

    if not normalized_filename or not normalized_title:
        return 0.0

    # difflibë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
    matcher = SequenceMatcher(None, normalized_filename, normalized_title)
    similarity = matcher.ratio()

    logger.debug(
        f"ì œëª© ìœ ì‚¬ë„: {similarity:.3f} | íŒŒì¼ëª…: {filename_stem[:30]} | ì œëª©: {announcement_title[:30]}"
    )

    return similarity


def calculate_file_score(file_path: Path, announcement_title: str = "", apply_image_penalty: bool = True) -> dict:
    """
    âš ï¸ DEPRECATED (2025-11-14): ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    ê·œì¹™ ê¸°ë°˜ íŒŒì¼ ì„ ë³„ ì‹œìŠ¤í…œ(rule_based_file_selection)ìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.
    ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ì—ˆìœ¼ë‚˜, ìƒˆë¡œìš´ ì½”ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

    ëŒ€ì‹  ì‚¬ìš©: rule_based_file_selection(all_files, announcement_title)

    ---

    íŒŒì¼ì˜ ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œì™€ ì œì™¸ í‚¤ì›Œë“œë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.

    Args:
        file_path: ì ìˆ˜ë¥¼ ê³„ì‚°í•  íŒŒì¼ ê²½ë¡œ
        announcement_title: ê³µê³  ì œëª© (ì„ íƒì‚¬í•­, ì œëª© ìœ ì‚¬ë„ ê³„ì‚°ì— ì‚¬ìš©)

    Returns:
        dict: {
            'priority_score': int,         # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ì ìˆ˜
            'exclude_score': int,          # ì œì™¸ í‚¤ì›Œë“œ íŒ¨ë„í‹°
            'pattern_penalty': int,        # ì •ê·œì‹ íŒ¨í„´ íŒ¨ë„í‹°
            'title_similarity': float,     # ì œëª© ìœ ì‚¬ë„ (0.0-1.0)
            'base_score': float,           # ê¸°ë³¸ ì ìˆ˜ (ìš°ì„ ìˆœìœ„ - ì œì™¸ - íŒ¨í„´)
            'final_score': float,          # ìµœì¢… ì ìˆ˜ (ê¸°ë³¸ ì ìˆ˜ Ã— ì œëª© ê°€ì¤‘ì¹˜)
            'matched_priority': list,      # ë§¤ì¹­ëœ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ
            'matched_exclude': list,       # ë§¤ì¹­ëœ ì œì™¸ í‚¤ì›Œë“œ
            'matched_patterns': list       # ë§¤ì¹­ëœ ì •ê·œì‹ íŒ¨í„´
        }
    """
    import re
    from difflib import SequenceMatcher

    filename = file_path.name
    filename_lower = filename.lower()
    filename_stem = file_path.stem  # í™•ì¥ì ì œì™¸

    # ğŸ†• ì œëª©ê³¼ íŒŒì¼ëª…ì´ ì¼ì¹˜í•˜ë©´ ìµœìš°ì„  ì„ íƒ (ìœ ì‚¬ë„ > 0.95)
    if announcement_title and filename_stem:
        # ì œëª© ìœ ì‚¬ë„ ë¨¼ì € ê³„ì‚°
        title_similarity_check = calculate_title_similarity(filename, announcement_title)

        if title_similarity_check > 0.95:
            logger.info(
                f"ğŸ“Œ ì œëª©-íŒŒì¼ëª… ì¼ì¹˜ ê°ì§€ (ìœ ì‚¬ë„: {title_similarity_check:.3f}) â†’ ìµœìš°ì„  ì„ íƒ: {filename[:60]}"
            )
            return {
                'priority_score': 1000,
                'exclude_score': 0,
                'pattern_penalty': 0,
                'extension_penalty': 0,
                'title_similarity': 1.0,
                'base_score': 1000.0,
                'final_score': 2000.0,  # ë¬´ì¡°ê±´ ìµœê³  ì ìˆ˜
                'matched_priority': ['ì œëª©ì¼ì¹˜(+1000)'],
                'matched_exclude': [],
                'matched_patterns': []
            }

    # ê¸°ì¡´ ë¡œì§ ê³„ì†...

    # 1. ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (êµ¬ì²´ì ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
    priority_keywords = {
        # ê³µê³  ê´€ë ¨ (ìµœìš°ì„ ) - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ëª¨ì§‘ê³µê³ ": 20,
        "ì„ ì •ê³µê³ ": 20,
        "ë°œí‘œê³µê³ ": 20,
        "ê³µê³ ë¬¸": 15,
        "ê³µê³ ": 10,
        "ê³µë¬¸": 10,
        # ì‚¬ì—… ê´€ë ¨ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ì‚¬ì—…ê³„íš": 15,
        "ì§€ì›ì‚¬ì—…": 15,
        "ë³´ì¡°ì‚¬ì—…": 15,
        "ì‚¬ì—…": 5,
        # ë³´ì¡°ê¸ˆ ê´€ë ¨
        "ë³´ì¡°ê¸ˆ": 10,
        # ì‹ ì²­/ëª¨ì§‘/ì§€ì› ê´€ë ¨ - ë³µí•©ì–´ë§Œ í¬í•¨
        "ì§€ì›ì‹ ì²­": 8,
        "ì°¸ê°€ì‹ ì²­": 8,
        "ì…ì£¼ì‹ ì²­": 8,
        "ì ‘ìˆ˜ì‹ ì²­": 8,
        "ëª¨ì§‘": 8,
        "ì§€ì›": 5,
        "ì°¸ì—¬": 5,
        "ì ‘ìˆ˜": 5,
        # ê³„íš/ì œì•ˆ ê´€ë ¨
        "ì‚¬ì—…ê³„íšì„œ": 12,
        "ì¶”ì§„ê³„íšì„œ": 12,
        "ê³„íšì„œ": 8,
        "ì œì•ˆì„œ": 8,
        "ì¶”ì§„ê³„íš": 8,
    }

    priority_score = 0
    matched_priority = []

    for keyword, score in priority_keywords.items():
        if keyword in filename_lower:
            priority_score += score
            matched_priority.append(f"{keyword}(+{score})")

    # 2. ì •ê·œì‹ íŒ¨í„´ íŒ¨ë„í‹° (-30ì /íŒ¨í„´)
    regex_patterns = [
        r"ë³„ì§€\s*\d+",
        r"ë¶€ë¡\s*\d+",
        r"ì–‘ì‹\s*\d+[-\d]*",
        r"ì²¨ë¶€\s*ë¬¸ì„œ",
        r"ì²¨ë¶€\s*ì„œë¥˜",
        r"ì²¨ë¶€\s*ìë£Œ",
        r"ë§¤ë‰´ì–¼\s*\d+",
    ]

    pattern_penalty = 0
    matched_patterns = []

    for pattern in regex_patterns:
        if re.search(pattern, filename, re.IGNORECASE):
            pattern_penalty += 30
            matched_patterns.append(pattern)

    # 3. ì œì™¸ í‚¤ì›Œë“œ íŒ¨ë„í‹° (êµ¬ì²´ì ì¼ìˆ˜ë¡ ë†’ì€ íŒ¨ë„í‹°)
    exclude_keywords = {
        # ì‹ ì²­ì„œ ê´€ë ¨ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°
        "ì‹ ì²­ì„œì–‘ì‹": 35,
        "ì…ì£¼ì‹ ì²­ì„œ": 30,
        "ì°¸ê°€ì‹ ì²­ì„œ": 30,
        "ì§€ì›ì‹ ì²­ì„œ": 30,
        "ì ‘ìˆ˜ì‹ ì²­ì„œ": 30,
        "ë“±ë¡ì‹ ì²­ì„œ": 30,
        "íšŒì›ì‹ ì²­ì„œ": 30,
        "ê°€ì…ì‹ ì²­ì„œ": 30,
        "ì‹ ì²­ì–‘ì‹": 30,
        "ì‹ ì²­ì„œ": 25,
        # ì²¨ë¶€ ê´€ë ¨
        "ì²¨ë¶€ë¬¸ì„œ": 25,
        "ì²¨ë¶€ì„œë¥˜": 25,
        "ì²¨ë¶€ìë£Œ": 25,
        "ì²¨ë¶€": 20,
        # í…œí”Œë¦¿ ê´€ë ¨
        "ê³„íšì„œí…œí”Œë¦¿": 30,
        "ì œì•ˆì„œí…œí”Œë¦¿": 30,
        "ë³´ê³ ì„œí…œí”Œë¦¿": 30,
        "í…œí”Œë¦¿": 25,
        "template": 25,
        # ê¸°ë³¸ ì„œì‹/ì–‘ì‹ ê´€ë ¨
        "ì„œì‹": 25,
        "ì–‘ì‹": 25,
        "form": 20,
        # ì²¨ë¶€/ë³„ì²¨ ê´€ë ¨
        "ë³„ì²¨": 20,
        "ë³„í‘œ": 20,
        "ì°¸ê³ ìë£Œ": 20,
        "ì°¸ì¡°": 15,
        "ë³„ì§€": 20,
        "ë¶€ë¡": 20,
        "ë¶™ì„": 15,
        # ê¸°íƒ€ ì œì™¸ ëŒ€ìƒ
        "ì²´í¬ë¦¬ìŠ¤íŠ¸": 20,
        "checklist": 20,
        "ì ê²€í‘œ": 20,
        "ì•ˆë‚´ì„œ": 15,
        "ê°€ì´ë“œ": 15,
        "guide": 15,
        "ë§¤ë‰´ì–¼": 15,
        "manual": 15,
        "ìƒ˜í”Œ": 20,
        "sample": 20,
        "ì˜ˆì‹œ": 20,
        "example": 20,
        # FAQ
        "ìì£¼ë¬»ëŠ”ì§ˆë¬¸": 15,
        "faq.": 15,
        "_faq": 15,
        "faq_": 15,
        # ğŸ†• ì´ë¯¸ì§€ ê´€ë ¨ ì œì™¸ í‚¤ì›Œë“œ
        "ê³µê³ ì´ë¯¸ì§€": 15,
        "í¬ìŠ¤í„°": 10,
        "ì´ë¯¸ì§€": 10,
    }

    exclude_score = 0
    matched_exclude = []

    for keyword, penalty in exclude_keywords.items():
        if keyword in filename_lower:
            exclude_score += penalty
            matched_exclude.append(f"{keyword}(-{penalty})")

    # 4. ì œëª© ìœ ì‚¬ë„ ê³„ì‚°
    title_similarity = 0.0
    if announcement_title:
        title_similarity = calculate_title_similarity(filename, announcement_title)

    # 5. ğŸ†• í™•ì¥ìë³„ íŒ¨ë„í‹° (ì´ë¯¸ì§€ íŒŒì¼ ìš°ì„ ìˆœìœ„ ë‚®ì¶¤)
    # ë‹¨, ë¬¸ì„œ íŒŒì¼ì´ ì—†ê³  ì´ë¯¸ì§€ë§Œ ìˆëŠ” ê²½ìš°ì—ëŠ” íŒ¨ë„í‹° ë¯¸ì ìš©
    file_extension = file_path.suffix.lower()
    extension_penalty = 0

    if file_extension in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']:
        if apply_image_penalty:
            extension_penalty = 20  # ì´ë¯¸ì§€ íŒŒì¼ íŒ¨ë„í‹° (ë¬¸ì„œê°€ ìˆì„ ë•Œë§Œ)
            logger.debug(f"ì´ë¯¸ì§€ íŒŒì¼ íŒ¨ë„í‹° ì ìš©: {filename} (-{extension_penalty})")
        else:
            logger.debug(f"ì´ë¯¸ì§€ë§Œ ìˆìŒ - íŒ¨ë„í‹° ë¯¸ì ìš©: {filename}")

    # 6. ìµœì¢… ì ìˆ˜ ê³„ì‚°
    # base_score = ìš°ì„ ìˆœìœ„ ì ìˆ˜ - ì œì™¸ íŒ¨ë„í‹° - íŒ¨í„´ íŒ¨ë„í‹° - í™•ì¥ì íŒ¨ë„í‹°
    base_score = priority_score - exclude_score - pattern_penalty - extension_penalty

    # final_score = base_score Ã— (1.0 + title_similarity)
    # ì œëª© ìœ ì‚¬ë„ê°€ ë†’ì„ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ì¦ê°€ (ìµœëŒ€ 2ë°°)
    final_score = base_score * (1.0 + title_similarity)

    result = {
        "priority_score": priority_score,
        "exclude_score": exclude_score,
        "pattern_penalty": pattern_penalty,
        "extension_penalty": extension_penalty,
        "title_similarity": title_similarity,
        "base_score": base_score,
        "final_score": final_score,
        "matched_priority": matched_priority,
        "matched_exclude": matched_exclude,
        "matched_patterns": matched_patterns,
    }

    logger.debug(
        f"íŒŒì¼ ì ìˆ˜ ê³„ì‚°: {filename} | "
        f"ìš°ì„ ìˆœìœ„={priority_score} ì œì™¸={exclude_score} íŒ¨í„´={pattern_penalty} | "
        f"ìœ ì‚¬ë„={title_similarity:.3f} | base={base_score:.1f} final={final_score:.1f}"
    )

    return result


def convert_code_info():
    """
    ì½”ë“œ ìƒìˆ˜ ê°’ë“¤ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        str: ì½”ë“œ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ìì—´
    """

    # ì½”ë“œ ì‚¬ì „ ëª©ë¡
    code_dicts = {
        "ì†Œê´€ê¸°ê´€ì½”ë“œ (RCPT_INST_CD)": RCPT_INST_CD,
        "ì†Œê´€ê¸°ê´€ìœ í˜•ì½”ë“œ (RCPT_INST_CTGR_CD)": RCPT_INST_CTGR_CD,
        "ì§€ì›ëŒ€ìƒêµ¬ë¶„ì½”ë“œ (SPOT_TRG_DV_CD)": SPOT_TRG_DV_CD,
        "ì§€ì›ëŒ€ìƒì°½ì—…êµ¬ë¶„ì½”ë“œ (SPOT_TRG_STRTUP_DV_CD)": SPOT_TRG_STRTUP_DV_CD,
        "ì§€ì›ëŒ€ìƒì§€ì—­ì½”ë“œ (SPOT_TRG_AREA_CD)": SPOT_TRG_AREA_CD,
        "ì‹ ì²­ë°©ë²•ì½”ë“œ (APL_MTHD_CD)": APL_MTHD_CD,
        "ìš°ëŒ€ì œí•œêµ¬ë¶„ì½”ë“œ (PRF_RSTR_DV_CD)": PRF_RSTR_DV_CD,
        "ì—…ì¢…ì½”ë“œ (INDST_CD)": INDST_CD,
        "ì§€ì›ë¶„ì•¼êµ¬ë¶„ì½”ë“œ (SPOT_TYP_DV_CD)": SPOT_TYP_DV_CD,
    }

    # ëª¨ë“  ì½”ë“œ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ìƒì„±
    code_info_str = ""
    for title, code_dict in code_dicts.items():
        code_info_str += f"- {title}\n"
        for name, code in code_dict.items():
            code_info_str += f"    - {name} : {code}\n"
        code_info_str += "\n"

    # ë§ˆì§€ë§‰ ì¤„ë°”ê¿ˆ í•˜ë‚˜ ì œê±°
    return code_info_str.rstrip()


def listToStr(data) -> str:
    """
    ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (íƒ€ì… ì•ˆì „ì„± ê°œì„ )

    Args:
        data: ë³€í™˜í•  ë°ì´í„° (ë¦¬ìŠ¤íŠ¸, ë¬¸ìì—´, ë˜ëŠ” ê¸°íƒ€)

    Returns:
        ë¬¸ìì—´
    """
    # None ì²´í¬
    if data is None:
        return ""

    # ì´ë¯¸ ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì¤‘ìš”!)
    if isinstance(data, str):
        return data

    # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
    if not isinstance(data, (list, tuple)):
        return str(data)

    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²´í¬
    if len(data) == 0:
        return ""

    # ë°°ì—´ì´ ê°œë³„ ë¬¸ìë¡œ ë¶„ë¦¬ëœ ê²½ìš° ê°ì§€ ë° ë³µì›
    if len(data) > 10 and all(len(str(item)) <= 3 for item in data):
        # ëŒ€ë¶€ë¶„ì˜ ìš”ì†Œê°€ 3ì ì´í•˜ì´ë©´ ë¬¸ìì—´ì´ ë¶„ë¦¬ëœ ê²ƒìœ¼ë¡œ íŒë‹¨
        result = "".join(str(item) for item in data)
    else:
        # ì •ìƒì ì¸ ë°°ì—´ì¸ ê²½ìš° ì‰¼í‘œë¡œ ì—°ê²°
        result = ", ".join(str(item) for item in data if item)

    return result


def strToInt(data) -> int:
    """
    ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        data: ë³€í™˜í•  ë¬¸ìì—´ ë˜ëŠ” ì •ìˆ˜

    Returns:
        ì •ìˆ˜
    """
    if data is None:
        return 0
    if isinstance(data, int):
        return data
    if isinstance(data, str) and (data == "" or data == "null"):
        return 0
    if isinstance(data, str) and len(data) == 0:
        return 0
    try:
        return int(data)
    except (ValueError, TypeError):
        return 0


def convert_pdf_to_md_docling(pdf_path: str, output_path: str = None) -> bool:
    """
    Doclingì„ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    í‘œ êµ¬ì¡° ë³´ì¡´ê³¼ OCR ê¸°ëŠ¥ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
        output_path (str, optional): ì¶œë ¥í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì œì™¸í•  í‚¤ì›Œë“œ ê²€ì‚¬ (ì„œì‹, ì–‘ì‹ ë“±)
        if should_exclude_file(Path(pdf_path)):
            return False

        with Timer(f"PDF íŒŒì¼ ë³€í™˜ (Docling): {pdf_path}", totalTimeChk=False):
            try:
                from docling.document_converter import (
                    DocumentConverter,
                    PdfFormatOption,
                )
                from docling.datamodel.base_models import InputFormat
                from docling.datamodel.pipeline_options import (
                    OcrOptions,
                    PdfPipelineOptions,
                    TableStructureOptions,
                )

                logger.info("!!docling IMPORT!!!")
            except ImportError as e:
                logger.error(f"Docling ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                logger.info("pip install doclingì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”")
                return False

            # í‘œ êµ¬ì¡° ë³´ì¡´ ì˜µì…˜ ì„¤ì • (ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­)
            try:
                table_options = TableStructureOptions(
                    do_cell_matching=False,  # ì…€ ë§¤ì¹­ í™œì„±í™”
                )

                pipeline_options = PdfPipelineOptions(
                    do_table_structure=True,  # í‘œ êµ¬ì¡° ì¸ì‹ í™œì„±í™”
                    table_structure_options=table_options,
                )

                pipeline_options.do_ocr = True
                pipeline_options.ocr_options.use_gpu = False

                pdf_format_options = PdfFormatOption(pipeline_options=pipeline_options)
                converter = DocumentConverter(
                    format_options={InputFormat.PDF: pdf_format_options}
                )
                logger.info("í‘œ êµ¬ì¡° ì¸ì‹ í™œì„±í™”ëœ DocumentConverter ìƒì„± ì™„ë£Œ")
            except Exception as opt_error:
                logger.warning(f"ê³ ê¸‰ ì˜µì…˜ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ ë³€í™˜ê¸° ì‚¬ìš©: {opt_error}")
                converter = DocumentConverter()

            # PDF íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ (ê°œì„ ëœ ë²„ì „)
            try:
                with open(pdf_path, "rb") as f:
                    header = f.read(4)
                    if header != b"%PDF":
                        logger.warning(
                            f"ìœ íš¨í•˜ì§€ ì•Šì€ PDF íŒŒì¼ (í—¤ë” ë¶ˆì¼ì¹˜): {pdf_path}"
                        )
                        return False

                    # PDF íŒŒì¼ êµ¬ì¡° ê¸°ë³¸ ê²€ì‚¬ - ë” í° ë²”ìœ„ë¥¼ ê²€ì‚¬í•˜ê±°ë‚˜ ê±´ë„ˆë›°ê¸°
                    # Root ê°ì²´ëŠ” íŒŒì¼ ì–´ë””ì—ë‚˜ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì „ì²´ íŒŒì¼ì„ ê²€ì‚¬í•˜ê±°ë‚˜
                    # ë˜ëŠ” ì´ ê²€ì‚¬ë¥¼ ê±´ë„ˆë›°ê³  ë³€í™˜ ì‹œë„ë¥¼ í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì„ ìˆ˜ ìˆìŒ
                    file_size = os.path.getsize(pdf_path)
                    if file_size > 0:
                        # íŒŒì¼ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ë³€í™˜ ì‹œë„
                        f.seek(0)
                        # íŒŒì¼ì´ ë„ˆë¬´ í¬ë©´ ì²˜ìŒ 10KBë§Œ í™•ì¸, ì‘ìœ¼ë©´ ì „ì²´ í™•ì¸
                        check_size = min(10240, file_size)  # 10KB ë˜ëŠ” íŒŒì¼ ì „ì²´
                        content = f.read(check_size)

                        # Root ê°ì²´ê°€ ì—†ì–´ë„ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ë³€í™˜ ì‹œë„
                        if b"/Root" not in content:
                            logger.warning(
                                f"PDF íŒŒì¼ì— Root ê°ì²´ê°€ ì²˜ìŒ {check_size}ë°”ì´íŠ¸ ë‚´ì— ì—†ìŒ: {pdf_path}"
                            )
                            logger.info(
                                "Root ê°ì²´ê°€ ë’¤ìª½ì— ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë³€í™˜ ì‹œë„ë¥¼ ê³„ì†í•©ë‹ˆë‹¤..."
                            )
                            # return Falseë¥¼ ì œê±°í•˜ì—¬ ë³€í™˜ ê³„ì† ì§„í–‰
                    else:
                        logger.error(f"PDF íŒŒì¼ì´ ë¹„ì–´ìˆìŒ: {pdf_path}")
                        return False

            except Exception as e:
                logger.error(f"PDF íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                # ì½ê¸° ì‹¤íŒ¨í•´ë„ ë³€í™˜ì€ ì‹œë„í•´ë³¼ ìˆ˜ ìˆìŒ
                logger.info("PDF íŒŒì¼ ì½ê¸° ì‹¤íŒ¨í–ˆì§€ë§Œ ë³€í™˜ ì‹œë„ë¥¼ ê³„ì†í•©ë‹ˆë‹¤...")

            # PDF ë³€í™˜ ì‹¤í–‰
            try:
                conversion_result = converter.convert(pdf_path)

                # Markdownìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
                markdown_content = conversion_result.document.export_to_markdown()
                # logger.info(markdown_content)

                # ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if not markdown_content or not markdown_content.strip():
                    logger.warning(f"Docling ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ: {pdf_path}")
                    return convert_pdf_to_md_markitdown_fallback(pdf_path, output_path)

                # íŒŒì¼ì— ì €ì¥
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(markdown_content)

                logger.info(f"Docling PDF ë³€í™˜ ì™„ë£Œ: {output_path}")
                return True

            except UnicodeDecodeError as ude:
                logger.warning(f"Docling PDF ì¸ì½”ë”© ì˜¤ë¥˜ ê°ì§€: {pdf_path} - {ude}")

                # ì¸ì½”ë”© ìë™ ê°ì§€ ë° ì¬ì‹œë„
                detected_encoding = _detect_pdf_encoding(pdf_path)
                if detected_encoding and detected_encoding.lower() != 'utf-8':
                    logger.info(f"ê°ì§€ëœ ì¸ì½”ë”©: {detected_encoding}, ì¬ë³€í™˜ ì‹œë„")
                    try:
                        # ê°ì§€ëœ ì¸ì½”ë”©ìœ¼ë¡œ PDF ì¬ì²˜ë¦¬ ì‹œë„
                        conversion_result = converter.convert(pdf_path)
                        markdown_content = conversion_result.document.export_to_markdown()

                        if markdown_content and markdown_content.strip():
                            # ì¸ì½”ë”© ìˆ˜ì • í›„ ì €ì¥
                            try:
                                # ê°ì§€ëœ ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë“œ í›„ UTF-8ë¡œ ì¬ì¸ì½”ë”©
                                if isinstance(markdown_content, bytes):
                                    markdown_content = markdown_content.decode(detected_encoding, errors='replace')

                                with open(output_path, "w", encoding="utf-8") as f:
                                    f.write(markdown_content)

                                logger.info(f"ì¸ì½”ë”© ìˆ˜ì • í›„ Docling ë³€í™˜ ì™„ë£Œ: {output_path}")
                                return True
                            except Exception as enc_e:
                                logger.warning(f"ì¸ì½”ë”© ë³€í™˜ ì‹¤íŒ¨: {enc_e}")
                    except Exception as retry_e:
                        logger.warning(f"ì¸ì½”ë”© ìˆ˜ì • í›„ ì¬ì‹œë„ ì‹¤íŒ¨: {retry_e}")

                logger.info(f"ì¸ì½”ë”© ì˜¤ë¥˜ë¡œ markitdown í´ë°±: {pdf_path}")
                return convert_pdf_to_md_markitdown_fallback(pdf_path, output_path)
            except Exception as conv_e:
                logger.warning(f"Docling ë³€í™˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {pdf_path} - {conv_e}")
                logger.info(f"Docling ë³€í™˜ ì‹¤íŒ¨, markitdown í´ë°±: {pdf_path}")
                return convert_pdf_to_md_markitdown_fallback(pdf_path, output_path)

    except UnicodeDecodeError as e:
        logger.warning(f"Docling PDF ì¸ì½”ë”© ì˜¤ë¥˜: {pdf_path} - {e}")
        logger.info(f"ì¸ì½”ë”© ì˜¤ë¥˜ë¡œ markitdown í´ë°±: {pdf_path}")
        return convert_pdf_to_md_markitdown_fallback(pdf_path, output_path)
    except Exception as e:
        logger.error(f"Docling PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ê¸°ì¡´ markitdownìœ¼ë¡œ í´ë°±
        logger.info(f"Docling ë³€í™˜ ì‹¤íŒ¨, markitdownìœ¼ë¡œ í´ë°±: {pdf_path}")
        return convert_pdf_to_md_markitdown_fallback(pdf_path, output_path)


def convert_pdf_to_md_markitdown_fallback(
    pdf_path: str, output_path: str = None
) -> bool:
    """
    ê¸°ì¡´ markitdownì„ ì‚¬ìš©í•œ PDF ë³€í™˜ (Docling ì‹¤íŒ¨ì‹œ í´ë°±ìš©)

    Args:
        pdf_path (str): ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
        output_path (str, optional): ì¶œë ¥í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    try:
        try:
            from markitdown import MarkItDown
        except (ImportError, AttributeError) as e:
            logger.warning(f"MarkItDown import ì‹¤íŒ¨ (NumPy í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥): {e}")
            logger.info("MarkItDown ì—†ì´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ PDF ì²˜ë¦¬")
            return False

        # PDF íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        if not os.path.exists(pdf_path):
            logger.error(f"PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {pdf_path}")
            return False

        file_size = os.path.getsize(pdf_path)
        if file_size == 0:
            logger.error(f"PDF íŒŒì¼ì´ ë¹„ì–´ìˆìŒ: {pdf_path}")
            return False

        if file_size > 100 * 1024 * 1024:  # 100MB ì œí•œ
            logger.warning(f"PDF íŒŒì¼ì´ ë„ˆë¬´ í¼ (>100MB): {pdf_path}")
            return False

        ## markitdown START ##
        md = MarkItDown(enable_plugins=False)

        result = md.convert(pdf_path)

        # ë³€í™˜ ê²°ê³¼ ê²€ì¦
        if not result or not hasattr(result, "text_content") or not result.text_content:
            logger.warning(f"Markitdown ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ: {pdf_path}")
            return False

        # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ë³€í™˜ ì‹¤íŒ¨ë¡œ ê°„ì£¼
        if len(result.text_content.strip()) < 10:
            logger.warning(f"Markitdown ë³€í™˜ ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ìŒ: {pdf_path}")
            return False

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(result.text_content)

        logger.info(f"Markitdown í´ë°± ë³€í™˜ ì™„ë£Œ: {output_path}")
        return True

    except UnicodeDecodeError as e:
        logger.error(f"Markitdown ìœ ë‹ˆì½”ë“œ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        return False
    except Exception as e:
        error_msg = str(e)
        if "PDFSyntaxError" in error_msg or "No /Root object" in error_msg:
            logger.warning(f"ì†ìƒëœ PDF íŒŒì¼ë¡œ ë³€í™˜ ë¶ˆê°€: {pdf_path}")
        elif "Invalid code point" in error_msg:
            logger.warning(f"ì˜ëª»ëœ ì½”ë“œ í¬ì¸íŠ¸ë¡œ ë³€í™˜ ë¶ˆê°€: {pdf_path}")
        elif "File conversion failed" in error_msg:
            logger.warning(f"PDF ë³€í™˜ê¸°ì—ì„œ íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {pdf_path}")
        else:
            logger.error(
                f"Markitdown í´ë°± ë³€í™˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\n{traceback.format_exc()}"
            )
        return False


def convert_pdf_to_md_markitdown(pdf_path: str, output_path: str = None) -> bool:
    """
    ê¸°ì¡´ markitdownì„ ì‚¬ìš©í•œ PDF ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
    """
    return convert_pdf_to_md_markitdown_fallback(pdf_path, output_path)


def find_pdf_files(directory: str, md_file: str = None) -> list[str]:
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ PDF íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    ì ˆëŒ€ ê²½ë¡œì™€ ìƒëŒ€ ê²½ë¡œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
    í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ data í´ë”ë„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        directory (str): ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œ)
        md_filename (str, optional): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ëª… (data í´ë” ê²€ìƒ‰ìš©)

    Returns:
        list[str]: ë°œê²¬ëœ PDF íŒŒì¼ë“¤ì˜ ì ˆëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    try:
        pdf_files = []

        pdf_dir_path = Path(directory) / md_file

        for root, _, files in os.walk(pdf_dir_path):
            for file in files:
                try:
                    if file.lower().endswith(".pdf"):
                        pdf_files.append(os.path.abspath(os.path.join(root, file)))
                except Exception as e:
                    logger.error(
                        f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {file} - {str(e)}\n{traceback.format_exc()}"
                    )
                    continue

        return pdf_files

    except Exception as e:
        logger.error(
            f"PDF íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {directory}/{md_file} - {str(e)}\n{traceback.format_exc()}"
        )
        return []


def find_hwp_files(directory: str, md_file: str = None) -> list[str]:
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ HWP íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    ì ˆëŒ€ ê²½ë¡œì™€ ìƒëŒ€ ê²½ë¡œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
    í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ data í´ë”ë„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        directory (str): ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œ)
        md_filename (str, optional): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ëª… (data í´ë” ê²€ìƒ‰ìš©)

    Returns:
        list[str]: ë°œê²¬ëœ HWP íŒŒì¼ë“¤ì˜ ì ˆëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    try:
        hwp_files = []

        hwp_dir_path = Path(directory) / md_file

        for root, _, files in os.walk(hwp_dir_path):
            for file in files:
                try:
                    if file.lower().endswith((".hwp", ".hwpx")):
                        hwp_files.append(os.path.abspath(os.path.join(root, file)))
                except Exception as e:
                    logger.error(
                        f"HWP íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {file} - {str(e)}\n{traceback.format_exc()}"
                    )
                    continue

        if not hwp_files:
            logger.warning(f"HWP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hwp_dir_path}")

        return hwp_files

    except Exception as e:
        logger.error(
            f"HWP íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {directory}/{md_file} - {str(e)}\n{traceback.format_exc()}"
        )
        return []


def convert_text_to_markdown(text: str) -> str:
    """
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        text (str): ë³€í™˜í•  í…ìŠ¤íŠ¸
    Returns:
        str: Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ í…ìŠ¤íŠ¸
    """
    try:
        lines = text.split("\n")
        markdown_lines = []
        in_list = False

        for line in lines:
            try:
                # ë¹ˆ ì¤„ ì²˜ë¦¬
                if not line.strip():
                    markdown_lines.append("")
                    in_list = False
                    continue

                # ì œëª© ì²˜ë¦¬ (ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì œëª©)
                if re.match(r"^\d+\.", line.strip()):
                    markdown_lines.append(f"## {line}")
                    continue

                # ëª©ë¡ ì²˜ë¦¬
                if line.strip().startswith("â€¢") or line.strip().startswith("-"):
                    if not in_list:
                        markdown_lines.append("")
                    markdown_lines.append(line.replace("â€¢", "-"))
                    in_list = True
                    continue

                # ì¼ë°˜ í…ìŠ¤íŠ¸
                if in_list:
                    markdown_lines.append("")
                    in_list = False
                markdown_lines.append(line)

            except Exception as line_e:
                logger.error(
                    f"ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì¤‘ ë¼ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {line} - {str(line_e)}\n{traceback.format_exc()}"
                )
                # ì˜¤ë¥˜ ë°œìƒ ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                markdown_lines.append(line)

        return "\n".join(markdown_lines)

    except Exception as e:
        logger.error(
            f"í…ìŠ¤íŠ¸ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}"
        )
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        return text


# def hwpx_to_hwp(hwpx_file, hwp_file=None):
#     """
#     hwpx â†’ hwp ë³€í™˜ (í•œ ì¤„ í˜¸ì¶œ)

#     Usage:
#         hwpx_to_hwp("ë¬¸ì„œ.hwpx")  # ìë™ìœ¼ë¡œ ë¬¸ì„œ.hwp ìƒì„±
#         hwpx_to_hwp("ë¬¸ì„œ.hwpx", "ê²°ê³¼.hwp")
#     """
#     try:
#         from pyhwpx import Hwp

#         if hwp_file is None:
#             hwp_file = hwpx_file.replace('.hwpx', '.hwp')

#         hwp = Hwp(visible=False)
#         hwp.open(hwpx_file)
#         hwp.save_as(hwp_file, format="HWP")
#         hwp.quit()

#         logger.info(f"âœ… {hwpx_file} â†’ {hwp_file}")
#         return True

#     except Exception as e:
#         logger.error(f"âŒ ì‹¤íŒ¨: {e}")
#         return False

# def hwpx_to_html(hwpx_file, html_file=None):
#     """
#     hwpx â†’ html ë³€í™˜ (í•œ ì¤„ í˜¸ì¶œ)

#     Usage:
#         hwpx_to_html("ë¬¸ì„œ.hwpx")  # ìë™ìœ¼ë¡œ ë¬¸ì„œ.html ìƒì„±
#         hwpx_to_html("ë¬¸ì„œ.hwpx", "ê²°ê³¼.html")
#     """
#     try:
#         from pyhwpx import Hwp

#         if html_file is None:
#             html_file = hwpx_file.replace('.hwpx', '.html')

#         hwp = Hwp(visible=False)
#         hwp.open(hwpx_file)
#         hwp.save_as(html_file, format="HTML")
#         hwp.quit()

#         logger.info(f"âœ… {hwpx_file} â†’ {html_file}")
#         return True

#     except Exception as e:
#         logger.error(f"âŒ ì‹¤íŒ¨: {e}")
#         return False


def convert_html_to_md_markitdown(html_path: str, output_path: str = None) -> bool:
    """
    HTML íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
        output_path (str, optional): ì¶œë ¥í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ.
            Noneì¸ ê²½ìš° PDF íŒŒì¼ê³¼ ë™ì¼í•œ ìœ„ì¹˜ì— ì €ì¥ë©ë‹ˆë‹¤.

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    try:
        try:
            from markitdown import MarkItDown
        except (ImportError, AttributeError) as e:
            logger.warning(f"MarkItDown import ì‹¤íŒ¨ (NumPy í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥): {e}")
            return False

        ## markitdown START ##
        md = MarkItDown(enable_plugins=False)
        result = md.convert(html_path)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(result.text_content)
        ## markitdown END ##

        logger.info(f"ë³€í™˜ ì™„ë£Œ: {output_path}")
        return True

    except Exception as e:
        logger.error(f"ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return False


def convert_pdf_to_html_pdfminder(pdf_path: str, output_path: str = None) -> bool:
    """
    PDF íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
        output_path (str, optional): ì¶œë ¥í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ.
            Noneì¸ ê²½ìš° PDF íŒŒì¼ê³¼ ë™ì¼í•œ ìœ„ì¹˜ì— ì €ì¥ë©ë‹ˆë‹¤.

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    try:
        from pdfminer.converter import HTMLConverter
        from pdfminer.layout import LAParams
        from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager
        from pdfminer.pdfpage import PDFPage

        rsrcmgr = PDFResourceManager()
        laparams = LAParams()

        # íŒŒì¼ë¡œ ë°”ë¡œ ì €ì¥
        with (
            open(pdf_path, "rb") as fp,
            open(output_path, "w", encoding="utf-8") as outfp,
        ):
            device = HTMLConverter(rsrcmgr, outfp, laparams=laparams)
            interpreter = PDFPageInterpreter(rsrcmgr, device)
            for page in PDFPage.get_pages(fp, check_extractable=True):
                interpreter.process_page(page)
            device.close()

        logger.info(f"ë³€í™˜ ì™„ë£Œ: {output_path}")
        return True

    except Exception as e:
        logger.error(f"ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n{traceback.format_exc()}")
        return False


def convert_pdf_to_text_simple(pdf_path: str, output_path: str = None) -> bool:
    """
    PDFMinerë¥¼ ì‚¬ìš©í•´ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê°„ë‹¨íˆ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
        output_path (str): ì¶œë ¥í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ìƒ‰ìƒ ì˜¤ë¥˜ë¥¼ ì™„ì „íˆ ë¬´ì‹œí•˜ëŠ” í™˜ê²½ ì„¤ì •
        import os

        os.environ["PDFMINER_IGNORE_COLOR_ERRORS"] = "1"

        # PDFMiner ì„¤ì •ìœ¼ë¡œ ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ ë°©ì§€
        from pdfminer.high_level import extract_text
        from pdfminer.layout import LAParams

        # ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ì„¤ì •
        laparams = LAParams(
            line_margin=0.5,
            word_margin=0.1,
            char_margin=2.0,
            boxes_flow=0.5,
            detect_vertical=True,
            all_texts=True,
        )

        # ìƒ‰ìƒ ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
        import warnings

        warnings.filterwarnings("ignore", category=UserWarning, module="pdfminer")
        warnings.filterwarnings("ignore", message=".*color.*", category=UserWarning)

        # ìƒ‰ìƒ ì˜¤ë¥˜ë¥¼ ì™„ì „íˆ ìš°íšŒí•˜ëŠ” íŒ¨ì¹˜ ì ìš©
        try:
            from pdfminer.pdfcolor import PDFColorSpace

            original_set_gray = PDFColorSpace.set_gray

            def safe_set_gray(self, gray):
                try:
                    return original_set_gray(self, gray)
                except (ValueError, TypeError):
                    # ìƒ‰ìƒ ì˜¤ë¥˜ ë¬´ì‹œ
                    return None

            PDFColorSpace.set_gray = safe_set_gray

            # ì¶”ê°€ ìƒ‰ìƒ ê´€ë ¨ ë©”ì„œë“œë“¤ë„ íŒ¨ì¹˜
            if hasattr(PDFColorSpace, "set_rgb"):
                original_set_rgb = PDFColorSpace.set_rgb

                def safe_set_rgb(self, r, g, b):
                    try:
                        return original_set_rgb(self, r, g, b)
                    except (ValueError, TypeError):
                        return None

                PDFColorSpace.set_rgb = safe_set_rgb

            if hasattr(PDFColorSpace, "set_cmyk"):
                original_set_cmyk = PDFColorSpace.set_cmyk

                def safe_set_cmyk(self, c, m, y, k):
                    try:
                        return original_set_cmyk(self, c, m, y, k)
                    except (ValueError, TypeError):
                        return None

                PDFColorSpace.set_cmyk = safe_set_cmyk

            # ìƒ‰ìƒ ê³µê°„ ì´ˆê¸°í™” ë©”ì„œë“œë„ íŒ¨ì¹˜
            if hasattr(PDFColorSpace, "__init__"):
                original_init = PDFColorSpace.__init__

                def safe_init(self, *args, **kwargs):
                    try:
                        return original_init(self, *args, **kwargs)
                    except (ValueError, TypeError):
                        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
                        self.name = "DeviceGray"
                        self.ncomponents = 1
                        return None

                PDFColorSpace.__init__ = safe_init

        except ImportError:
            pass  # PDFMiner ë²„ì „ì— ë”°ë¼ ì—†ì„ ìˆ˜ ìˆìŒ

        try:
            # ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ë¥¼ ë¬´ì‹œí•˜ê³  í…ìŠ¤íŠ¸ ì¶”ì¶œ
            try:
                text = extract_text(pdf_path, laparams=laparams)
            except Exception as color_error:
                # ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ì¸ì§€ í™•ì¸
                error_msg = str(color_error).lower()
                if any(
                    keyword in error_msg
                    for keyword in [
                        "color",
                        "gray",
                        "stroke",
                        "invalid float",
                        "p67",
                        "pa1",
                        "pa2",
                    ]
                ):
                    logger.warning(
                        f"ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€, ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„: {color_error}"
                    )
                    # ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„
                    text = extract_text(pdf_path, laparams=laparams, codec="utf-8")
                else:
                    raise color_error
        except Exception as page_error:
            logger.warning(
                f"PDFMiner í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ (ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŒ): {page_error}"
            )

            # ìƒ‰ìƒ ì˜¤ë¥˜ì¸ ê²½ìš° ë” ì•ˆì „í•œ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„
            try:
                from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager
                from pdfminer.converter import TextConverter
                from pdfminer.pdfpage import PDFPage
                import io
                import warnings

                # ìƒ‰ìƒ ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
                warnings.filterwarnings(
                    "ignore", category=UserWarning, module="pdfminer"
                )
                warnings.filterwarnings(
                    "ignore", message=".*color.*", category=UserWarning
                )
                warnings.filterwarnings(
                    "ignore", message=".*gray.*", category=UserWarning
                )
                warnings.filterwarnings(
                    "ignore", message=".*stroke.*", category=UserWarning
                )

                # ìƒ‰ìƒ ì²˜ë¦¬ë¥¼ ì™„ì „íˆ ë¹„í™œì„±í™”í•œ ì„¤ì •
                rsrcmgr = PDFResourceManager()
                retstr = io.StringIO()
                device = TextConverter(rsrcmgr, retstr, laparams=laparams)

                with open(pdf_path, "rb") as fp:
                    interpreter = PDFPageInterpreter(rsrcmgr, device)
                    for page in PDFPage.get_pages(fp, check_extractable=True):
                        try:
                            interpreter.process_page(page)
                        except Exception as page_ex:
                            # ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ì¸ì§€ í™•ì¸ (ë” í¬ê´„ì ìœ¼ë¡œ)
                            error_msg = str(page_ex).lower()
                            color_keywords = [
                                "color",
                                "gray",
                                "stroke",
                                "invalid float",
                                "p67",
                                "pa1",
                                "pa2",
                                "non-stroke",
                            ]
                            if any(keyword in error_msg for keyword in color_keywords):
                                logger.debug(
                                    f"ìƒ‰ìƒ ê´€ë ¨ ì˜¤ë¥˜ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰: {page_ex}"
                                )
                                continue
                            else:
                                logger.debug(f"í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë¬´ì‹œ: {page_ex}")
                                continue
                    device.close()
                    text = retstr.getvalue()
                    retstr.close()

                if not text.strip():
                    raise Exception("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")

            except Exception as fallback_error:
                logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                return False
        logger.debug(f"PDF ì›ë³¸ ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} ë¬¸ì")

        # í…ìŠ¤íŠ¸ ì •ë¦¬
        cleaned_text = text.strip()
        if len(cleaned_text) == 0:
            logger.warning(
                f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ - PDFê°€ ìŠ¤ìº”ëœ ì´ë¯¸ì§€ì´ê±°ë‚˜ ë³´í˜¸ëœ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {pdf_path}"
            )

            # ëŒ€ì•ˆì ì¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„
            try:
                logger.info("ëŒ€ì•ˆì ì¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„ ì¤‘...")
                import PyPDF2

                with open(pdf_path, "rb") as file:
                    reader = PyPDF2.PdfReader(file)
                    alt_text = ""
                    for page_num in range(len(reader.pages)):
                        page = reader.pages[page_num]
                        alt_text += page.extract_text() + "\n"

                    if alt_text.strip():
                        cleaned_text = alt_text.strip()
                        logger.info(
                            f"PyPDF2ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {len(cleaned_text)} ë¬¸ì"
                        )
                    else:
                        logger.warning("PyPDF2ë¡œë„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
                        return False

            except ImportError:
                logger.warning("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - pip install PyPDF2")
                return False
            except Exception as alt_error:
                logger.error(f"ëŒ€ì•ˆì ì¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {alt_error}")
                return False

        # ê¸¸ì´ ì œí•œ ì œê±° - ëª¨ë“  í…ìŠ¤íŠ¸ í—ˆìš©
        logger.debug(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(cleaned_text)} ë¬¸ì")

        # output_path ë¯¸ì§€ì • ì‹œ í…ìŠ¤íŠ¸ ì§ì ‘ ë°˜í™˜
        if output_path is None:
            return cleaned_text

        # íŒŒì¼ë¡œ ì €ì¥ (output_path ì§€ì •ëœ ê²½ìš°)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(cleaned_text)

        # ProcessedDataManagerê°€ ì´ì œ í…ìŠ¤íŠ¸ ì €ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤

        # ì •ë¦¬ - high-level API ì‚¬ìš©ì‹œ ë³„ë„ ì •ë¦¬ ë¶ˆí•„ìš”

        logger.info(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {output_path} ({len(cleaned_text)} ë¬¸ì)")
        return True

    except Exception as e:
        logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}\n{traceback.format_exc()}")
        return "" if output_path is None else False


# marker-pdf í•¨ìˆ˜ ì œê±°ë¨ - ì²˜ë¦¬ ì†ë„ ë¬¸ì œë¡œ ë¹„í™œì„±í™”


def convert_pdf_with_ocr(pdf_path: str, output_path: str = None) -> bool:
    """
    PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ê³  OCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
        output_path (str): ì¶œë ¥í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì œì™¸í•  í‚¤ì›Œë“œ ê²€ì‚¬
        if should_exclude_file(Path(pdf_path)):
            return False

        logger.info(f"PDF OCR ì²˜ë¦¬ ì‹œì‘: {pdf_path}")

        # PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
        images = extract_images_from_pdf(pdf_path)
        if not images:
            logger.warning(f"PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_path}")
            return False

        # OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        markdown_content = []
        markdown_content.append("# PDF OCR ì²˜ë¦¬ ê²°ê³¼\n")

        for i, image in enumerate(images):
            logger.info(f"ì´ë¯¸ì§€ {i+1}/{len(images)} OCR ì²˜ë¦¬ ì¤‘...")

            # OCR ì²˜ë¦¬
            text = perform_ocr_on_image(image)
            if text and len(text.strip()) > 10:
                markdown_content.append(f"## í˜ì´ì§€ {i+1}\n")
                markdown_content.append(f"{text}\n\n")

        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
        if (
            markdown_content and len(markdown_content) > 1
        ):  # í—¤ë” ì™¸ì— ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
            with open(output_path, "w", encoding="utf-8") as f:
                f.write("\n".join(markdown_content))

            logger.info(f"PDF OCR ë³€í™˜ ì™„ë£Œ: {output_path}")
            return True
        else:
            logger.warning(f"OCR ê²°ê³¼ê°€ ë¶€ì¡±í•¨: {pdf_path}")
            return False

    except Exception as e:
        logger.warning(f"PDF OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def extract_images_from_pdf(pdf_path: str) -> list:
    """
    PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): PDF íŒŒì¼ ê²½ë¡œ

    Returns:
        list: ì¶”ì¶œëœ ì´ë¯¸ì§€ ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    try:
        import fitz  # PyMuPDF

        images = []
        doc = fitz.open(pdf_path)

        for page_num in range(len(doc)):
            page = doc.load_page(page_num)

            # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í•´ìƒë„ ë†’ê²Œ)
            mat = fitz.Matrix(2.0, 2.0)  # 2ë°° í™•ëŒ€
            pix = page.get_pixmap(matrix=mat)

            # PIL Imageë¡œ ë³€í™˜
            import io

            from PIL import Image

            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))
            images.append(image)

        doc.close()
        logger.info(f"PDFì—ì„œ {len(images)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ")
        return images

    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []


def perform_ocr_on_image(image) -> str:
    """
    ì´ë¯¸ì§€ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        image: PIL Image ê°ì²´

    Returns:
        str: ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    # 1ì°¨ ì‹œë„: EasyOCR (ìš°ì„ ìˆœìœ„ 1)
    try:
        import easyocr
        import numpy as np

        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        img_array = np.array(image)

        # EasyOCR ë¦¬ë” ì´ˆê¸°í™” (í•œêµ­ì–´ + ì˜ì–´)
        logger.info("EasyOCR ì‹¤í–‰ ì¤‘... (ìš°ì„ ìˆœìœ„ 1)")
        reader = easyocr.Reader(["ko", "en"], gpu=True)  # GPU ì‚¬ìš© í™œì„±í™”

        # OCR ìˆ˜í–‰
        results = reader.readtext(img_array)

        # ê²°ê³¼ ì •ë¦¬
        lines = []
        for bbox, text, confidence in results:
            if confidence > 0.2 and len(text.strip()) > 1:  # ì‹ ë¢°ë„ 30% ì´ìƒ (ì§€ì—­ëª… ë“± í¬í•¨)
                lines.append(text.strip())

        if lines:
            cleaned_text = "\n".join(lines)  # ì¤„ë°”ê¿ˆìœ¼ë¡œ ê²°í•©í•˜ì—¬ ë ˆì´ì•„ì›ƒ ë³´ì¡´

            # í‘œ í˜•íƒœ ê°ì§€ ë° ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜ ì‹œë„
            if "|" in cleaned_text or "\t" in cleaned_text:
                cleaned_text = format_as_markdown_table(cleaned_text)

            logger.info(f"EasyOCR ì„±ê³µ: {len(lines)}ê°œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            return cleaned_text

    except Exception as e:
        logger.warning(f"EasyOCR ì‹¤íŒ¨, Tesseractë¡œ í´ë°±: {e}")

    # 2ì°¨ ì‹œë„: Tesseract OCR (í´ë°±)
    try:
        import pytesseract

        logger.info("Tesseract OCR ì‹¤í–‰ ì¤‘... (í´ë°±)")
        # í•œêµ­ì–´ + ì˜ì–´ OCR ì²˜ë¦¬
        text = pytesseract.image_to_string(image, lang="kor+eng")

        if text and len(text.strip()) > 10:
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            lines = []
            for line in text.split("\n"):
                line = line.strip()
                if line and len(line) > 1:  # ì˜ë¯¸ìˆëŠ” ì¤„ë§Œ ì¶”ê°€
                    lines.append(line)

            # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
            cleaned_text = "\n".join(lines)

            # í‘œ í˜•íƒœ ê°ì§€ ë° ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜ ì‹œë„
            if "|" in cleaned_text or "\t" in cleaned_text:
                cleaned_text = format_as_markdown_table(cleaned_text)

            logger.info(f"Tesseract í´ë°± ì„±ê³µ: {len(lines)}ê°œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            return cleaned_text

    except Exception as e:
        logger.warning(f"Tesseract OCR í´ë°± ì‹¤íŒ¨: {e}")

    logger.error("ëª¨ë“  OCR ë°©ë²• ì‹¤íŒ¨")
    return ""


def markdown_to_plain_text(markdown_content: str) -> str:
    """
    ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ë¥¼ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    extracted_text.txt íŒŒì¼ì—ëŠ” ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì´ ì œê±°ëœ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.

    Args:
        markdown_content: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í…ìŠ¤íŠ¸

    Returns:
        ìˆœìˆ˜ í…ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±°)
    """
    if not markdown_content:
        return ""

    text = markdown_content

    # ì½”ë“œ ë¸”ë¡ ì œê±° (``` ë˜ëŠ” ~~~ ë¸”ë¡)
    text = re.sub(r"```[\s\S]*?```", "", text)
    text = re.sub(r"~~~[\s\S]*?~~~", "", text)

    # ì¸ë¼ì¸ ì½”ë“œ ì œê±° (`code`)
    text = re.sub(r"`([^`]+)`", r"\1", text)

    # í—¤ë” ë§ˆí¬ë‹¤ìš´ ì œê±° (# ## ### ë“±)
    text = re.sub(r"^#{1,6}\s+", "", text, flags=re.MULTILINE)

    # ë³¼ë“œ/ì´íƒ¤ë¦­ ë§ˆí¬ë‹¤ìš´ ì œê±° (**text**, *text*, __text__, _text_)
    text = re.sub(r"\*\*([^*]+)\*\*", r"\1", text)  # **bold**
    text = re.sub(r"\*([^*]+)\*", r"\1", text)  # *italic*
    text = re.sub(r"__([^_]+)__", r"\1", text)  # __bold__
    text = re.sub(r"_([^_]+)_", r"\1", text)  # _italic_

    # ë§í¬ ë§ˆí¬ë‹¤ìš´ ì œê±° [text](url)
    text = re.sub(r"\[([^\]]+)\]\([^)]+\)", r"\1", text)

    # ì´ë¯¸ì§€ ë§ˆí¬ë‹¤ìš´ ì œê±° ![alt](url)
    text = re.sub(r"!\[([^\]]*)\]\([^)]+\)", r"\1", text)

    # ë¦¬ìŠ¤íŠ¸ ë§ˆì»¤ ì œê±° (- * + 1. 2. ë“±)
    text = re.sub(r"^[\s]*[-*+]\s+", "", text, flags=re.MULTILINE)  # - * +
    text = re.sub(r"^\s*\d+\.\s+", "", text, flags=re.MULTILINE)  # 1. 2. 3.

    # ì¸ìš©ë¬¸ ë§ˆí¬ë‹¤ìš´ ì œê±° (> text)
    text = re.sub(r"^>\s*", "", text, flags=re.MULTILINE)

    # ìˆ˜í‰ì„  ì œê±° (---, ***, ___)
    text = re.sub(r"^[-*_]{3,}\s*$", "", text, flags=re.MULTILINE)

    # í…Œì´ë¸” êµ¬ë¶„ì ì œê±° (|-----|-----|)
    text = re.sub(r"^\|[-:\s|]+\|\s*$", "", text, flags=re.MULTILINE)

    # í…Œì´ë¸” íŒŒì´í”„ ì œê±° (| cell | cell |)
    text = re.sub(r"^\|(.+)\|\s*$", r"\1", text, flags=re.MULTILINE)
    text = re.sub(r"\|", " ", text)  # ë‚¨ì€ íŒŒì´í”„ë“¤ì„ ê³µë°±ìœ¼ë¡œ

    # ì—¬ëŸ¬ ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
    text = re.sub(r"\s+", " ", text)

    # ì—¬ëŸ¬ ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ ìµœëŒ€ 2ê°œë¡œ ì œí•œ
    text = re.sub(r"\n\s*\n\s*\n+", "\n\n", text)

    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()

    return text


def format_as_markdown_table(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì‹œë„

    Args:
        text (str): ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ë˜ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸
    """
    try:
        lines = text.split("\n")
        table_lines = []

        for line in lines:
            if "|" in line or "\t" in line:
                # êµ¬ë¶„ìë¡œ ë¶„í• 
                if "\t" in line:
                    cols = [col.strip() for col in line.split("\t") if col.strip()]
                else:
                    cols = [col.strip() for col in line.split("|") if col.strip()]

                if len(cols) > 1:
                    table_lines.append("| " + " | ".join(cols) + " |")

        if len(table_lines) > 1:
            # í—¤ë”ì™€ êµ¬ë¶„ì„  ì¶”ê°€
            header = table_lines[0]
            separator = "|" + "---|" * (header.count("|") - 1)

            return header + "\n" + separator + "\n" + "\n".join(table_lines[1:])

        return text

    except Exception:
        return text


def _convert_hwp_with_gethwp(hwp_file_path: Path, output_dir: Path) -> bool:
    """
    gethwp.read_hwp()ë¥¼ ì‚¬ìš©í•˜ì—¬ HWP íŒŒì¼ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜.
    êµ¬í˜• HWP í¬ë§·(HWP 3.0, HWP 96 ë“±)ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        hwp_file_path: HWP íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
    """
    try:
        # HWP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì—° ë¡œë”©
        hwp_libs = get_hwp_libraries()
        hwp_custom = hwp_libs["hwp_custom"]

        # hwp_custom.read_hwp() í˜¸ì¶œ (gethwp.read_hwp()ë¥¼ ë˜í•‘)
        hwp_text = hwp_custom.read_hwp(str(hwp_file_path))

        if hwp_text and hwp_text.strip():
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ HTML í˜•íƒœë¡œ ì €ì¥
            import html

            html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{hwp_file_path.stem}</title>
</head>
<body>
    <pre>{html.escape(hwp_text)}</pre>
</body>
</html>"""
            # output_dir ìƒì„± ë° index.xhtml ì €ì¥
            output_dir.mkdir(parents=True, exist_ok=True)
            html_file = output_dir / "index.xhtml"
            with open(html_file, "w", encoding="utf-8") as f:
                f.write(html_content)
            logger.info(
                f"gethwp.read_hwp() ë³€í™˜ ì„±ê³µ: {hwp_file_path.name} â†’ {html_file}"
            )
            return True
        else:
            logger.debug(
                f"gethwp.read_hwp() í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {hwp_file_path.name}"
            )
            return False
    except Exception as e:
        logger.debug(
            f"gethwp.read_hwp() ì‹¤íŒ¨: {hwp_file_path.name} - {e}"
        )
        return False


def _convert_hwpx_file_to_html(hwpx_file_path: Path, output_dir: Path) -> bool:
    """
    HWPX íŒŒì¼ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜.

    Args:
        hwpx_file_path: HWPX íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
    """
    try:
        hwpx_text = convert_hwpx_to_text(hwpx_file_path)
        if hwpx_text and hwpx_text.strip():
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ HTML í˜•íƒœë¡œ ì €ì¥
            import html

            html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{hwpx_file_path.stem}</title>
</head>
<body>
    <pre>{html.escape(hwpx_text)}</pre>
</body>
</html>"""
            # output_dir ìƒì„± ë° index.xhtml ì €ì¥
            output_dir.mkdir(parents=True, exist_ok=True)
            html_file = output_dir / "index.xhtml"
            with open(html_file, "w", encoding="utf-8") as f:
                f.write(html_content)
            logger.info(
                f"HWPX íŒŒì¼ ë³€í™˜ ì„±ê³µ: {hwpx_file_path.name} â†’ {html_file}"
            )
            return True
        else:
            logger.warning(
                f"HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {hwpx_file_path.name}"
            )
            return False
    except Exception as e:
        logger.warning(
            f"HWPX ë³€í™˜ ì‹¤íŒ¨: {hwpx_file_path.name} - {e}"
        )
        return False


def convert_hwp_to_html(hwp_file_path: Path, output_dir: Path) -> bool:
    """
    HWP/HWPX íŒŒì¼ì„ HTML í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•©ë‹ˆë‹¤:

    .hwpx íŒŒì¼:
        â†’ HWPX ì²˜ë¦¬ (hwp_custom.read_hwpx)

    .hwp íŒŒì¼ (3ë‹¨ê³„ fallback):
        1ë‹¨ê³„: HWP5 (hwp5 ë¼ì´ë¸ŒëŸ¬ë¦¬) ì‹œë„
        2ë‹¨ê³„: gethwp.read_hwp() ì‹œë„ (êµ¬í˜• HWP)
        3ë‹¨ê³„: HWPX fallback (ì˜ëª»ëœ í™•ì¥ì ì²˜ë¦¬)

    Args:
        hwp_file_path (Path): ë³€í™˜í•  HWP/HWPX íŒŒì¼ì˜ ê²½ë¡œ. pathlib.Path ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
        output_dir (Path): ë³€í™˜ëœ íŒŒì¼ë“¤ì´ ì €ì¥ë  ì¶œë ¥ ë””ë ‰í† ë¦¬. pathlib.Path ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False.
    """
    # Heavy libraries - lazy import for performance
    from hwp5.dataio import ParseError
    from hwp5.errors import InvalidHwp5FileError
    from hwp5.hwp5html import HTMLTransform
    from hwp5.xmlmodel import Hwp5File

    if not hwp_file_path.exists():
        logger.error(f"ì˜¤ë¥˜: HWP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hwp_file_path}")
        return False

    if not hwp_file_path.is_file():
        logger.error(f"ì˜¤ë¥˜: '{hwp_file_path}'ì€(ëŠ”) íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return False

    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_ext = hwp_file_path.suffix.lower()
    if file_ext not in [".hwp", ".hwpx"]:
        logger.error(
            f"ì˜¤ë¥˜: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í™•ì¥ì: {hwp_file_path.name} (í™•ì¥ì: {file_ext})"
        )
        return False

    # íŒŒì¼ í¬ê¸° í™•ì¸ (ë„ˆë¬´ í° íŒŒì¼ì€ ì œí•œ)
    file_size = hwp_file_path.stat().st_size
    max_size = 50 * 1024 * 1024  # 50MB ì œí•œ
    if file_size > max_size:
        logger.warning(
            f"HWP íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {file_size / 1024 / 1024:.1f}MB (ìµœëŒ€ {max_size / 1024 / 1024}MB)"
        )
        return False

    try:
        with Timer(f"HWP íŒŒì¼ ë³€í™˜: {hwp_file_path.name}", totalTimeChk=False):
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„ (HWP ë³€í™˜ íŒŒì¼ê³¼ llm_responseë§Œ ì‚­ì œ, extracted_text.txtëŠ” ë³´ì¡´)
            if output_dir.exists():
                try:
                    deleted_count = 0
                    # HWP ë³€í™˜ ê´€ë ¨ íŒŒì¼ë§Œ ì„ íƒì  ì‚­ì œ
                    for file_pattern in [
                        "*.xhtml",
                        "*.css",
                        "*.html",
                        "llm_response_*.json",
                    ]:
                        for file in output_dir.glob(file_pattern):
                            file.unlink()
                            deleted_count += 1

                    if deleted_count > 0:
                        logger.debug(
                            f"ê¸°ì¡´ HWP ë³€í™˜ íŒŒì¼ {deleted_count}ê°œ ì‚­ì œ, extracted_text.txtëŠ” ë³´ì¡´"
                        )
                    else:
                        logger.debug(f"ì‚­ì œí•  HWP ë³€í™˜ íŒŒì¼ ì—†ìŒ")
                except OSError as e:
                    logger.error(f"ì˜¤ë¥˜: HWP ë³€í™˜ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{output_dir}': {e}")
                    return False

            output_dir.mkdir(parents=True, exist_ok=True)
            logger.debug(f"ìƒˆ ì¶œë ¥ ë””ë ‰í† ë¦¬ '{output_dir}'ì„(ë¥¼) ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

            # í™•ì¥ìì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            if file_ext == ".hwpx":
                # HWPX íŒŒì¼ ì²˜ë¦¬
                logger.debug(f"HWPX íŒŒì¼ ì²˜ë¦¬: {hwp_file_path.name}")
                return _convert_hwpx_file_to_html(hwp_file_path, output_dir)
            else:
                # .hwp íŒŒì¼ ì²˜ë¦¬: HWP5 â†’ gethwp.read_hwp â†’ HWPX fallback (3ë‹¨ê³„)
                logger.debug(f"HWP íŒŒì¼ ì²˜ë¦¬: {hwp_file_path.name}")

                # 1ë‹¨ê³„: HWP5 (OLE2) í¬ë§· ì‹œë„
                try:
                    with closing(Hwp5File(str(hwp_file_path))) as hwp5file:
                        # íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ì—´ë¦¬ëŠ”ì§€ í™•ì¸
                        if not hasattr(hwp5file, "header"):
                            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ HWP5 íŒŒì¼ êµ¬ì¡°: {hwp_file_path}")
                        else:
                            logger.debug(f"HWP5 íŒŒì¼ ì½ê¸° ì‹œì‘: {hwp_file_path.name}")

                            # HTMLTransform ê°ì²´ ìƒì„± ë° ë³€í™˜
                            html_transform = HTMLTransform()
                            html_transform.transform_hwp5_to_dir(hwp5file, str(output_dir))

                            # ë³€í™˜ ê²°ê³¼ í™•ì¸
                            index_file = output_dir / "index.xhtml"
                            if index_file.exists() and index_file.stat().st_size > 0:
                                logger.info(f"HWP5 íŒŒì¼ ë³€í™˜ ì„±ê³µ: {hwp_file_path.name}")
                                return True
                            else:
                                logger.warning(
                                    f"HWP5 ë³€í™˜ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ: {index_file}"
                                )

                except (ParseError, InvalidHwp5FileError) as e:
                    logger.info(f"HWP5 í¬ë§· ì•„ë‹˜ (2ë‹¨ê³„ fallback ì§„í–‰): {hwp_file_path.name}")
                    logger.debug(f"HWP5 ì˜¤ë¥˜ ìƒì„¸: {e}")

                try:
                    # 2ë‹¨ê³„: gethwp.read_hwp() ì‹œë„ (êµ¬í˜• HWP í¬ë§·)
                    logger.info(f"gethwp.read_hwp() ì‹œë„: {hwp_file_path.name}")
                    hwp_text_result = _convert_hwp_with_gethwp(hwp_file_path, output_dir)
                    if hwp_text_result:
                        return True

                    # 3ë‹¨ê³„: HWPX fallback ì‹œë„ (.hwp í™•ì¥ìì§€ë§Œ ì‹¤ì œë¡œëŠ” HWPXì¼ ê°€ëŠ¥ì„±)
                    logger.info(f"HWPX fallback ì‹œë„: {hwp_file_path.name}")
                    return _convert_hwpx_file_to_html(hwp_file_path, output_dir)
                except Exception as transform_error:
                    # XML íŒŒì‹± ì˜¤ë¥˜ êµ¬ì²´ì  ì²˜ë¦¬
                    import xml.parsers.expat

                    if isinstance(transform_error, xml.parsers.expat.ExpatError):
                        logger.error(f"XML íŒŒì‹± ì˜¤ë¥˜: {hwp_file_path.name}")
                        logger.error(
                            f"  ì˜¤ë¥˜ ìœ„ì¹˜: line {getattr(transform_error, 'lineno', '?')}, column {getattr(transform_error, 'offset', '?')}"
                        )
                        logger.error(f"  ì˜¤ë¥˜ ë©”ì‹œì§€: {transform_error}")
                        logger.warning(
                            "  â†’ XML ì†ì„±ê°’ì— ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                        )
                    else:
                        logger.error(
                            f"HWP ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {hwp_file_path.name} - {transform_error}"
                        )
                    return False

    except MemoryError:
        logger.error(f"HWP íŒŒì¼ ë³€í™˜ ì¤‘ ë©”ëª¨ë¦¬ ë¶€ì¡±: {hwp_file_path.name}")
        return False
    except TimeoutError:
        logger.error(f"HWP íŒŒì¼ ë³€í™˜ ì‹œê°„ ì´ˆê³¼: {hwp_file_path.name}")
        return False
    except Exception as e:
        logger.error(f"HWP íŒŒì¼ ë³€í™˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {hwp_file_path.name} - {e}")
        logger.error(f"íŒŒì¼ ë¬¼ë¦¬ ê²½ë¡œ: {hwp_file_path.absolute()}")
        logger.debug(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return False


def convert_file_to_text(file_path: Path, file_type: str) -> str | None:
    """
    íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ë³€í™˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        file_path (Path): ë³€í™˜í•  íŒŒì¼ ê²½ë¡œ
        file_type (str): íŒŒì¼ íƒ€ì… ('pdf', 'hwp', 'hwpx')

    Returns:
        Optional[str]: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´. ì‹¤íŒ¨ ì‹œ None.
    """

    logger.info("convert_file_to_text")

    try:
        if file_type.lower() == "pdf":
            # PDF íŒŒì¼ ì²˜ë¦¬
            from tempfile import NamedTemporaryFile

            with NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as temp_file:
                temp_path = temp_file.name

            success = convert_pdf_to_text_simple(str(file_path), temp_path)
            if success:
                with open(temp_path, encoding="utf-8") as f:
                    text = f.read()
                os.unlink(temp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                return text
            else:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                return None

        elif file_type.lower() == "hwpx":
            # HWPX íŒŒì¼ ì²˜ë¦¬
            return convert_hwpx_to_text(file_path)

        elif file_type.lower() == "hwp":
            # HWP íŒŒì¼ ì²˜ë¦¬ - ê¸°ì¡´ ë¡œì§ í™œìš©
            from tempfile import NamedTemporaryFile

            with NamedTemporaryFile(mode="w", suffix=".md", delete=False) as temp_file:
                temp_path = temp_file.name

            success = convert_hwp_to_markdown(file_path, Path(temp_path))
            if success:
                with open(temp_path, encoding="utf-8") as f:
                    text = f.read()
                os.unlink(temp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                return text
            else:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                return None
        else:
            logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}")
            return None

    except Exception as e:
        logger.error(f"íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {file_path.name} ({file_type}) - {e}")
        return None


def convert_hwp_to_markdown(hwp_file_path: Path, output_path: Path) -> bool:
    """
    HWP íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    HTML ë³€í™˜ì„ ìš°ì„  ì‹œë„í•˜ê³ , í‚¤ë¦´ ë¬¸ì ê°ì§€ ì‹œ hwp5txtë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.

    ë³€í™˜ ìˆœì„œ:
    1. HTML ë³€í™˜ (hwp5html â†’ MarkItDown)
       â†’ í‚¤ë¦´ ë¬¸ì ê°ì§€ ì‹œ: hwp5txtë¡œ ì¬ë³€í™˜ ì‹œë„
    2. MarkItDown (fallback)
    3. ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (gethwp)

    Args:
        hwp_file_path: ë³€í™˜í•  HWP íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥í•  Markdown íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ë³€í™˜ ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
    """

    logger.info("!!!!!!!!convert_hwp_to_markdown!!!!!!!!")
    try:
        if not hwp_file_path.exists():
            logger.error(f"HWP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hwp_file_path}")
            return False

        # .hwpx íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ì²˜ë¦¬
        if hwp_file_path.suffix.lower() == ".hwpx":
            logger.info(f"HWPX íŒŒì¼ ì²˜ë¦¬: {hwp_file_path.name}")
            try:
                hwpx_text = convert_hwpx_to_text(hwp_file_path)
                if hwpx_text and hwpx_text.strip():
                    with open(output_path, "w", encoding="utf-8") as f:
                        f.write(hwpx_text)
                    logger.info(
                        f"HWPX íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {hwp_file_path.name} â†’ {output_path.name}"
                    )
                    return True
                else:
                    logger.warning(f"HWPX íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {hwp_file_path.name}")
                    return False
            except Exception as e:
                logger.error(f"HWPX íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {hwp_file_path.name} - {e}")
                return False

        # .hwp í™•ì¥ìì§€ë§Œ OLE2 ì„œëª…ì´ ì•„ë‹Œ ê²½ìš°(HWPXë¡œ ì˜ëª» ì €ì¥ëœ ì‚¬ë¡€) ìš°ì„  ì²˜ë¦¬
        try:
            if hwp_file_path.suffix.lower() == ".hwp" and not is_valid_hwp_file(
                hwp_file_path
            ):
                logger.warning(
                    f"HWP íŒŒì¼ì´ OLE2 ì‹œê·¸ë‹ˆì²˜ê°€ ì•„ë‹˜(ì‹¤ì œëŠ” HWPXì¼ ê°€ëŠ¥ì„±): {hwp_file_path.name}"
                )
                # HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„ í›„, ê²°ê³¼ë¥¼ Markdown íŒŒì¼ë¡œ ì €ì¥
                hwpx_text = convert_hwpx_to_text(hwp_file_path)
                if hwpx_text and hwpx_text.strip():
                    with open(output_path, "w", encoding="utf-8") as f:
                        f.write(hwpx_text)
                    logger.info(
                        f"HWPX-ìœ ì‚¬ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {hwp_file_path.name} â†’ {output_path.name}"
                    )
                    return True
                else:
                    logger.warning(
                        f"HWPX-ìœ ì‚¬ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {hwp_file_path.name} â€” ì¼ë°˜ ê²½ë¡œë¡œ ê³„ì†"
                    )
        except Exception as sig_check_error:
            logger.debug(f"HWP ì„œëª… ì ê²€ ì¤‘ ì˜¤ë¥˜(ë¬´ì‹œ): {sig_check_error}")

        # 1ì°¨ ì‹œë„: HTML ë³€í™˜
        try:
            from tempfile import TemporaryDirectory

            with TemporaryDirectory() as temp_dir:
                temp_output_dir = Path(temp_dir)
                if convert_hwp_to_html(hwp_file_path, temp_output_dir):
                    html_file = temp_output_dir / "index.xhtml"
                    logger.info(f"HWP HTML path: {temp_output_dir}")
                    if html_file.exists():
                        content = read_html_file(html_file)
                        if content and len(content.strip()) > 50:
                            # í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ ê²€ì¦
                            has_issue, message = has_cyrillic_encoding_issue(content)
                            if has_issue:
                                logger.warning(
                                    f"HTML ë³€í™˜ ì‹œ í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ ê°ì§€: {hwp_file_path.name} - {message}"
                                )
                                # hwp5txtë¡œ ì¬ì‹œë„
                                logger.info(f"hwp5txtë¡œ ì¬ë³€í™˜ ì‹œë„: {hwp_file_path.name}")
                                try:
                                    import subprocess
                                    result = subprocess.run(
                                        ['hwp5txt', str(hwp_file_path)],
                                        capture_output=True,
                                        timeout=30,
                                        check=False
                                    )

                                    if result.returncode == 0:
                                        text = result.stdout.decode('utf-8', errors='replace')

                                        if text and len(text.strip()) > 50:
                                            # í‚¤ë¦´ ë¬¸ì ì¬ê²€ì¦
                                            has_issue_retry, message_retry = has_cyrillic_encoding_issue(text)

                                            if not has_issue_retry:
                                                # í…ìŠ¤íŠ¸ ì •ë¦¬
                                                from src.utils.textCleaner import clean_extracted_text
                                                cleaned_text = clean_extracted_text(text)

                                                with open(output_path, "w", encoding="utf-8") as f:
                                                    f.write(cleaned_text)

                                                logger.info(
                                                    f"hwp5txt ì¬ë³€í™˜ ì„±ê³µ (í‚¤ë¦´ ë¬¸ì œ í•´ê²°): {hwp_file_path.name} â†’ {output_path.name}"
                                                )
                                                return True
                                            else:
                                                logger.warning(
                                                    f"hwp5txt ì¬ë³€í™˜ì—ë„ í‚¤ë¦´ ë¬¸ì ë°œê²¬: {message_retry}, ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ fallback"
                                                )
                                                # hwp5txtë„ ì‹¤íŒ¨ - ë‹¤ìŒ ë³€í™˜ ë°©ë²• ì‹œë„
                                                raise Exception(f"hwp5txtë„ í‚¤ë¦´ ë¬¸ì ë¬¸ì œ: {message_retry}")
                                except Exception as retry_error:
                                    logger.warning(f"hwp5txt ì¬ë³€í™˜ ì‹¤íŒ¨: {retry_error}, ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ fallback")
                                    # HTML ë³€í™˜ë„ ì‹¤íŒ¨, hwp5txtë„ ì‹¤íŒ¨ - ë‹¤ìŒ ë³€í™˜ ë°©ë²•(MarkItDown, gethwp)ìœ¼ë¡œ ë„˜ì–´ê°
                                    # HTML ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì˜ˆì™¸ ë°œìƒì‹œì¼œ ë‹¤ìŒ ë°©ë²• ì‹œë„
                                    raise
                            else:
                                # í‚¤ë¦´ ë¬¸ì ë¬¸ì œ ì—†ìŒ - HTML ê²°ê³¼ ì‚¬ìš©
                                with open(output_path, "w", encoding="utf-8") as f:
                                    f.write(content)
                                logger.info(
                                    f"HWP HTML ë³€í™˜ ì„±ê³µ: {hwp_file_path.name} -> {output_path.name} ->{output_path}"
                                )
                                return True
        except Exception as e:
            logger.info(f"HTML ë³€í™˜ ì‹¤íŒ¨: {e}")

        # 3ì°¨ ì‹œë„: MarkItDown ë³€í™˜ (HWPëŠ” ì§€ì›í•˜ì§€ ì•Šì§€ë§Œ ì‹œë„)
        try:
            try:
                from markitdown import MarkItDown
                markitdown = MarkItDown()
            except (ImportError, AttributeError) as e:
                logger.warning(f"MarkItDown import ì‹¤íŒ¨ (NumPy í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥): {e}")
                raise ImportError("MarkItDown ì‚¬ìš© ë¶ˆê°€")
            result = markitdown.convert(str(hwp_file_path))

            if result and result.text_content:
                # í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ ê²€ì¦
                has_issue, message = has_cyrillic_encoding_issue(result.text_content)
                if has_issue:
                    logger.warning(
                        f"MarkItDown ë³€í™˜ ì‹œ í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ ê°ì§€: {hwp_file_path.name} - {message}"
                    )
                    # ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ fallback
                    raise ValueError(f"Cyrillic encoding issue: {message}")

                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(result.text_content)
                logger.info(
                    f"HWP MarkItDown ë³€í™˜ ì„±ê³µ: {hwp_file_path.name} -> {output_path.name}"
                )
                return True
        except Exception as e:
            logger.info(f"MarkItDown ë³€í™˜ ì‹¤íŒ¨: {e}")

        # 3ì°¨ ì‹œë„: ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ëŒ€ì²´ ë°©ë²•)
        try:
            text_content = extract_hwp_text_fallback(hwp_file_path)
            if text_content:
                # í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ ê²€ì¦
                has_issue, message = has_cyrillic_encoding_issue(text_content)
                if has_issue:
                    logger.error(
                        f"ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œ í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ ê°ì§€: {hwp_file_path.name} - {message}"
                    )
                    # ë¬¸ì œê°€ ìˆì–´ë„ ì €ì¥ì€ í•˜ë˜, ì—ëŸ¬ ë¡œê·¸ ë‚¨ê¹€

                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(text_content)
                logger.info(
                    f"HWP ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {hwp_file_path.name} -> {output_path.name}"
                )
                return True
        except Exception as e:
            logger.warning(f"HWP ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        return False

    except Exception as e:
        logger.error(f"HWP íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {hwp_file_path} - {e}")
        return False


def convert_hwpx_to_text(hwpx_file_path: Path) -> str | None:
    """
    HWPX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    gethwp ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ HWPX íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        hwpx_file_path (Path): ë³€í™˜í•  HWPX íŒŒì¼ì˜ ê²½ë¡œ.

    Returns:
        Optional[str]: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´. ì‹¤íŒ¨ ì‹œ None.
    """
    if not isinstance(hwpx_file_path, Path):
        logger.error(
            f"ì˜¤ë¥˜: 'hwpx_file_path'ëŠ” pathlib.Path ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ íƒ€ì…: {type(hwpx_file_path)}"
        )
        return None

    # ì œì™¸ íŒŒì¼ ì²´í¬ (ì²¨ë¶€ë¬¸ì„œ, ì‹ ì²­ì„œ ë“±)
    if should_exclude_file(hwpx_file_path):
        logger.info(f"HWPX íŒŒì¼ ì œì™¸ë¨: {hwpx_file_path.name}")
        return None

    if not hwpx_file_path.exists() or not hwpx_file_path.is_file():
        logger.error(
            f"ì˜¤ë¥˜: HWPX íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {hwpx_file_path}"
        )
        return None

    # íŒŒì¼ í¬ê¸° í™•ì¸ (ë„ˆë¬´ í° íŒŒì¼ì€ ì œí•œ)
    file_size = hwpx_file_path.stat().st_size
    max_size = 30 * 1024 * 1024  # 30MB ì œí•œ
    if file_size > max_size:
        logger.warning(
            f"HWPX íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {file_size / 1024 / 1024:.1f}MB (ìµœëŒ€ {max_size / 1024 / 1024}MB)"
        )
        return None

    logger.debug(f"HWPX íŒŒì¼ '{hwpx_file_path.name}'ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    try:
        with Timer(f"HWPX íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ: {hwpx_file_path.name}", totalTimeChk=False):
            # HWP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì—° ë¡œë”©
            hwp_libs = get_hwp_libraries()
            gethwp = hwp_libs["gethwp"]

            # gethwpë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            extracted_text = gethwp.read_hwpx(str(hwpx_file_path))

            if isinstance(extracted_text, str) and extracted_text.strip():
                # í…ìŠ¤íŠ¸ ì •ë¦¬
                cleaned_text = extracted_text.strip()
                # ê¸¸ì´ ì œí•œ ì œê±° - ëª¨ë“  ì¶”ì¶œ í…ìŠ¤íŠ¸ í—ˆìš©
                if len(cleaned_text) == 0:
                    logger.warning(
                        f"HWPX íŒŒì¼ '{hwpx_file_path.name}'ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
                    )
                    return None

                logger.debug(f"HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(cleaned_text)}ì")

                # ProcessedDataManagerê°€ ì´ì œ í…ìŠ¤íŠ¸ ì €ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤

                logger.info(
                    f"HWPX íŒŒì¼ '{hwpx_file_path.name}'ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ ({len(cleaned_text)}ì)"
                )
                return cleaned_text
            else:
                logger.warning(
                    f"HWPX íŒŒì¼ '{hwpx_file_path.name}'ì—ì„œ ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
                return None

    except MemoryError:
        logger.error(f"HWPX íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ë©”ëª¨ë¦¬ ë¶€ì¡±: {hwpx_file_path.name}")
        return None
    except Exception as e:
        # ZIP í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° fallbackìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë¯€ë¡œ WARNINGìœ¼ë¡œ ë‚®ì¶¤
        logger.warning(f"HWPX íŒŒì¼ '{hwpx_file_path.name}' í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (fallback ì‹œë„ ì˜ˆì •): {e}")
        logger.debug(f"HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return None


def clean_hwp_extracted_text(text: str) -> str:
    """
    HWPì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì˜ ê¹¨ì§„ ë¬¸ìë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.

    Args:
        text: ì›ë³¸ HWP ì¶”ì¶œ í…ìŠ¤íŠ¸

    Returns:
        ì •ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""

    # 1. ì œì–´ ë¬¸ì ë° ë¹„í‘œì¤€ ìœ ë‹ˆì½”ë“œ ë¬¸ì ì œê±°
    control_chars = re.compile(r"[\u0000-\u001F\u007F-\u009F\uFFFE\uFFFF]")
    text = control_chars.sub("", text)

    # 2. íŠ¹ì • íŒ¨í„´ì˜ ê¹¨ì§„ ë¬¸ì ì œê±°
    corrupted_patterns = [
        r"[\u0002\u0003\u0004\u0005\u0006\u0007\u0008\u0009\u000A\u000B\u000C\u000D\u000E\u000F]+",
        r"[\u4E00-\u9FFF]{1,3}(?=\u0000)",  # í•œì ë’¤ì— null ë¬¸ìê°€ ì˜¤ëŠ” íŒ¨í„´
        r"\u0000+",  # ì—°ì†ëœ null ë¬¸ì
        r"[\u0010-\u001F]+",  # ì¶”ê°€ ì œì–´ ë¬¸ì
    ]

    for pattern in corrupted_patterns:
        text = re.sub(pattern, "", text)

    # 3. HWP íŠ¹ìˆ˜ ë¬¸ì íŒ¨í„´ ì •ë¦¬
    hwp_special_chars = [
        r"[æ° ç‘¢æ±¤æ¯æ¤ç¥]+",  # HWP í…Œì´ë¸” ê´€ë ¨ íŠ¹ìˆ˜ ë¬¸ì
        r"[æ¼ æ³]+",  # ê¸°íƒ€ HWP íŠ¹ìˆ˜ ë¬¸ì
    ]

    for pattern in hwp_special_chars:
        text = re.sub(pattern, "", text)

    # 4. ì—°ì†ëœ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r"\n\s*\n\s*\n", "\n\n", text)  # 3ê°œ ì´ìƒì˜ ì—°ì† ì¤„ë°”ê¿ˆì„ 2ê°œë¡œ
    text = re.sub(r"[ \t]+", " ", text)  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ

    # 5. ë¹ˆ ì¤„ ê³¼ë‹¤ ì œê±°
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()


def has_cyrillic_encoding_issue(text: str, threshold: float = 0.01) -> tuple[bool, str]:
    """
    í…ìŠ¤íŠ¸ì— í‚¤ë¦´ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œê°€ ìˆëŠ”ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤.

    Args:
        text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
        threshold: í‚¤ë¦´ ë¬¸ì ë¹„ìœ¨ ì„ê³„ê°’ (ê¸°ë³¸ 1%)

    Returns:
        tuple[bool, str]: (ë¬¸ì œ ë°œê²¬ ì—¬ë¶€, ìƒì„¸ ë©”ì‹œì§€)
    """
    if not text or len(text) == 0:
        return False, "Empty text"

    # í‚¤ë¦´ ë¬¸ì íŒ¨í„´ (ì „ì²´ Cyrillic ë¸”ë¡ í¬í•¨: U+0400-04FF)
    # ê¸°ë³¸ Cyrillic (U+0400-04FF) + Cyrillic Supplement (U+0500-052F)
    # í•œê¸€ HWP ì¸ì½”ë”© ì˜¤ë¥˜ ì‹œ Cyrillic Extended ë¬¸ìë¡œ ê¹¨ì§
    cyrillic_pattern = r'[\u0400-\u052F]'
    cyrillic_matches = re.findall(cyrillic_pattern, text)
    cyrillic_count = len(cyrillic_matches)

    total_chars = len(text)
    cyrillic_ratio = cyrillic_count / total_chars if total_chars > 0 else 0

    if cyrillic_ratio > threshold:
        message = f"Cyrillic encoding issue detected: {cyrillic_count}/{total_chars} chars ({cyrillic_ratio*100:.2f}%)"
        return True, message

    return False, "OK"


def is_valid_hwp_file(hwp_file_path: Path) -> bool:
    """
    HWP íŒŒì¼ì˜ ìœ íš¨ì„±ì„ ê°„ë‹¨íˆ ê²€ì‚¬í•©ë‹ˆë‹¤.
    """
    try:
        if not hwp_file_path.exists() or hwp_file_path.stat().st_size == 0:
            return False

        # HWP íŒŒì¼ì˜ ì‹œì‘ ë°”ì´íŠ¸ í™•ì¸ (OLE2 êµ¬ì¡°ì²´)
        with open(hwp_file_path, "rb") as f:
            header = f.read(8)
            # OLE2 signature: D0CF11E0A1B11AE1
            if len(header) < 8 or header[:8] != b"\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1":
                logger.warning(f"HWP íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ ë¶ˆì¼ì¹˜: {hwp_file_path.name}")
                return False

        return True

    except Exception as e:
        logger.warning(f"HWP íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨: {hwp_file_path.name} - {e}")
        return False


def process_hwp_with_fallback(
    hwp_file_path: Path, temp_output_dir: Path = None
) -> str | None:
    """HWP íŒŒì¼ ì²˜ë¦¬ - fallback í¬í•¨ (announcementClassifier ë° processManager í˜¸í™˜ì„±)"""
    # temp_output_dir ì¸ìˆ˜ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ë°›ì§€ë§Œ í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    return extract_hwp_text_fallback(hwp_file_path)


def extract_hwp_text_fallback(hwp_file_path: Path) -> str | None:
    """
    HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•œ ëŒ€ì²´ ë°©ë²•.
    ì£¼ ë³€í™˜ ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì‚¬ìš©ë©ë‹ˆë‹¤.
    """

    # ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€: convert_hwp_to_markdown()ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    logger.info(f"Fallback HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘: {hwp_file_path.name}")

    # HWPX íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ì²˜ë¦¬
    if hwp_file_path.suffix.lower() == ".hwpx":
        # 1. ë¨¼ì € ì œì™¸ ëŒ€ìƒì¸ì§€ í™•ì¸ (ì œì™¸ ëŒ€ìƒì´ë©´ OLE2 fallbackë„ ë¶ˆí•„ìš”)
        if should_exclude_file(hwp_file_path):
            logger.debug(f"HWPX íŒŒì¼ ì œì™¸ë¨ (fallback ë¶ˆí•„ìš”): {hwp_file_path.name}")
            return None

        # 2. ì œì™¸ ëŒ€ìƒ ì•„ë‹˜ -> HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        result = convert_hwpx_to_text(hwp_file_path)
        if result:
            return result

        # 3. HWPX ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ, ì‹¤ì œ OLE2 í˜•ì‹ì¸ì§€ í™•ì¸ í›„ fallback
        # (í™•ì¥ìëŠ” .hwpxì´ì§€ë§Œ ì‹¤ì œë¡œëŠ” OLE2 HWP í˜•ì‹ì¼ ìˆ˜ ìˆìŒ)
        if is_valid_hwp_file(hwp_file_path):
            logger.info(f"HWPX í™•ì¥ìì§€ë§Œ ì‹¤ì œ OLE2 í˜•ì‹ìœ¼ë¡œ í™•ì¸ë¨, read_hwp() ì‹œë„: {hwp_file_path.name}")
            try:
                import gethwp
                text = gethwp.read_hwp(str(hwp_file_path))
                if text and text.strip():
                    cleaned_text = clean_hwp_extracted_text(text)
                    if len(cleaned_text) >= 10:
                        logger.info(f"OLE2 í˜•ì‹ HWPX ì¶”ì¶œ ì„±ê³µ: {hwp_file_path.name} ({len(cleaned_text)}ì)")
                        return cleaned_text
            except Exception as e:
                logger.warning(f"OLE2 í˜•ì‹ HWPX ì¶”ì¶œ ì‹¤íŒ¨: {hwp_file_path.name} - {e}")
        else:
            logger.debug(f"HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶ˆê°€ (ZIP í˜•ì‹ì´ë‚˜ íŒŒì‹± ì‹¤íŒ¨): {hwp_file_path.name}")

        return None

    # 2025.09.03  ê¸°ì¡´ ì†ŒìŠ¤. í˜„ì¬  extracted_text = gethwp.read_hwp(str(hwp_file_path))
    # ì´ê±¸ë¡œë§Œ í•˜ê³  ìˆë‹¤. ì´ ë¶€ë¶„ì€ failbackì´ë‹¤.
    try:
        # íŒŒì¼ ìœ íš¨ì„± ì‚¬ì „ ê²€ì‚¬
        if not is_valid_hwp_file(hwp_file_path):
            logger.warning(
                f"HWP íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨, ì²˜ë¦¬ ê±´ë„ˆëœ€: {hwp_file_path.name}"
            )
            return None

        # Heavy library - lazy import for performance
        import gethwp

        # gethwpë¡œ HWP íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        if hwp_file_path.suffix.lower() == ".hwp":
            logger.info(f"HWP íŒŒì¼ ëŒ€ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„: {hwp_file_path.name}")
            extracted_text = gethwp.read_hwp(str(hwp_file_path))

            if isinstance(extracted_text, str) and extracted_text.strip():
                # ê¹¨ì§„ ë¬¸ì ì •ë¦¬ ì ìš©
                cleaned_text = clean_hwp_extracted_text(extracted_text)
                if len(cleaned_text) >= 10:
                    logger.info(
                        f"HWP íŒŒì¼ ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {hwp_file_path.name} ({len(cleaned_text)}ì)"
                    )
                    return cleaned_text

        # ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹œë„ ê°€ëŠ¥ ìœ„ì¹˜
        logger.warning(f"HWP íŒŒì¼ ëŒ€ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {hwp_file_path.name}")
        return None

    except Exception as e:
        logger.error(f"HWP íŒŒì¼ ëŒ€ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {hwp_file_path.name} - {e}")
        return None


# ====================================================================================
# ê·œì¹™ ê¸°ë°˜ íŒŒì¼ ì„ ë³„ ì‹œìŠ¤í…œ (Rule-Based File Selection)
# ====================================================================================

# í™•ì¥ì ìš°ì„ ìˆœìœ„ (ë‚®ì€ ìˆ«ì = ë†’ì€ ìš°ì„ ìˆœìœ„)
EXTENSION_PRIORITY = {
    '.md': 1,      # ì´ë¯¸ ë³€í™˜ëœ ë§ˆí¬ë‹¤ìš´ (ìµœìš°ì„ )
    '.hwp': 2,     # í•œê¸€ ì›ë³¸
    '.hwpx': 3,    # í•œê¸€ XML
    '.pdf': 4,     # PDF
    '.docx': 5,    # MS Word
    '.pptx': 10,   # PowerPoint
    '.jpg': 20,    # ì´ë¯¸ì§€
    '.jpeg': 20,
    '.png': 20,
    '.gif': 20,
    '.bmp': 20,
    '.webp': 20,
    '.zip': 30     # ì••ì¶• íŒŒì¼ (ìµœí•˜ìœ„)
}

# í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ (í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ì„ ë³„)
REQUIRED_KEYWORDS = [
    # ê³µê³  ê´€ë ¨
    "ëª¨ì§‘ê³µê³ ", "ì„ ì •ê³µê³ ", "ë°œí‘œê³µê³ ", "ê³µê³ ë¬¸", "ê³µê³ ", "ê³µë¬¸",
    # ì‚¬ì—… ê´€ë ¨
    "ì‚¬ì—…ê³„íš", "ì§€ì›ì‚¬ì—…", "ë³´ì¡°ì‚¬ì—…", "ì‚¬ì—…", "ë³´ì¡°ê¸ˆ",
    # ì‹ ì²­/ëª¨ì§‘ ê´€ë ¨
    "ì§€ì›ì‹ ì²­", "ì°¸ê°€ì‹ ì²­", "ì…ì£¼ì‹ ì²­", "ì ‘ìˆ˜ì‹ ì²­", "ëª¨ì§‘", "ì§€ì›", "ì°¸ì—¬", "ì ‘ìˆ˜",
    # ê³„íš/ì œì•ˆ ê´€ë ¨
    "ì‚¬ì—…ê³„íšì„œ", "ì¶”ì§„ê³„íšì„œ", "ê³„íšì„œ", "ì œì•ˆì„œ", "ì¶”ì§„ê³„íš",
]

# ì œì™¸ í‚¤ì›Œë“œ (í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ì œì™¸)
EXCLUDE_KEYWORDS = [
    # ì‹ ì²­ì„œ ê´€ë ¨
    "ì‹ ì²­ì„œì–‘ì‹", "ì…ì£¼ì‹ ì²­ì„œ", "ì°¸ê°€ì‹ ì²­ì„œ", "ì§€ì›ì‹ ì²­ì„œ", "ì‹ ì²­ì„œ", "ì‹ ì²­ì–‘ì‹",
    # ì²¨ë¶€/ì°¸ê³ 
    "ì²¨ë¶€ë¬¸ì„œ", "ì²¨ë¶€ì„œë¥˜", "ì²¨ë¶€ìë£Œ", "ì²¨ë¶€", "ì°¸ê³ ìë£Œ", "ì°¸ì¡°",
    # ì–‘ì‹/í…œí”Œë¦¿
    "ì–‘ì‹", "ì„œì‹", "í…œí”Œë¦¿", "template", "form",
    # ê¸°íƒ€
    "ë³„ì§€", "ë³„ì²¨", "ë¶™ì„", "ë¶€ë¡", "ìƒ˜í”Œ", "ì˜ˆì‹œ", "ì•ˆë‚´ì„œ", "ê°€ì´ë“œ", "ë§¤ë‰´ì–¼",
    "ì²´í¬ë¦¬ìŠ¤íŠ¸", "checklist", "faq", "ê³µê³ ì´ë¯¸ì§€", "í¬ìŠ¤í„°", "ì´ë¯¸ì§€",
]


def find_title_matched_files(files: list, title: str) -> list:
    """
    ì œëª©ê³¼ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ë“¤ ì°¾ê¸° (ìœ ì‚¬ë„ > 0.95)

    Args:
        files: íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (Path ê°ì²´)
        title: ê³µê³  ì œëª©

    Returns:
        list: ì œëª©ê³¼ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    """
    logger = setup_logging(__name__)
    matched = []

    for file_path in files:
        similarity = calculate_title_similarity(file_path.stem, title)
        if similarity > 0.95:
            matched.append(file_path)
            logger.info(f"ğŸ“Œ ì œëª© ì¼ì¹˜ ë°œê²¬: {file_path.name} (ìœ ì‚¬ë„: {similarity:.3f})")

    return matched


def select_by_extension_priority(files: list) -> Path:
    """
    í™•ì¥ì ìš°ì„ ìˆœìœ„ë¡œ 1ê°œ ì„ íƒ

    Args:
        files: íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (Path ê°ì²´)

    Returns:
        Path: ìš°ì„ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ íŒŒì¼
    """
    logger = setup_logging(__name__)

    best_file = min(files, key=lambda f: EXTENSION_PRIORITY.get(f.suffix.lower(), 99))
    logger.info(f"ğŸ† í™•ì¥ì ìš°ì„ ìˆœìœ„ ì„ íƒ: {best_file.name} ({best_file.suffix})")

    return best_file


def filter_by_required_keywords(files: list) -> list:
    """
    í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œë¡œ ì„ ë³„

    Args:
        files: íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (Path ê°ì²´)

    Returns:
        list: í•„ìˆ˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    """
    logger = setup_logging(__name__)
    selected = []

    for file_path in files:
        filename = file_path.stem.lower()
        matched_keywords = [kw for kw in REQUIRED_KEYWORDS if kw.lower() in filename]

        if matched_keywords:
            selected.append(file_path)
            logger.debug(f"âœ… í•„ìˆ˜ í‚¤ì›Œë“œ ë§¤ì¹­: {file_path.name} - {matched_keywords}")

    logger.info(f"ğŸ“‹ í•„ìˆ˜ í‚¤ì›Œë“œ ì„ ë³„: {len(selected)}/{len(files)}ê°œ")
    return selected


def filter_by_exclude_keywords(files: list) -> list:
    """
    ì œì™¸ í‚¤ì›Œë“œë¡œ í•„í„°ë§

    Args:
        files: íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (Path ê°ì²´)

    Returns:
        list: ì œì™¸ í‚¤ì›Œë“œê°€ ì—†ëŠ” íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    """
    logger = setup_logging(__name__)
    filtered = []

    for file_path in files:
        filename = file_path.stem.lower()
        matched_exclude = [kw for kw in EXCLUDE_KEYWORDS if kw.lower() in filename]

        if not matched_exclude:
            filtered.append(file_path)
        else:
            logger.debug(f"âŒ ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­: {file_path.name} - {matched_exclude}")

    logger.info(f"ğŸ” ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§: {len(filtered)}/{len(files)}ê°œ ë‚¨ìŒ")
    return filtered


def rule_based_file_selection(all_files: list, announcement_title: str) -> list:
    """
    ê·œì¹™ ê¸°ë°˜ íŒŒì¼ ì„ ë³„ ì‹œìŠ¤í…œ

    ë‹¨ê³„:
    1. ì••ì¶• íŒŒì¼ í•´ì œ (ì´ë¯¸ ì™„ë£Œë¨, í™•ì¸ë§Œ)
    2. ì œëª©-íŒŒì¼ëª… ì™„ì „ ì¼ì¹˜? â†’ ì„ íƒ (í™•ì¥ì ìš°ì„ ìˆœìœ„)
    3. ì²¨ë¶€íŒŒì¼ 1ê°œ? â†’ ì„ íƒ
    4. í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œë¡œ ì„ ë³„ (ì—†ìœ¼ë©´ ëª¨ë“  íŒŒì¼)
    5. ì œì™¸ í‚¤ì›Œë“œë¡œ í•„í„°ë§ (ì—†ìœ¼ë©´ ì œì™¸ ì „ íŒŒì¼)

    Args:
        all_files: ëª¨ë“  íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (Path ê°ì²´)
        announcement_title: ê³µê³  ì œëª©

    Returns:
        list: ì²˜ë¦¬í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (1ê°œ ì´ìƒ)
    """
    logger = setup_logging(__name__)

    # Step 1: ì••ì¶• íŒŒì¼ í•´ì œ í™•ì¸ (ì´ë¯¸ attachmentProcessorì—ì„œ ì²˜ë¦¬ë¨)
    logger.info(f"ğŸ“ ê·œì¹™ ê¸°ë°˜ íŒŒì¼ ì„ ë³„ ì‹œì‘: ì´ {len(all_files)}ê°œ íŒŒì¼")

    # Step 2: ì œëª©-íŒŒì¼ëª… ì™„ì „ ì¼ì¹˜ í™•ì¸
    if announcement_title:
        title_matched = find_title_matched_files(all_files, announcement_title)
        if title_matched:
            logger.info(f"âœ… [Step 2] ì œëª© ì¼ì¹˜ íŒŒì¼ ë°œê²¬: {len(title_matched)}ê°œ")
            # ì—¬ëŸ¬ê°œë©´ í™•ì¥ì ìš°ì„ ìˆœìœ„ë¡œ 1ê°œ ì„ íƒ
            selected = select_by_extension_priority(title_matched)
            return [selected]

    # Step 3: ì²¨ë¶€íŒŒì¼ 1ê°œ?
    if len(all_files) == 1:
        logger.info(f"âœ… [Step 3] ì²¨ë¶€íŒŒì¼ 1ê°œë§Œ ì¡´ì¬ â†’ ë¬´ì¡°ê±´ ì²˜ë¦¬: {all_files[0].name}")
        return all_files

    # Step 4: í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œë¡œ ì„ ë³„
    logger.info(f"ğŸ” [Step 4] í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ ì„ ë³„ ì‹œì‘")
    selected = filter_by_required_keywords(all_files)

    if not selected:
        logger.info(f"âš ï¸  í•„ìˆ˜ í‚¤ì›Œë“œ ì„ ë³„ ì—†ìŒ â†’ ëª¨ë“  íŒŒì¼ ì„ íƒ")
        selected = all_files.copy()
    else:
        logger.info(f"âœ… í•„ìˆ˜ í‚¤ì›Œë“œ ì„ ë³„ ì™„ë£Œ: {len(selected)}ê°œ")

    # Step 5: ì œì™¸ í‚¤ì›Œë“œë¡œ í•„í„°ë§
    logger.info(f"ğŸ” [Step 5] ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§ ì‹œì‘")
    filtered = filter_by_exclude_keywords(selected)

    if not filtered:
        logger.warning(f"âš ï¸  ì œì™¸ í›„ ë‚¨ëŠ” íŒŒì¼ ì—†ìŒ â†’ ì œì™¸ ì „ íŒŒì¼ ì‚¬ìš©")
        filtered = selected.copy()
    else:
        logger.info(f"âœ… ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§ ì™„ë£Œ: {len(filtered)}ê°œ")

    # Step 6: ìµœì¢… íŒŒì¼ë“¤ ë°˜í™˜
    logger.info(f"ğŸ¯ [ìµœì¢…] ì²˜ë¦¬í•  íŒŒì¼: {len(filtered)}ê°œ")
    for idx, file_path in enumerate(filtered, 1):
        logger.info(f"  {idx}. {file_path.name}")

    return filtered
