#!/usr/bin/env python3
"""
ê° ìŠ¤í¬ë˜í¼ íŒŒì¼ì—ì„œ ì œëª© ë¹„êµ ë¡œì§ì´ ìˆëŠ”ì§€ ì²´í¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import re
from pathlib import Path
from datetime import datetime

# ìŠ¤í¬ë˜í¼ ë””ë ‰í† ë¦¬
SCRAPER_DIR = Path("/Users/jin/classfy_scraper/node/scraper")

def check_title_comparison(file_path, site_code):
    """íŒŒì¼ì—ì„œ ì œëª© ë¹„êµ ë¡œì§ì„ ì°¾ê¸°"""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ì œëª© ë¹„êµì™€ ê´€ë ¨ëœ íŒ¨í„´ë“¤
        patterns = {
            'exact_title_match': [
                r'announcement\.title\s*===?\s*',  # announcement.title === something
                r'title\s*===?\s*',                # title === something
                r'\.title.*?===',                  # .title ... ===
            ],
            'includes_title': [
                r'\.includes\([\'"`].*?title',     # .includes("...title")
                r'title.*?\.includes\(',           # title.includes(
            ],
            'indexOf_title': [
                r'\.indexOf\([\'"`].*?title',      # .indexOf("...title")
                r'title.*?\.indexOf\(',            # title.indexOf(
            ],
            'startsWith_endsWith': [
                r'\.startsWith\([\'"`]',           # .startsWith("...")
                r'\.endsWith\([\'"`]',             # .endsWith("...")
            ],
            'regex_title': [
                r'title.*?\.match\(',              # title.match(
                r'title.*?\.test\(',               # title.test(
                r'new RegExp.*?title',             # new RegExp(...title...)
            ],
            'lastProcessedTitle': [
                r'lastProcessedTitle',             # lastProcessedTitle ë³€ìˆ˜
                r'previousTitle',                  # previousTitle ë³€ìˆ˜
                r'latestTitle',                    # latestTitle ë³€ìˆ˜
            ],
            'break_on_condition': [
                r'if\s*\(.*?title.*?\).*?break',   # if (..title..) break
                r'if\s*\(.*?title.*?\).*?return',  # if (..title..) return
            ]
        }
        
        findings = {}
        
        for pattern_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    if pattern_type not in findings:
                        findings[pattern_type] = []
                    findings[pattern_type].extend(matches[:3])  # ìµœëŒ€ 3ê°œ ì˜ˆì‹œë§Œ
        
        # ì¶”ê°€ë¡œ ì œëª©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬í•˜ëŠ” ë¡œì§ ì°¾ê¸°
        duplicate_patterns = [
            r'processedTitles',
            r'seenTitles',
            r'existingTitles',
            r'duplicateCheck',
            r'Set\(\).*?title',  # Setì— title ì¶”ê°€
            r'Map\(\).*?title',  # Mapì— title ì¶”ê°€
        ]
        
        for pattern in duplicate_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                if 'duplicate_check' not in findings:
                    findings['duplicate_check'] = []
                findings['duplicate_check'].append(pattern)
        
        # ë‚ ì§œ ë¹„êµ íŒ¨í„´ë„ ì²´í¬
        date_comparison_patterns = [
            r'targetDate.*?[<>=]',
            r'fromDate.*?[<>=]',
            r'startDate.*?[<>=]',
            r'announcement\.date.*?[<>=]',
        ]
        
        for pattern in date_comparison_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                if 'date_comparison' not in findings:
                    findings['date_comparison'] = []
                findings['date_comparison'].append(pattern)
        
        return findings
        
    except Exception as e:
        return {'error': str(e)}


def main():
    print("=" * 80)
    print("ìŠ¤í¬ë˜í¼ ì œëª© ë¹„êµ ë¡œì§ ì²´í¬")
    print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # ëª¨ë“  ìŠ¤í¬ë˜í¼ íŒŒì¼ ì°¾ê¸°
    scraper_files = sorted(SCRAPER_DIR.glob("*_scraper.js"))
    
    print(f"\nì´ {len(scraper_files)}ê°œ ìŠ¤í¬ë˜í¼ íŒŒì¼ ë°œê²¬\n")
    
    results = {
        'with_title_logic': [],
        'without_title_logic': [],
        'with_date_logic': [],
        'errors': []
    }
    
    for scraper_file in scraper_files:
        site_code = scraper_file.stem.replace('_scraper', '')
        findings = check_title_comparison(scraper_file, site_code)
        
        if 'error' in findings:
            results['errors'].append({
                'site_code': site_code,
                'error': findings['error']
            })
        elif findings:
            # ë‚ ì§œ ë¹„êµ ë¡œì§ì´ ìˆëŠ”ì§€ ì²´í¬
            if 'date_comparison' in findings:
                results['with_date_logic'].append(site_code)
            
            # ì œëª© ê´€ë ¨ ë¡œì§ì´ ìˆëŠ”ì§€ ì²´í¬ (date_comparison ì œì™¸)
            title_related_findings = {k: v for k, v in findings.items() if k != 'date_comparison'}
            if title_related_findings:
                results['with_title_logic'].append({
                    'site_code': site_code,
                    'logic_types': list(title_related_findings.keys()),
                    'examples': title_related_findings
                })
            else:
                results['without_title_logic'].append(site_code)
        else:
            results['without_title_logic'].append(site_code)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"  - ì œëª© ë¹„êµ ë¡œì§ ìˆìŒ: {len(results['with_title_logic'])}ê°œ")
    print(f"  - ì œëª© ë¹„êµ ë¡œì§ ì—†ìŒ: {len(results['without_title_logic'])}ê°œ")
    print(f"  - ë‚ ì§œ ë¹„êµ ë¡œì§ ìˆìŒ: {len(results['with_date_logic'])}ê°œ")
    print(f"  - ì˜¤ë¥˜ ë°œìƒ: {len(results['errors'])}ê°œ")
    
    # ìƒì„¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    output_file = Path("/Users/jin/classfy_scraper/scraper_title_logic_report.md")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# ìŠ¤í¬ë˜í¼ ì œëª© ë¹„êµ ë¡œì§ ë¶„ì„ ë³´ê³ ì„œ\n\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"## ìš”ì•½\n")
        f.write(f"- ì´ ìŠ¤í¬ë˜í¼ ìˆ˜: {len(scraper_files)}ê°œ\n")
        f.write(f"- ì œëª© ë¹„êµ ë¡œì§ ìˆìŒ: {len(results['with_title_logic'])}ê°œ\n")
        f.write(f"- ì œëª© ë¹„êµ ë¡œì§ ì—†ìŒ: {len(results['without_title_logic'])}ê°œ\n")
        f.write(f"- ë‚ ì§œ ë¹„êµ ë¡œì§ ìˆìŒ: {len(results['with_date_logic'])}ê°œ\n\n")
        
        f.write("## ì œëª© ë¹„êµ ë¡œì§ì´ ìˆëŠ” ìŠ¤í¬ë˜í¼\n\n")
        if results['with_title_logic']:
            for item in results['with_title_logic']:
                f.write(f"### {item['site_code']}\n")
                f.write(f"- ë¡œì§ ìœ í˜•: {', '.join(item['logic_types'])}\n")
                f.write("- ì˜ˆì‹œ:\n")
                for logic_type, examples in item['examples'].items():
                    f.write(f"  - {logic_type}: {examples[:2]}\n")
                f.write("\n")
        else:
            f.write("ì—†ìŒ\n\n")
        
        f.write("## ì œëª© ë¹„êµ ë¡œì§ì´ ì—†ëŠ” ìŠ¤í¬ë˜í¼\n\n")
        if results['without_title_logic']:
            # 10ê°œì”© ì¤„ë°”ê¿ˆí•˜ì—¬ ì¶œë ¥
            for i in range(0, len(results['without_title_logic']), 10):
                batch = results['without_title_logic'][i:i+10]
                f.write(f"- {', '.join(batch)}\n")
        else:
            f.write("ì—†ìŒ\n\n")
        
        f.write("\n## ë‚ ì§œ ë¹„êµ ë¡œì§ì´ ìˆëŠ” ìŠ¤í¬ë˜í¼\n\n")
        if results['with_date_logic']:
            for i in range(0, len(results['with_date_logic']), 10):
                batch = results['with_date_logic'][i:i+10]
                f.write(f"- {', '.join(batch)}\n")
        else:
            f.write("ì—†ìŒ\n\n")
        
        if results['errors']:
            f.write("\n## ì˜¤ë¥˜ ë°œìƒ ìŠ¤í¬ë˜í¼\n\n")
            for item in results['errors']:
                f.write(f"- {item['site_code']}: {item['error']}\n")
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“„ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥: {output_file}")
    
    # ì œëª© ë¹„êµ ë¡œì§ì´ ì—†ëŠ” ìŠ¤í¬ë˜í¼ ëª©ë¡ë§Œ ë”°ë¡œ ì €ì¥
    no_title_logic_file = Path("/Users/jin/classfy_scraper/scrapers_without_title_logic.txt")
    with open(no_title_logic_file, 'w', encoding='utf-8') as f:
        f.write("# ì œëª© ë¹„êµ ë¡œì§ì´ ì—†ëŠ” ìŠ¤í¬ë˜í¼ ëª©ë¡\n\n")
        f.write(f"ì´ {len(results['without_title_logic'])}ê°œ\n\n")
        for site_code in results['without_title_logic']:
            f.write(f"{site_code}\n")
    
    print(f"ğŸ“„ ì œëª© ë¹„êµ ì—†ëŠ” ìŠ¤í¬ë˜í¼ ëª©ë¡: {no_title_logic_file}")


if __name__ == "__main__":
    main()