#!/usr/bin/env python3
"""
ê³µê³  ì²˜ë¦¬ ë©”ì¸ í”„ë¡œê·¸ë¨

ì‚¬ìš©ë²•:
    python announcement_processor.py [ë””ë ‰í† ë¦¬ëª…] [ì‚¬ì´íŠ¸ì½”ë“œ]
    
ì˜ˆì‹œ:
    python announcement_processor.py data.origin cbt
    python announcement_processor.py  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.config.config import ConfigManager
from src.config.logConfig import setup_logging
from src.utils.attachmentProcessor import AttachmentProcessor
from src.utils.ollamaClient import AnnouncementAnalyzer
from src.models.announcementDatabase import AnnouncementDatabaseManager, create_announcement_tables
from src.utils.announcementFilter import AnnouncementFilter

logger = setup_logging(__name__)
config = ConfigManager().get_config()


class AnnouncementProcessor:
    """ê³µê³  ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, attach_force: bool = False):
        self.attachment_processor = AttachmentProcessor()
        self.announcement_analyzer = AnnouncementAnalyzer()
        self.db_manager = AnnouncementDatabaseManager()
        self.filter = AnnouncementFilter()
        self.attach_force = attach_force
        
        # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)
        self._ensure_database_tables()
        
        # ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ
        self.exclusion_keywords = self._load_exclusion_keywords()
    
    def _ensure_database_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if self.db_manager.test_connection():
                self.db_manager.create_tables()
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ")
            else:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
    
    def _load_exclusion_keywords(self) -> List[Dict[str, Any]]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT EXCLUSION_ID, KEYWORD, DESCRIPTION
                    FROM EXCLUSION_KEYWORDS
                    WHERE IS_ACTIVE = TRUE
                    ORDER BY EXCLUSION_ID
                """))
                
                keywords = []
                for row in result:
                    keywords.append({
                        'id': row[0],
                        'keyword': row[1],
                        'description': row[2]
                    })
                
                logger.info(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ: {len(keywords)}ê°œ")
                return keywords
                
        except Exception as e:
            logger.warning(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def process_directory(self, directory_path: Path, site_code: str) -> bool:
        """
        ë‹¨ì¼ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            directory_path: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        folder_name = directory_path.name
        return self.process_directory_with_custom_name(directory_path, site_code, folder_name)
    
    def _collect_attachment_info(self, directory_path: Path) -> List[Dict[str, Any]]:
        """ì²¨ë¶€íŒŒì¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        attachment_info = []
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return attachment_info
        
        try:
            # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            # attachment_results = self.attachment_processor.process_directory_attachments(directory_path)
            
            # ì‹¤ì œ íŒŒì¼ë“¤ê³¼ ë§¤ì¹­
            for file_path in attachments_dir.iterdir():
                if file_path.is_file():
                    filename = file_path.stem
                    file_extension = file_path.suffix
                    
                    # íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                    try:
                        file_size = file_path.stat().st_size
                    except:
                        file_size = 0
                    
                    # ë³€í™˜ ê²°ê³¼ ì°¾ê¸°
                    # converted_content = attachment_results.get(filename, "")
                    # conversion_success = bool(converted_content)
                    
                    # ë³€í™˜ ë°©ë²• ì¶”ì •
                    # conversion_method = self._guess_conversion_method(file_extension)
                    
                    attachment_info.append({
                        "filename": filename,
                        "file_extension": file_extension,
                        "file_path": str(file_path),
                        "file_size": file_size,
                        # "converted_content": converted_content,
                        # "conversion_method": conversion_method,
                        # "conversion_success": conversion_success
                    })
            
            logger.info(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(attachment_info)}ê°œ")
            
        except Exception as e:
            logger.error(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return attachment_info
    
    def _guess_conversion_method(self, file_extension: str) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë³€í™˜ ë°©ë²•ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
        ext_lower = file_extension.lower()
        
        if ext_lower == '.pdf':
            return 'pdf_docling'
        elif ext_lower in ['.hwp', '.hwpx']:
            return 'hwp_markdown'
        elif ext_lower in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']:
            return 'ocr'
        else:
            return 'unknown'
    
    def _find_target_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        ì²˜ë¦¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            recursive: ì¬ê·€ì  ê²€ìƒ‰ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬ ëª©ë¡
        """
        site_dir = base_dir / site_code
        
        if not site_dir.exists():
            logger.error(f"ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {site_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ content.md ë˜ëŠ” attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
            logger.info(f"ì¬ê·€ì  ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘: {site_dir}")
            
            for root_path in site_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md íŒŒì¼ì´ ìˆê±°ë‚˜ attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬ ë°œê²¬: {root_path.relative_to(site_dir)}")
        else:
            # ê¸°ë³¸ ë™ì‘: ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ì˜ ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë§Œ ê²€ìƒ‰í•˜ê³  í´ë”ëª…ìœ¼ë¡œ ì •ë ¬
            all_directories = [d for d in site_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ë°œê²¬ëœ ì „ì²´ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
        
        # ì²˜ìŒ ëª‡ ê°œ í´ë”ëª… ë¡œê¹…
        if target_directories:
            logger.info(f"ì²« 5ê°œ í´ë”: {[d.name for d in target_directories[:5]]}")
        
        # force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ì œì™¸
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders(site_code))
            
            filtered_directories = []
            for directory in target_directories:
                # ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
                relative_path = directory.relative_to(site_dir)
                folder_name = str(relative_path).replace("/", "_")  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
            
            logger.info(f"ì „ì²´ ë°œê²¬ëœ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
            logger.info(f"ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {len(filtered_directories)}ê°œ")
            logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”: {len(processed_folders)}ê°œ")
            
            return filtered_directories
        else:
            # force ì˜µì…˜ì´ ìˆìœ¼ë©´ ëª¨ë“  ë””ë ‰í† ë¦¬ ë°˜í™˜
            logger.info(f"--force ì˜µì…˜: ëª¨ë“  ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ({len(target_directories)}ê°œ)")
            return target_directories
    
    def process_site_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        íŠ¹ì • ì‚¬ì´íŠ¸ì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        # ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ ì°¾ê¸°
        target_directories = self._find_target_directories(base_dir, site_code, recursive, force)
        
        if not target_directories:
            logger.warning("ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        site_dir = base_dir / site_code
        
        print(f"\n{'='*60}")
        print(f"ê³µê³  ì²˜ë¦¬ ì‹œì‘: {site_code} ({total_count}ê°œ í´ë”)")
        print(f"{'='*60}")
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # ê°œë³„ í•­ëª© ì‹œì‘ ì‹œê°„
                item_start_time = time.time()
                
                # ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
                relative_path = directory.relative_to(site_dir)
                folder_name = str(relative_path).replace("/", "_")  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                progress_pct = (i / total_count) * 100
                print(f"\n[{i}/{total_count} : {progress_pct:.1f}%] {folder_name}")
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© í™•ì¸ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
                if not force and self.db_manager.is_already_processed(folder_name, site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"  âœ“ ì´ë¯¸ ì²˜ë¦¬ë¨, ê±´ë„ˆëœ€ ({skip_elapsed:.1f}ì´ˆ)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, site_code):
                    print("  ğŸ”„ ì´ë¯¸ ì²˜ë¦¬ë¨, --force ì˜µì…˜ìœ¼ë¡œ ì¬ì²˜ë¦¬")
                
                success = self.process_directory_with_custom_name(directory, site_code, folder_name, attach_force, force)
                
                # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"  âœ“ ì²˜ë¦¬ ì™„ë£Œ ({item_elapsed:.1f}ì´ˆ)")
                else:
                    results["failed"] += 1
                    print(f"  âœ— ì²˜ë¦¬ ì‹¤íŒ¨ ({item_elapsed:.1f}ì´ˆ)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"  âœ— ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}... ({error_elapsed:.1f}ì´ˆ)")
                logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({directory}): {e}")
        
        # ì¢…ë£Œ ì‹œê°„ ë° í†µê³„ ê³„ì‚°
        end_time = time.time()
        total_elapsed = end_time - start_time
        processed_count = results['success'] + results['failed']  # ì‹¤ì œ ì²˜ë¦¬í•œ ê°œìˆ˜ (ê±´ë„ˆë›´ ê²ƒ ì œì™¸)
        
        print(f"\n{'='*60}")
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {results['success']}/{total_count} ì„±ê³µ ({(results['success']/total_count)*100:.1f}%)")
        print(f"ê±´ë„ˆëœ€: {results['skipped']}, ì‹¤íŒ¨: {results['failed']}")
        print(f"")
        print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„ í†µê³„:")
        print(f"   ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ ({total_elapsed/60:.1f}ë¶„)")
        
        if processed_count > 0:
            avg_time_per_item = total_elapsed / processed_count
            print(f"   ì²˜ë¦¬í•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_item:.1f}ì´ˆ")
        
        if results['success'] > 0:
            avg_time_per_success = total_elapsed / results['success'] 
            print(f"   ì„±ê³µí•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_success:.1f}ì´ˆ")
        
        print(f"{'='*60}")
        
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ - ì „ì²´: {results['total']}, ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}, ê±´ë„ˆëœ€: {results['skipped']}")
        
        return results
    
    def process_directory_with_custom_name(self, directory_path: Path, site_code: str, folder_name: str, attach_force: bool = False, force: bool = False) -> bool:
        """
        ì‚¬ìš©ì ì •ì˜ í´ë”ëª…ìœ¼ë¡œ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            directory_path: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            folder_name: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•  í´ë”ëª…
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        logger.info(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì‹œì‘: {folder_name}")
        
        try:
            # 0. ì¤‘ë³µ ì²˜ë¦¬ ì²´í¬ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
            if not force:
                if self.db_manager.is_already_processed(folder_name, site_code):
                    logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
                    return True  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì´ë¯¸ ì²˜ë¦¬ë¨)
            
            # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
            excluded_keywords = self._check_exclusion_keywords(folder_name)
            
            # 2. content.md íŒŒì¼ ì½ê¸°
            content_md_path = directory_path / "content.md"
            content_md = ""
            
            if content_md_path.exists():
                try:
                    with open(content_md_path, 'r', encoding='utf-8') as f:
                        content_md = f.read()
                    logger.info(f"content.md ì½ê¸° ì™„ë£Œ: {len(content_md)} ë¬¸ì")
                except Exception as e:
                    logger.error(f"content.md ì½ê¸° ì‹¤íŒ¨: {e}")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, "", 
                        status="ollama", error_message=f"content.md ì½ê¸° ì‹¤íŒ¨: {e}"
                    )
            else:
                logger.warning(f"content.md íŒŒì¼ì´ ì—†ìŒ: {content_md_path}")
            
            # 3. ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ (content.mdì™€ ë¶„ë¦¬)
            try:
                combined_content, attachment_filenames = self._process_attachments_separately(directory_path, attach_force)
                
                if not content_md.strip() and not combined_content.strip():
                    logger.warning("ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŒ")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, combined_content,
                        attachment_filenames=attachment_filenames,
                        status="ollama", error_message="ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŒ"
                    )
                
                logger.info(f"ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ ì™„ë£Œ: {len(combined_content)} ë¬¸ì, íŒŒì¼ {len(attachment_filenames)}ê°œ")
                
            except Exception as e:
                logger.error(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="ollama", error_message=f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                )
            
            # 4. ì œì™¸ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ì œì™¸ ì²˜ë¦¬
            if excluded_keywords:
                exclusion_msg = f"ì œì™¸ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {', '.join(excluded_keywords)}"
                logger.info(f"ì œì™¸ ì²˜ë¦¬: {folder_name} - {exclusion_msg}")
                
                return self._save_processing_result(
                    folder_name, site_code, content_md, combined_content,
                    attachment_filenames=attachment_filenames,
                    status="ì œì™¸", exclusion_keywords=excluded_keywords,
                    exclusion_reason=exclusion_msg
                )
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ì— 1ì°¨ ì €ì¥ (status: ollama)
            record_id = self._save_processing_result(
                folder_name, site_code, content_md, combined_content, 
                attachment_filenames=attachment_filenames,
                status="ollama", force=True  # force ì˜µì…˜ì€ í•­ìƒ UPSERTë¡œ ì²˜ë¦¬
            )
            
            if not record_id:
                logger.error("1ì°¨ ì €ì¥ ì‹¤íŒ¨")
                return False
            
            # 6. content_mdë¡œ ì²«ë²ˆì§¸ ollama ë¶„ì„
            print("  ğŸ“‹ 1ì°¨ Ollama ë¶„ì„ ì¤‘ (content.md)...")
            first_response = None
            
            if content_md.strip():
                first_response, first_prompt = self._analyze_with_ollama(content_md)
                
                # EXTRACTED_TARGETì´ ìˆëŠ”ì§€ í™•ì¸
                def has_valid_target(response):
                    if not response:
                        return False
                    target = response.get("EXTRACTED_TARGET", "")
                    return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
                
                if has_valid_target(first_response):
                    # ì„±ê³µ: ìµœì¢… ì‘ë‹µìœ¼ë¡œ ì‚¬ìš©
                    logger.info("1ì°¨ ë¶„ì„ ì„±ê³µ - content.mdì—ì„œ EXTRACTED_TARGET ì¶”ì¶œë¨")
                    return self._update_processing_result(
                        record_id, first_response, first_prompt, status="ì„±ê³µ"
                    )
            
            # 7. combined_contentë¡œ ë‘ë²ˆì§¸ ollama ë¶„ì„
            print("  ğŸ“‹ 2ì°¨ Ollama ë¶„ì„ ì¤‘ (ì²¨ë¶€íŒŒì¼)...")
            second_response = None
            
            if combined_content.strip():
                second_response, second_prompt = self._analyze_with_ollama(combined_content)
                
                # ìµœì¢… ìƒíƒœ ê²°ì • ë¡œì§
                final_status = self._determine_final_status(first_response, second_response)
                
                return self._update_processing_result(
                    record_id, second_response, second_prompt, 
                    first_response=first_response, status=final_status
                )
            else:
                # combined_contentê°€ ì—†ëŠ” ê²½ìš° 1ì°¨ ê²°ê³¼ë§Œ ì‚¬ìš©
                final_status = self._determine_final_status(first_response, None)
                return self._update_processing_result(
                    record_id, first_response, first_prompt if first_response else "", 
                    status=final_status
                )
                
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return self._save_processing_result(
                folder_name, site_code, "", "",
                status="ollama", error_message=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}"
            )
    
    def _check_exclusion_keywords(self, folder_name: str) -> List[str]:
        """í´ë”ëª…ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ì²´í¬í•©ë‹ˆë‹¤."""
        matched_keywords = []
        
        for keyword_info in self.exclusion_keywords:
            keyword = keyword_info['keyword'].lower()
            if keyword in folder_name.lower():
                matched_keywords.append(keyword_info['keyword'])
                logger.debug(f"ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­: '{keyword}' in '{folder_name}'")
        
        return matched_keywords
    
    def _determine_final_status(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]]) -> str:
        """1ì°¨, 2ì°¨ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ìƒíƒœë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        
        # EXTRACTED_TARGETì´ ìœ íš¨í•œ ê°’ì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
        def has_valid_target(response):
            if not response:
                return False
            target = response.get("EXTRACTED_TARGET", "")
            return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        # 1ì°¨ ë˜ëŠ” 2ì°¨ì—ì„œ EXTRACTED_TARGETì´ ìˆìœ¼ë©´ ì„±ê³µ
        if has_valid_target(first_response) or has_valid_target(second_response):
            return "ì„±ê³µ"
        
        # 1ì°¨, 2ì°¨ ëª¨ë‘ ì •ë³´ ì—†ìŒì¸ ê²½ìš° completed
        first_no_info = not first_response or not has_valid_target(first_response)
        second_no_info = not second_response or not has_valid_target(second_response)
        
        if first_no_info and second_no_info:
            return "completed"
        
        # ê¸°ë³¸ê°’
        return "ollama"
    
    def _format_date_to_standard(self, date_str: str) -> Optional[str]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        import re
        
        if not date_str or date_str in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]:
            return None
        
        # ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_date = re.sub(r'[^\d\.\-/]', '', date_str.strip())
        
        # YYYY-MM-DD íŒ¨í„´ (ì´ë¯¸ í‘œì¤€ í˜•íƒœ)
        if re.match(r'^\d{4}-\d{2}-\d{2}$', clean_date):
            return clean_date
        
        # YYYY.MM.DD íŒ¨í„´
        match = re.match(r'^(\d{4})\.(\d{2})\.(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYYMMDD íŒ¨í„´
        match = re.match(r'^(\d{4})(\d{2})(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYY/MM/DD íŒ¨í„´
        match = re.match(r'^(\d{4})/(\d{2})/(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # ë” ë³µì¡í•œ íŒ¨í„´ë“¤ ì²˜ë¦¬
        # ì˜ˆ: 2024ë…„ 12ì›” 25ì¼
        year_month_day = re.search(r'(\d{4})ë…„?\s*(\d{1,2})ì›”?\s*(\d{1,2})ì¼?', date_str)
        if year_month_day:
            year = year_month_day.group(1)
            month = year_month_day.group(2).zfill(2)
            day = year_month_day.group(3).zfill(2)
            return f"{year}-{month}-{day}"
        
        # ìˆ«ìë§Œ 8ìë¦¬ì¸ ê²½ìš° (YYYYMMDD)
        numbers_only = re.sub(r'[^\d]', '', date_str)
        if len(numbers_only) == 8:
            return f"{numbers_only[:4]}-{numbers_only[4:6]}-{numbers_only[6:8]}"
        
        logger.debug(f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: '{date_str}' -> None")
        return None
    
    def _get_best_value_from_responses(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]], key: str) -> str:
        """first_responseì™€ second_response ì¤‘ì—ì„œ ìœ íš¨í•œ ê°’ì´ ìˆëŠ” ê²ƒì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        def is_valid_value(value):
            return value and value not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        # first_responseì—ì„œ ê°’ í™•ì¸ (ìš°ì„ ìˆœìœ„)
        if first_response and key in first_response:
            first_value = first_response.get(key, "")
            if is_valid_value(first_value):
                logger.debug(f"{key} ê°’ì„ first_responseì—ì„œ ì‚¬ìš©: {first_value}")
                return first_value
        
        # second_responseì—ì„œ ê°’ í™•ì¸
        if second_response and key in second_response:
            second_value = second_response.get(key, "")
            if is_valid_value(second_value):
                logger.debug(f"{key} ê°’ì„ second_responseì—ì„œ ì‚¬ìš©: {second_value}")
                return second_value
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return ""
    
    def _natural_sort_key(self, path: Path) -> tuple:
        """í´ë”ëª…ì˜ ìˆ«ì ë¶€ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ìì—° ì •ë ¬ì„ ìœ„í•œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        import re
        
        folder_name = path.name
        # ìˆ«ì_ì œëª© íŒ¨í„´ì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
        match = re.match(r'^(\d+)_(.*)$', folder_name)
        if match:
            number = int(match.group(1))
            title = match.group(2)
            return (number, title)
        else:
            # ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ë§¨ ë’¤ë¡œ
            return (float('inf'), folder_name)
    
    def _process_attachments_separately(self, directory_path: Path, attach_force: bool = False) -> tuple[str, List[str]]:
        """ì²¨ë¶€íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ë‚´ìš©ì„ ê²°í•©í•˜ê³  íŒŒì¼ëª… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return "", []
        
        combined_content = ""
        attachment_filenames = []
        
        # ì²˜ë¦¬ ê°€ëŠ¥í•œ í™•ì¥ì ì •ì˜
        supported_extensions = {'.pdf', '.hwp', '.hwpx', '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.pptx', '.docx', '.xlsx'}
        
        for file_path in attachments_dir.iterdir():
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                filename = file_path.stem
                
                # í™•ì¥ìê°€ ì—†ê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                if not file_extension or file_extension not in supported_extensions:
                    logger.debug(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ê±´ë„ˆëœ€: {file_path.name}")
                    continue
                
                attachment_filenames.append(file_path.name)  # ì „ì²´ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
                logger.debug(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")
                
                # ì²¨ë¶€íŒŒì¼ëª….md íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                md_file_path = attachments_dir / f"{filename}.md"
                
                # attach_forceê°€ Trueì´ë©´ ê¸°ì¡´ .md íŒŒì¼ì„ ë¬´ì‹œí•˜ê³  ì›ë³¸ì—ì„œ ì¬ë³€í™˜
                if not attach_force and md_file_path.exists():
                    # .md íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì½ìŒ
                    try:
                        with open(md_file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            combined_content += f"\n\n=== {filename}.md ===\n{content}"
                            logger.debug(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì„±ê³µ: {filename}.md ({len(content)} ë¬¸ì)")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ .md ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {filename}.md")
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì‹¤íŒ¨: {e}")
                else:
                    # .md íŒŒì¼ì´ ì—†ê±°ë‚˜ attach_forceê°€ Trueì´ë©´ ì›ë³¸ íŒŒì¼ì„ ë³€í™˜
                    if attach_force and md_file_path.exists():
                        logger.info(f"--attach-force: ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì¬ë³€í™˜: {file_path.name}")
                    else:
                        logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹œì‘: {file_path.name}")
                        
                    try:
                        content = self.attachment_processor.process_single_file(file_path)
                        
                        if content and content.strip():
                            combined_content += f"\n\n=== {file_path.name} ===\n{content}"
                            logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì„±ê³µ: {file_path.name} ({len(content)} ë¬¸ì)")
                            
                            # ë³€í™˜ëœ ë‚´ìš©ì„ .md íŒŒì¼ë¡œ ì €ì¥
                            try:
                                with open(md_file_path, 'w', encoding='utf-8') as f:
                                    f.write(content)
                                logger.debug(f"ë³€í™˜ëœ ë‚´ìš©ì„ .mdë¡œ ì €ì¥: {md_file_path}")
                            except Exception as save_e:
                                logger.warning(f".md íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_e}")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ì—ì„œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {file_path.name}")
                        
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ ({file_path}): {e}")
        
        logger.info(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(attachment_filenames)}ê°œ íŒŒì¼, {len(combined_content)} ë¬¸ì")
        return combined_content.strip(), attachment_filenames
    
    def _analyze_with_ollama(self, content: str) -> tuple[Optional[Dict[str, Any]], str]:
        """Ollamaë¥¼ í†µí•´ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            return self.announcement_analyzer.analyze_announcement(content)
        except Exception as e:
            logger.error(f"Ollama ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, ""
    
    def _save_processing_result(
        self, 
        folder_name: str, 
        site_code: str, 
        content_md: str, 
        combined_content: str,
        attachment_filenames: List[str] = None,
        status: str = "ollama",
        exclusion_keywords: List[str] = None,
        exclusion_reason: str = None,
        error_message: str = None,
        force: bool = False
    ) -> Optional[int]:
        """ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                if force:
                    # UPSERT ë¡œì§
                    sql = text("""
                        INSERT INTO announcement_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                        ON DUPLICATE KEY UPDATE
                            content_md = VALUES(content_md),
                            combined_content = VALUES(combined_content),
                            attachment_filenames = VALUES(attachment_filenames),
                            exclusion_keyword = VALUES(exclusion_keyword),
                            exclusion_reason = VALUES(exclusion_reason),
                            processing_status = VALUES(processing_status),
                            error_message = VALUES(error_message),
                            updated_at = NOW()
                    """)
                else:
                    # ì¼ë°˜ INSERT
                    sql = text("""
                        INSERT INTO announcement_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                    """)
                
                params = {
                    'folder_name': folder_name,
                    'site_code': site_code,
                    'content_md': content_md,
                    'combined_content': combined_content,
                    'attachment_filenames': ', '.join(attachment_filenames) if attachment_filenames else None,
                    'exclusion_keyword': ', '.join(exclusion_keywords) if exclusion_keywords else None,
                    'exclusion_reason': exclusion_reason,
                    'processing_status': status,
                    'error_message': error_message
                }
                
                result = session.execute(sql, params)
                session.commit()
                
                record_id = result.lastrowid
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                return record_id
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def _update_processing_result(
        self,
        record_id: int,
        ollama_response: Optional[Dict[str, Any]],
        ollama_prompt: str,
        first_response: Optional[Dict[str, Any]] = None,
        status: str = "ollama"
    ) -> bool:
        """ê¸°ì¡´ ë ˆì½”ë“œì— Ollama ë¶„ì„ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                # ì¶”ì¶œëœ ë°ì´í„° ì¤€ë¹„
                extracted_data = {}
                if ollama_response:
                    # URLê³¼ ë‚ ì§œëŠ” first_responseì™€ ollama_response ì¤‘ ê°’ì´ ìˆëŠ” ê²ƒì„ ìš°ì„  ì‚¬ìš©
                    extracted_url = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_URL")
                    extracted_announcement_date = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_ANNOUNCEMENT_DATE")
                    
                    extracted_data = {
                        'extracted_title': ollama_response.get("EXTRACTED_TITLE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_target': ollama_response.get("EXTRACTED_TARGET", "ì •ë³´ ì—†ìŒ"),
                        'extracted_target_type': ollama_response.get("EXTRACTED_TARGET_TYPE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_amount': ollama_response.get("EXTRACTED_AMOUNT", "ì •ë³´ ì—†ìŒ"),
                        'extracted_period': ollama_response.get("EXTRACTED_PERIOD", "ì •ë³´ ì—†ìŒ"),
                        'extracted_schedule': ollama_response.get("EXTRACTED_SCHEDULE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_content': ollama_response.get("EXTRACTED_CONTENT", "ì •ë³´ ì—†ìŒ"),
                        'extracted_announcement_date': extracted_announcement_date,
                        'original_url': extracted_url,
                        'formatted_announcement_date': self._format_date_to_standard(extracted_announcement_date)
                    }
                
                sql = text("""
                    UPDATE announcement_processing SET
                        ollama_first_response = :ollama_first_response,
                        ollama_response = :ollama_response,
                        ollama_prompt = :ollama_prompt,
                        extracted_title = :extracted_title,
                        extracted_target = :extracted_target,
                        extracted_target_type = :extracted_target_type,
                        extracted_amount = :extracted_amount,
                        extracted_period = :extracted_period,
                        extracted_schedule = :extracted_schedule,
                        extracted_content = :extracted_content,
                        extracted_announcement_date = :extracted_announcement_date,
                        original_url = :original_url,
                        formatted_announcement_date = :formatted_announcement_date,
                        processing_status = :processing_status,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                params = {
                    'record_id': record_id,
                    'ollama_first_response': json.dumps(first_response, ensure_ascii=False) if first_response else None,
                    'ollama_response': json.dumps(ollama_response, ensure_ascii=False) if ollama_response else None,
                    'ollama_prompt': ollama_prompt,
                    'processing_status': status,
                    **extracted_data
                }
                
                session.execute(sql, params)
                session.commit()
                
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                
                # í™”ë©´ì— ê²°ê³¼ í‘œì‹œ
                if ollama_response:
                    self._display_ollama_results(ollama_response)
                
                return True
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _display_ollama_results(self, ollama_response: Dict[str, Any]):
        """Ollama ë¶„ì„ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."""
        print("  ğŸ¤– Ollama ë¶„ì„ ê²°ê³¼:")
        if "EXTRACTED_TARGET" in ollama_response and ollama_response["EXTRACTED_TARGET"]:
            print(f"     ğŸ“Œ ì§€ì›ëŒ€ìƒ: {ollama_response['EXTRACTED_TARGET'][:100]}...")
        if "EXTRACTED_TARGET_TYPE" in ollama_response and ollama_response["EXTRACTED_TARGET_TYPE"]:
            print(f"     ğŸ·ï¸ ì§€ì›ëŒ€ìƒë¶„ë¥˜: {ollama_response['EXTRACTED_TARGET_TYPE'][:50]}...")
        if "EXTRACTED_AMOUNT" in ollama_response and ollama_response["EXTRACTED_AMOUNT"]:
            print(f"     ğŸ’° ì§€ì›ê¸ˆì•¡: {ollama_response['EXTRACTED_AMOUNT'][:100]}...")
        if "EXTRACTED_TITLE" in ollama_response and ollama_response["EXTRACTED_TITLE"]:
            print(f"     ğŸ“ ì œëª©: {ollama_response['EXTRACTED_TITLE'][:100]}...")
        if "EXTRACTED_ANNOUNCEMENT_DATE" in ollama_response and ollama_response["EXTRACTED_ANNOUNCEMENT_DATE"]:
            print(f"     ğŸ“… ë“±ë¡ì¼: {ollama_response['EXTRACTED_ANNOUNCEMENT_DATE'][:50]}...")


def get_directory_and_site_code(args) -> tuple[Path, str]:
    """ëª…ë ¹í–‰ ì¸ì ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ë””ë ‰í† ë¦¬ì™€ ì‚¬ì´íŠ¸ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    # ë””ë ‰í† ë¦¬ ê²°ì •
    if args.data:
        directory_name = args.data
    else:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        directory_name = os.getenv("DEFAULT_DIR", "data")
    
    # ì‚¬ì´íŠ¸ ì½”ë“œ ê²°ì •
    if not args.site_code:
        logger.error("ì‚¬ì´íŠ¸ ì½”ë“œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    site_code = args.site_code
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ìƒì„±
    current_dir = Path.cwd()
    base_directory = current_dir / directory_name
    
    if not base_directory.exists():
        logger.error(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_directory}")
        sys.exit(1)
    
    logger.info(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬: {base_directory}")
    logger.info(f"ì‚¬ì´íŠ¸ ì½”ë“œ: {site_code}")
    
    return base_directory, site_code


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ê³µê³  ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ë° ë¶„ì„ í”„ë¡œê·¸ë¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python announcement_processor.py --data data.enhanced --site-code acci
  python announcement_processor.py --data data.origin --site-code cbt
  python announcement_processor.py --site-code acci  # í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ì‚¬ìš©
  python announcement_processor.py --data data.enhanced --site-code acci -r  # ì¬ê·€ì  ì²˜ë¦¬
  python announcement_processor.py --site-code acci --attach-force  # ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬
        """
    )
    
    parser.add_argument(
        "--data", 
        type=str,
        help="ë°ì´í„° ë””ë ‰í† ë¦¬ëª… (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ë˜ëŠ” 'data')"
    )
    
    parser.add_argument(
        "--site-code", 
        type=str,
        required=True,
        help="ì‚¬ì´íŠ¸ ì½”ë“œ (í•„ìˆ˜, ì˜ˆ: acci, cbt, andongcci ë“±)"
    )
    
    parser.add_argument(
        "--skip-processed", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© ê±´ë„ˆë›°ê¸° (ê¸°ë³¸ ë™ì‘)"
    )
    
    parser.add_argument(
        "--force", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬"
    )
    
    parser.add_argument(
        "-r", "--recursive",
        action="store_true",
        help="í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ëª¨ë“  í•˜ìœ„ ê²½ë¡œì˜ content.mdë‚˜ attachmentsë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬)"
    )
    
    parser.add_argument(
        "--attach-force",
        action="store_true",
        help="ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ (ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì›ë³¸ íŒŒì¼ì—ì„œ ë‹¤ì‹œ ë³€í™˜)"
    )
    
    args = parser.parse_args()
    
    try:
        # ë””ë ‰í† ë¦¬ì™€ ì‚¬ì´íŠ¸ì½”ë“œ ê²°ì •
        base_directory, site_code = get_directory_and_site_code(args)
        
        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        logger.info("ê³µê³  ì²˜ë¦¬ í”„ë¡œê·¸ë¨ ì‹œì‘")
        processor = AnnouncementProcessor(attach_force=args.attach_force)
        
        # ì²˜ë¦¬ ì‹¤í–‰
        results = processor.process_site_directories(base_directory, site_code, args.recursive, args.force, args.attach_force)
        
        # ê²°ê³¼ ì¶œë ¥ (process_site_directoriesì—ì„œ ì´ë¯¸ ìƒì„¸ ì¶œë ¥ë¨)
        print(f"\n=== ìµœì¢… ìš”ì•½ ===")
        print(f"ì „ì²´ ëŒ€ìƒ: {results['total']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {results['success']}ê°œ") 
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {results['failed']}ê°œ")
        print(f"ê±´ë„ˆë›´ í•­ëª©: {results['skipped']}ê°œ")
        
        if results['failed'] > 0:
            print(f"\nì‹¤íŒ¨í•œ í•­ëª©ì´ {results['failed']}ê°œ ìˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
        else:
            print("\nëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            sys.exit(0)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()