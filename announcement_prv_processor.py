#!/usr/bin/env python3
"""
Í≥µÍ≥† Ï≤òÎ¶¨ Î©îÏù∏ ÌîÑÎ°úÍ∑∏Îû®

ÏÇ¨Ïö©Î≤ï:
    python announcement_prv_processor.py [ÎîîÎ†âÌÜ†Î¶¨Î™Ö] [ÏÇ¨Ïù¥Ìä∏ÏΩîÎìú]
    
ÏòàÏãú:
    python announcement_prv_processor.py data.origin cbt
    python announcement_prv_processor.py  # ÌôòÍ≤ΩÎ≥ÄÏàò ÏÇ¨Ïö©
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import List, Dict, Any, Optional

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏Î•º Python pathÏóê Ï∂îÍ∞Ä
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.config.config import ConfigManager
from src.config.logConfig import setup_logging
from src.utils.attachmentProcessor import AttachmentProcessor
from src.utils.ollamaClient import AnnouncementPrvAnalyzer
from src.models.announcementPrvDatabase import AnnouncementPrvDatabaseManager, create_announcement_prv_tables
from src.utils.announcementFilter import AnnouncementFilter

logger = setup_logging(__name__)
config = ConfigManager().get_config()


class AnnouncementPrvProcessor:
    """Í≥µÍ≥† Ï≤òÎ¶¨ Î©îÏù∏ ÌÅ¥ÎûòÏä§"""
    
    def __init__(self, attach_force: bool = False):
        self.attachment_processor = AttachmentProcessor()
        self.announcement_analyzer = AnnouncementPrvAnalyzer()
        self.db_manager = AnnouncementPrvDatabaseManager()
        self.filter = AnnouncementFilter()
        self.attach_force = attach_force
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÖåÏù¥Î∏î ÏÉùÏÑ± (ÏóÜÎäî Í≤ΩÏö∞)
        self._ensure_database_tables()
        
        # Ï†úÏô∏ ÌÇ§ÏõåÎìú Î°úÎìú
        self.exclusion_keywords = self._load_exclusion_keywords()
    
    def _ensure_database_tables(self):
        """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÖåÏù¥Î∏îÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ≥† ÏÉùÏÑ±Ìï©ÎãàÎã§."""
        try:
            if self.db_manager.test_connection():
                self.db_manager.create_tables()
                logger.info("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÖåÏù¥Î∏î ÌôïÏù∏/ÏÉùÏÑ± ÏôÑÎ£å")
            else:
                logger.warning("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ïã§Ìå® - Í≥ÑÏÜç ÏßÑÌñâÌï©ÎãàÎã§ (DB Ï†ÄÏû• Î∂àÍ∞Ä)")
        except Exception as e:
            logger.warning(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e} - Í≥ÑÏÜç ÏßÑÌñâÌï©ÎãàÎã§ (DB Ï†ÄÏû• Î∂àÍ∞Ä)")
    
    def _load_exclusion_keywords(self) -> List[Dict[str, Any]]:
        """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú Ï†úÏô∏ ÌÇ§ÏõåÎìúÎ•º Î°úÎìúÌï©ÎãàÎã§."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT EXCLUSION_ID, KEYWORD, DESCRIPTION
                    FROM EXCLUSION_KEYWORDS
                    WHERE IS_ACTIVE = TRUE
                    ORDER BY EXCLUSION_ID
                """))
                
                keywords = []
                for row in result:
                    keywords.append({
                        'id': row[0],
                        'keyword': row[1],
                        'description': row[2]
                    })
                
                logger.info(f"Ï†úÏô∏ ÌÇ§ÏõåÎìú Î°úÎìú ÏôÑÎ£å: {len(keywords)}Í∞ú")
                return keywords
                
        except Exception as e:
            logger.warning(f"Ï†úÏô∏ ÌÇ§ÏõåÎìú Î°úÎìú Ïã§Ìå®: {e}")
            return []
    
    def process_directory(self, directory_path: Path, site_code: str) -> bool:
        """
        Îã®Ïùº ÎîîÎ†âÌÜ†Î¶¨Î•º Ï≤òÎ¶¨Ìï©ÎãàÎã§.
        
        Args:
            directory_path: Ï≤òÎ¶¨Ìï† ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú
            site_code: ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú
            
        Returns:
            Ï≤òÎ¶¨ ÏÑ±Í≥µ Ïó¨Î∂Ä
        """
        folder_name = directory_path.name
        return self.process_directory_with_custom_name(directory_path, site_code, folder_name)
    
    def _collect_attachment_info(self, directory_path: Path) -> List[Dict[str, Any]]:
        """Ï≤®Î∂ÄÌååÏùº Ï†ïÎ≥¥Î•º ÏàòÏßëÌï©ÎãàÎã§."""
        attachment_info = []
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return attachment_info
        
        try:
            # Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ Í≤∞Í≥º Í∞ÄÏ†∏Ïò§Í∏∞
            # attachment_results = self.attachment_processor.process_directory_attachments(directory_path)
            
            # Ïã§Ï†ú ÌååÏùºÎì§Í≥º Îß§Ïπ≠
            for file_path in attachments_dir.iterdir():
                if file_path.is_file():
                    filename = file_path.stem
                    file_extension = file_path.suffix
                    
                    # ÌååÏùº ÌÅ¨Í∏∞ Í∞ÄÏ†∏Ïò§Í∏∞
                    try:
                        file_size = file_path.stat().st_size
                    except:
                        file_size = 0
                    
                    # Î≥ÄÌôò Í≤∞Í≥º Ï∞æÍ∏∞
                    # converted_content = attachment_results.get(filename, "")
                    # conversion_success = bool(converted_content)
                    
                    # Î≥ÄÌôò Î∞©Î≤ï Ï∂îÏ†ï
                    # conversion_method = self._guess_conversion_method(file_extension)
                    
                    attachment_info.append({
                        "filename": filename,
                        "file_extension": file_extension,
                        "file_path": str(file_path),
                        "file_size": file_size,
                        # "converted_content": converted_content,
                        # "conversion_method": conversion_method,
                        # "conversion_success": conversion_success
                    })
            
            logger.info(f"Ï≤®Î∂ÄÌååÏùº Ï†ïÎ≥¥ ÏàòÏßë ÏôÑÎ£å: {len(attachment_info)}Í∞ú")
            
        except Exception as e:
            logger.error(f"Ï≤®Î∂ÄÌååÏùº Ï†ïÎ≥¥ ÏàòÏßë Ï§ë Ïò§Î•ò: {e}")
        
        return attachment_info
    
    def _guess_conversion_method(self, file_extension: str) -> str:
        """ÌååÏùº ÌôïÏû•ÏûêÏóê Îî∞Î•∏ Î≥ÄÌôò Î∞©Î≤ïÏùÑ Ï∂îÏ†ïÌï©ÎãàÎã§."""
        ext_lower = file_extension.lower()
        
        if ext_lower == '.pdf':
            return 'pdf_docling'
        elif ext_lower in ['.hwp', '.hwpx']:
            return 'hwp_markdown'
        elif ext_lower in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']:
            return 'ocr'
        else:
            return 'unknown'
    
    def _find_target_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        Ï≤òÎ¶¨Ìï† ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Îì§ÏùÑ Ï∞æÏäµÎãàÎã§.
        
        Args:
            base_dir: Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨
            site_code: ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú
            recursive: Ïû¨Í∑ÄÏ†Å Í≤ÄÏÉâ Ïó¨Î∂Ä
            force: Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨Ìï†ÏßÄ Ïó¨Î∂Ä
            
        Returns:
            Ï≤òÎ¶¨ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Î™©Î°ù
        """
        site_dir = base_dir / site_code
        
        if not site_dir.exists():
            logger.error(f"ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏùå: {site_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # Ïû¨Í∑ÄÏ†ÅÏúºÎ°ú Î™®Îì† ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú content.md ÎòêÎäî attachments Ìè¥ÎçîÍ∞Ä ÏûàÎäî ÎîîÎ†âÌÜ†Î¶¨ Ï∞æÍ∏∞
            logger.info(f"Ïû¨Í∑ÄÏ†Å ÎîîÎ†âÌÜ†Î¶¨ Í≤ÄÏÉâ ÏãúÏûë: {site_dir}")
            
            for root_path in site_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md ÌååÏùºÏù¥ ÏûàÍ±∞ÎÇò attachments Ìè¥ÎçîÍ∞Ä ÏûàÎäî ÎîîÎ†âÌÜ†Î¶¨Îßå ÎåÄÏÉÅÏúºÎ°ú Ìï®
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Î∞úÍ≤¨: {root_path.relative_to(site_dir)}")
        else:
            # Í∏∞Î≥∏ ÎèôÏûë: ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Ïùò ÏßÅÏ†ë ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨Îßå Í≤ÄÏÉâÌïòÍ≥† Ìè¥ÎçîÎ™ÖÏúºÎ°ú Ï†ïÎ†¨
            all_directories = [d for d in site_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"Î∞úÍ≤¨Îêú Ï†ÑÏ≤¥ ÎîîÎ†âÌÜ†Î¶¨: {len(target_directories)}Í∞ú")
        
        # Ï≤òÏùå Î™á Í∞ú Ìè¥ÎçîÎ™Ö Î°úÍπÖ
        if target_directories:
            logger.info(f"Ï≤´ 5Í∞ú Ìè¥Îçî: {[d.name for d in target_directories[:5]]}")
        
        # force ÏòµÏÖòÏù¥ ÏóÜÏùÑ ÎïåÎßå Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìè¥Îçî Ï†úÏô∏ (DBÏóêÏÑú prvÎ°ú Ï†ÄÏû•Îêú Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå)
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders("prv"))
            
            filtered_directories = []
            for directory in target_directories:
                # ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Î°úÎ∂ÄÌÑ∞Ïùò ÏÉÅÎåÄ Í≤ΩÎ°úÎ•º Ìè¥ÎçîÎ™ÖÏúºÎ°ú ÏÇ¨Ïö©
                relative_path = directory.relative_to(site_dir)
                folder_name = str(relative_path).replace("/", "_")  # Ïä¨ÎûòÏãúÎ•º Ïñ∏ÎçîÏä§ÏΩîÏñ¥Î°ú Î≥ÄÍ≤Ω
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìè¥Îçî Í±¥ÎÑàÎúÄ: {folder_name}")
            
            logger.info(f"Ï†ÑÏ≤¥ Î∞úÍ≤¨Îêú ÎîîÎ†âÌÜ†Î¶¨: {len(target_directories)}Í∞ú")
            logger.info(f"Ï≤òÎ¶¨ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨: {len(filtered_directories)}Í∞ú")
            logger.info(f"Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìè¥Îçî: {len(processed_folders)}Í∞ú")
            
            return filtered_directories
        else:
            # force ÏòµÏÖòÏù¥ ÏûàÏúºÎ©¥ Î™®Îì† ÎîîÎ†âÌÜ†Î¶¨ Î∞òÌôò
            logger.info(f"--force ÏòµÏÖò: Î™®Îì† ÎîîÎ†âÌÜ†Î¶¨ Ï≤òÎ¶¨ ({len(target_directories)}Í∞ú)")
            return target_directories
    
    def _find_prv_target_directories(self, city_dir: Path, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        PRVÏùò ÌäπÏ†ï ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú Ï≤òÎ¶¨Ìï† ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Îì§ÏùÑ Ï∞æÏäµÎãàÎã§.
        
        Args:
            city_dir: ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú (Ïòà: prv1/Í≤ΩÍ∏∞ÎèÑ/Í∞ÄÌèâÍµ∞)
            recursive: Ïû¨Í∑ÄÏ†Å Í≤ÄÏÉâ Ïó¨Î∂Ä
            force: Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨Ìï†ÏßÄ Ïó¨Î∂Ä
            
        Returns:
            Ï≤òÎ¶¨ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Î™©Î°ù
        """
        if not city_dir.exists():
            logger.error(f"ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏùå: {city_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # Ïû¨Í∑ÄÏ†ÅÏúºÎ°ú Î™®Îì† ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú content.md ÎòêÎäî attachments Ìè¥ÎçîÍ∞Ä ÏûàÎäî ÎîîÎ†âÌÜ†Î¶¨ Ï∞æÍ∏∞
            logger.info(f"Ïû¨Í∑ÄÏ†Å ÎîîÎ†âÌÜ†Î¶¨ Í≤ÄÏÉâ ÏãúÏûë: {city_dir}")
            
            for root_path in city_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md ÌååÏùºÏù¥ ÏûàÍ±∞ÎÇò attachments Ìè¥ÎçîÍ∞Ä ÏûàÎäî ÎîîÎ†âÌÜ†Î¶¨Îßå ÎåÄÏÉÅÏúºÎ°ú Ìï®
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Î∞úÍ≤¨: {root_path.relative_to(city_dir)}")
        else:
            # Í∏∞Î≥∏ ÎèôÏûë: ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨Ïùò ÏßÅÏ†ë ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨Îßå Í≤ÄÏÉâÌïòÍ≥† Ìè¥ÎçîÎ™ÖÏúºÎ°ú Ï†ïÎ†¨
            all_directories = [d for d in city_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ÏãúÍµ∞ {city_dir.name}ÏóêÏÑú Î∞úÍ≤¨Îêú Í≥µÍ≥† ÎîîÎ†âÌÜ†Î¶¨: {len(target_directories)}Í∞ú")
        
        # Ï≤òÏùå Î™á Í∞ú Ìè¥ÎçîÎ™Ö Î°úÍπÖ
        if target_directories:
            logger.debug(f"Ï≤´ 5Í∞ú Í≥µÍ≥† Ìè¥Îçî: {[d.name for d in target_directories[:5]]}")
        
        # force ÏòµÏÖòÏù¥ ÏóÜÏùÑ ÎïåÎßå Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìè¥Îçî Ï†úÏô∏ (DBÏóêÏÑú prvÎ°ú Ï†ÄÏû•Îêú Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå)
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders("prv"))
            
            filtered_directories = []
            for directory in target_directories:
                # ÏãúÍµ∞ Í≤ΩÎ°úÎ•º Ìè¨Ìï®Ìïú Ìè¥ÎçîÎ™Ö ÏÉùÏÑ± (DB Ï†ÄÏû• ÏãúÏôÄ ÎèôÏùºÌïú Î∞©Ïãù)
                city_path_from_base = str(city_dir).split('/')[-2:] # ÏßÄÏó≠/ÏãúÍµ∞ Ï∂îÏ∂ú
                city_path = '/'.join(city_path_from_base)
                relative_path = directory.relative_to(city_dir)
                folder_name = f"{city_path.replace('/', '_')}_{str(relative_path).replace('/', '_')}"
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìè¥Îçî Í±¥ÎÑàÎúÄ: {folder_name}")
            
            logger.info(f"ÏãúÍµ∞ {city_dir.name} - Ï†ÑÏ≤¥ Î∞úÍ≤¨: {len(target_directories)}Í∞ú, Ï≤òÎ¶¨ ÎåÄÏÉÅ: {len(filtered_directories)}Í∞ú")
            
            return filtered_directories
        else:
            # force ÏòµÏÖòÏù¥ ÏûàÏúºÎ©¥ Î™®Îì† ÎîîÎ†âÌÜ†Î¶¨ Î∞òÌôò
            logger.info(f"--force ÏòµÏÖò: ÏãúÍµ∞ {city_dir.name}Ïùò Î™®Îì† ÎîîÎ†âÌÜ†Î¶¨ Ï≤òÎ¶¨ ({len(target_directories)}Í∞ú)")
            return target_directories
    
    def process_all_sites(self, base_dir: Path, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        base_dir ÎÇ¥Ïùò Î™®Îì† ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Î•º Ï≤òÎ¶¨Ìï©ÎãàÎã§.
        
        Args:
            base_dir: Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ (Ïó¨Îü¨ ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Î•º Ìè¨Ìï®)
            recursive: Ïû¨Í∑ÄÏ†Å Ï≤òÎ¶¨ Ïó¨Î∂Ä
            force: Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨Ìï†ÏßÄ Ïó¨Î∂Ä
            attach_force: Ï≤®Î∂ÄÌååÏùº Í∞ïÏ†ú Ïû¨Ï≤òÎ¶¨ Ïó¨Î∂Ä
            
        Returns:
            Ï†ÑÏ≤¥ Ï≤òÎ¶¨ Í≤∞Í≥º ÌÜµÍ≥Ñ
        """
        if not base_dir.exists():
            logger.error(f"Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏùå: {base_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # base_dir ÎÇ¥Ïùò Î™®Îì† ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨ Ï∞æÍ∏∞
        site_directories = [d for d in base_dir.iterdir() if d.is_dir()]

        if not site_directories:
            logger.warning("Ï≤òÎ¶¨Ìï† ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏäµÎãàÎã§.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # Ï†ÑÏ≤¥ Í≤∞Í≥º ÌÜµÍ≥Ñ
        total_results = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        print(f"\n{'='*80}")
        print(f"Îã§Ï§ë ÏÇ¨Ïù¥Ìä∏ Í≥µÍ≥† Ï≤òÎ¶¨ ÏãúÏûë: {len(site_directories)}Í∞ú ÏÇ¨Ïù¥Ìä∏")
        print(f"Î∞úÍ≤¨Îêú ÏÇ¨Ïù¥Ìä∏: {[d.name for d in site_directories]}")
        print(f"{'='*80}")
        
        # Ï†ÑÏ≤¥ ÏãúÏûë ÏãúÍ∞Ñ Í∏∞Î°ù
        overall_start_time = time.time()
        
        # PRVÎäî 2depth Íµ¨Ï°∞: ÏßÄÏó≠/ÏãúÍµ∞/Í≥µÍ≥† 
        for region_idx, region_dir in enumerate(site_directories, 1):
            region_name = region_dir.name
            
            print(f"\nüåç [{region_idx}/{len(site_directories)}] ÏßÄÏó≠ Ï≤òÎ¶¨ ÏãúÏûë: {region_name}")
            print(f"{'‚îÄ'*60}")
            
            # Í∞Å ÏßÄÏó≠Ïùò ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨Îì§ Ï∞æÍ∏∞
            city_directories = [d for d in region_dir.iterdir() if d.is_dir()]
            
            if not city_directories:
                print(f"   ‚ö†Ô∏è {region_name}Ïóê ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏäµÎãàÎã§.")
                continue
                
            region_start_time = time.time()
            region_results = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
            
            for city_idx, city_dir in enumerate(city_directories, 1):
                city_name = city_dir.name
                site_code = "prv"  # PRV ÌîÑÎ°úÏÑ∏ÏÑúÎäî site_codeÎ•º "prv"Î°ú Í≥†Ï†ï
                
                print(f"\nüèòÔ∏è  [{city_idx}/{len(city_directories)}] ÏãúÍµ∞ Ï≤òÎ¶¨: {region_name}/{city_name} (DBÏ†ÄÏû•: {site_code})")
                
                city_start_time = time.time()
                
                # Í∞úÎ≥Ñ ÏãúÍµ∞ Ï≤òÎ¶¨ - 2depth Í≤ΩÎ°ú Ï†ÑÎã¨
                city_path = f"{region_name}/{city_name}"
                city_results = self.process_prv_city_directories(base_dir, city_path, recursive, force, attach_force)
                
                # ÏãúÍµ∞Î≥Ñ Í≤∞Í≥ºÎ•º ÏßÄÏó≠ Í≤∞Í≥ºÏóê Ìï©ÏÇ∞
                region_results["total"] += city_results["total"]
                region_results["success"] += city_results["success"]
                region_results["failed"] += city_results["failed"]
                region_results["skipped"] += city_results["skipped"]
                
                city_elapsed = time.time() - city_start_time
                
                print(f"     ‚úÖ {city_name} ÏôÑÎ£å: ÏÑ±Í≥µ {city_results['success']}, Ïã§Ìå® {city_results['failed']}, Í±¥ÎÑàÎõ¥ {city_results['skipped']} ({city_elapsed:.1f}Ï¥à)")
            
            # ÏßÄÏó≠Î≥Ñ Í≤∞Í≥ºÎ•º Ï†ÑÏ≤¥ Í≤∞Í≥ºÏóê Ìï©ÏÇ∞
            total_results["total"] += region_results["total"]
            total_results["success"] += region_results["success"]
            total_results["failed"] += region_results["failed"]
            total_results["skipped"] += region_results["skipped"]
            
            region_elapsed = time.time() - region_start_time
            
            print(f"\n‚úÖ ÏßÄÏó≠ '{region_name}' Ï≤òÎ¶¨ ÏôÑÎ£å ({region_elapsed:.1f}Ï¥à)")
            print(f"   Ï†ÑÏ≤¥ ÏÑ±Í≥µ: {region_results['success']}, Ïã§Ìå®: {region_results['failed']}, Í±¥ÎÑàÎõ¥: {region_results['skipped']}")
        
        # Ï†ÑÏ≤¥ Ï≤òÎ¶¨ ÏãúÍ∞Ñ Í≥ÑÏÇ∞
        overall_elapsed = time.time() - overall_start_time
        
        print(f"\n{'='*80}")
        print(f"üéâ Ï†ÑÏ≤¥ ÏÇ¨Ïù¥Ìä∏ Ï≤òÎ¶¨ ÏôÑÎ£å!")
        print(f"{'='*80}")
        print(f"Ï≤òÎ¶¨Ìïú ÏÇ¨Ïù¥Ìä∏: {len(site_directories)}Í∞ú")
        print(f"Ï†ÑÏ≤¥ ÎåÄÏÉÅ: {total_results['total']}Í∞ú")
        print(f"Ï≤òÎ¶¨ ÏÑ±Í≥µ: {total_results['success']}Í∞ú ({(total_results['success']/max(total_results['total'], 1))*100:.1f}%)")
        print(f"Ï≤òÎ¶¨ Ïã§Ìå®: {total_results['failed']}Í∞ú")
        print(f"Í±¥ÎÑàÎõ¥ Ìï≠Î™©: {total_results['skipped']}Í∞ú")
        print(f"")
        print(f"üìä Ï†ÑÏ≤¥ Ï≤òÎ¶¨ ÏãúÍ∞Ñ: {overall_elapsed:.1f}Ï¥à ({overall_elapsed/60:.1f}Î∂Ñ)")
        if total_results['total'] > 0:
            avg_time = overall_elapsed / total_results['total']
            print(f"Ìï≠Î™©Îãπ ÌèâÍ∑† ÏãúÍ∞Ñ: {avg_time:.1f}Ï¥à")
        print(f"{'='*80}")
        
        return total_results
        
    def process_site_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        ÌäπÏ†ï ÏÇ¨Ïù¥Ìä∏Ïùò Î™®Îì† ÎîîÎ†âÌÜ†Î¶¨Î•º Ï≤òÎ¶¨Ìï©ÎãàÎã§.
        
        Args:
            base_dir: Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨
            site_code: Ïã§Ï†ú ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Î™Ö
            recursive: Ïû¨Í∑ÄÏ†Å Ï≤òÎ¶¨ Ïó¨Î∂Ä
            force: Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨Ìï†ÏßÄ Ïó¨Î∂Ä
            attach_force: Ï≤®Î∂ÄÌååÏùº Í∞ïÏ†ú Ïû¨Ï≤òÎ¶¨ Ïó¨Î∂Ä
            
        Returns:
            Ï≤òÎ¶¨ Í≤∞Í≥º ÌÜµÍ≥Ñ
        """
        # PRV ÌîÑÎ°úÏÑ∏ÏÑúÏóêÏÑúÎäî DBÏóê "prv"Î°ú Ï†ÄÏû•
        db_site_code = "prv"
        
        # Ï≤òÎ¶¨Ìï† ÎîîÎ†âÌÜ†Î¶¨ Î™©Î°ù Ï∞æÍ∏∞
        target_directories = self._find_target_directories(base_dir, site_code, recursive, force)
        
        if not target_directories:
            logger.warning("Ï≤òÎ¶¨Ìï† ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏäµÎãàÎã§.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        site_dir = base_dir / site_code
        
        print(f"\n{'='*60}")
        print(f"Í≥µÍ≥† Ï≤òÎ¶¨ ÏãúÏûë: {site_code} (DB: {db_site_code}) ({total_count}Í∞ú Ìè¥Îçî)")
        print(f"{'='*60}")
        
        # ÏãúÏûë ÏãúÍ∞Ñ Í∏∞Î°ù
        start_time = time.time()
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # Í∞úÎ≥Ñ Ìï≠Î™© ÏãúÏûë ÏãúÍ∞Ñ
                item_start_time = time.time()
                
                # ÏÇ¨Ïù¥Ìä∏ ÎîîÎ†âÌÜ†Î¶¨Î°úÎ∂ÄÌÑ∞Ïùò ÏÉÅÎåÄ Í≤ΩÎ°úÎ•º Ìè¥ÎçîÎ™ÖÏúºÎ°ú ÏÇ¨Ïö©
                relative_path = directory.relative_to(site_dir)
                folder_name = str(relative_path).replace("/", "_")  # Ïä¨ÎûòÏãúÎ•º Ïñ∏ÎçîÏä§ÏΩîÏñ¥Î°ú Î≥ÄÍ≤Ω
                
                progress_pct = (i / total_count) * 100
                print(f"\n[{i}/{total_count} : {progress_pct:.1f}%] {folder_name}")
                
                # Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™© ÌôïÏù∏ (force ÏòµÏÖòÏù¥ ÏóÜÏùÑ ÎïåÎßå)
                if not force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"  ‚úì Ïù¥ÎØ∏ Ï≤òÎ¶¨Îê®, Í±¥ÎÑàÎúÄ ({skip_elapsed:.1f}Ï¥à)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    print("  üîÑ Ïù¥ÎØ∏ Ï≤òÎ¶¨Îê®, --force ÏòµÏÖòÏúºÎ°ú Ïû¨Ï≤òÎ¶¨")
                
                success = self.process_directory_with_custom_name(directory, db_site_code, folder_name, attach_force, force)
                
                # Í∞úÎ≥Ñ Ìï≠Î™© Ï≤òÎ¶¨ ÏãúÍ∞Ñ Í≥ÑÏÇ∞
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"  ‚úì Ï≤òÎ¶¨ ÏôÑÎ£å ({item_elapsed:.1f}Ï¥à)")
                else:
                    results["failed"] += 1
                    print(f"  ‚úó Ï≤òÎ¶¨ Ïã§Ìå® ({item_elapsed:.1f}Ï¥à)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"  ‚úó ÏòàÏô∏ Î∞úÏÉù: {str(e)[:100]}... ({error_elapsed:.1f}Ï¥à)")
                logger.error(f"Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò ({directory}): {e}")
        
        # Ï¢ÖÎ£å ÏãúÍ∞Ñ Î∞è ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        end_time = time.time()
        total_elapsed = end_time - start_time
        processed_count = results['success'] + results['failed']  # Ïã§Ï†ú Ï≤òÎ¶¨Ìïú Í∞úÏàò (Í±¥ÎÑàÎõ¥ Í≤É Ï†úÏô∏)
        
        print(f"\n{'='*60}")
        print(f"Ï≤òÎ¶¨ ÏôÑÎ£å: {results['success']}/{total_count} ÏÑ±Í≥µ ({(results['success']/total_count)*100:.1f}%)")
        print(f"Í±¥ÎÑàÎúÄ: {results['skipped']}, Ïã§Ìå®: {results['failed']}")
        print(f"")
        print(f"üìä Ï≤òÎ¶¨ ÏãúÍ∞Ñ ÌÜµÍ≥Ñ:")
        print(f"   Ï¥ù ÏÜåÏöî ÏãúÍ∞Ñ: {total_elapsed:.1f}Ï¥à ({total_elapsed/60:.1f}Î∂Ñ)")
        
        if processed_count > 0:
            avg_time_per_item = total_elapsed / processed_count
            print(f"   Ï≤òÎ¶¨Ìïú Ìï≠Î™©Îãπ ÌèâÍ∑† ÏãúÍ∞Ñ: {avg_time_per_item:.1f}Ï¥à")
        
        if results['success'] > 0:
            avg_time_per_success = total_elapsed / results['success'] 
            print(f"   ÏÑ±Í≥µÌïú Ìï≠Î™©Îãπ ÌèâÍ∑† ÏãúÍ∞Ñ: {avg_time_per_success:.1f}Ï¥à")
        
        print(f"{'='*60}")
        
        logger.info(f"Ï≤òÎ¶¨ ÏôÑÎ£å - Ï†ÑÏ≤¥: {results['total']}, ÏÑ±Í≥µ: {results['success']}, Ïã§Ìå®: {results['failed']}, Í±¥ÎÑàÎúÄ: {results['skipped']}")
        
        return results
    
    def process_prv_city_directories(self, base_dir: Path, city_path: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        PRV 2depth Íµ¨Ï°∞ÏóêÏÑú ÌäπÏ†ï ÏãúÍµ∞Ïùò ÎîîÎ†âÌÜ†Î¶¨Îì§ÏùÑ Ï≤òÎ¶¨Ìï©ÎãàÎã§.
        
        Args:
            base_dir: Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ 
            city_path: ÏãúÍµ∞ Í≤ΩÎ°ú (Ïòà: "Í≤ΩÍ∏∞ÎèÑ/Í∞ÄÌèâÍµ∞")
            recursive: Ïû¨Í∑ÄÏ†Å Ï≤òÎ¶¨ Ïó¨Î∂Ä
            force: Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨Ìï†ÏßÄ Ïó¨Î∂Ä
            attach_force: Ï≤®Î∂ÄÌååÏùº Í∞ïÏ†ú Ïû¨Ï≤òÎ¶¨ Ïó¨Î∂Ä
            
        Returns:
            Ï≤òÎ¶¨ Í≤∞Í≥º ÌÜµÍ≥Ñ
        """
        # PRV ÌîÑÎ°úÏÑ∏ÏÑúÏóêÏÑúÎäî DBÏóê "prv"Î°ú Ï†ÄÏû•
        db_site_code = "prv"
        
        # Ïã§Ï†ú ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú
        city_dir = base_dir / city_path
        
        if not city_dir.exists():
            logger.warning(f"ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏùå: {city_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # Ï≤òÎ¶¨Ìï† ÎîîÎ†âÌÜ†Î¶¨ Î™©Î°ù Ï∞æÍ∏∞ (ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Í≥µÍ≥† Ìè¥ÎçîÎì§)
        target_directories = self._find_prv_target_directories(city_dir, recursive, force)
        
        if not target_directories:
            logger.warning(f"Ï≤òÎ¶¨Ìï† Í≥µÍ≥† ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏùå: {city_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # Í∞úÎ≥Ñ Ìï≠Î™© ÏãúÏûë ÏãúÍ∞Ñ
                item_start_time = time.time()
                
                # ÏãúÍµ∞ ÎîîÎ†âÌÜ†Î¶¨Î°úÎ∂ÄÌÑ∞Ïùò ÏÉÅÎåÄ Í≤ΩÎ°úÎ•º Ìè¥ÎçîÎ™ÖÏúºÎ°ú ÏÇ¨Ïö©ÌïòÎêò, ÏãúÍµ∞ Í≤ΩÎ°úÎèÑ Ìè¨Ìï®
                relative_path = directory.relative_to(city_dir)
                folder_name = f"{city_path.replace('/', '_')}_{str(relative_path).replace('/', '_')}"
                
                progress_pct = (i / total_count) * 100
                print(f"     [{i}/{total_count} : {progress_pct:.1f}%] {relative_path.name}")
                
                # Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™© ÌôïÏù∏ (force ÏòµÏÖòÏù¥ ÏóÜÏùÑ ÎïåÎßå)
                if not force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"       ‚úì Ïù¥ÎØ∏ Ï≤òÎ¶¨Îê®, Í±¥ÎÑàÎúÄ ({skip_elapsed:.1f}Ï¥à)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    print("       üîÑ Ïù¥ÎØ∏ Ï≤òÎ¶¨Îê®, --force ÏòµÏÖòÏúºÎ°ú Ïû¨Ï≤òÎ¶¨")
                
                success = self.process_directory_with_custom_name(directory, db_site_code, folder_name, attach_force, force)
                
                # Í∞úÎ≥Ñ Ìï≠Î™© Ï≤òÎ¶¨ ÏãúÍ∞Ñ Í≥ÑÏÇ∞
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"       ‚úì Ï≤òÎ¶¨ ÏôÑÎ£å ({item_elapsed:.1f}Ï¥à)")
                else:
                    results["failed"] += 1
                    print(f"       ‚úó Ï≤òÎ¶¨ Ïã§Ìå® ({item_elapsed:.1f}Ï¥à)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"       ‚úó ÏòàÏô∏ Î∞úÏÉù: {str(e)[:50]}... ({error_elapsed:.1f}Ï¥à)")
                logger.error(f"Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò ({directory}): {e}")
        
        logger.info(f"ÏãúÍµ∞ Ï≤òÎ¶¨ ÏôÑÎ£å - Ï†ÑÏ≤¥: {results['total']}, ÏÑ±Í≥µ: {results['success']}, Ïã§Ìå®: {results['failed']}, Í±¥ÎÑàÎúÄ: {results['skipped']}")
        
        return results
    
    def process_directory_with_custom_name(self, directory_path: Path, site_code: str, folder_name: str, attach_force: bool = False, force: bool = False) -> bool:
        """
        ÏÇ¨Ïö©Ïûê Ï†ïÏùò Ìè¥ÎçîÎ™ÖÏúºÎ°ú ÎîîÎ†âÌÜ†Î¶¨Î•º Ï≤òÎ¶¨Ìï©ÎãàÎã§.
        
        Args:
            directory_path: Ï≤òÎ¶¨Ìï† ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú
            site_code: ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú
            folder_name: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•Ìï† Ìè¥ÎçîÎ™Ö
            attach_force: Ï≤®Î∂ÄÌååÏùº Í∞ïÏ†ú Ïû¨Ï≤òÎ¶¨ Ïó¨Î∂Ä
            force: Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨Ìï†ÏßÄ Ïó¨Î∂Ä
            
        Returns:
            Ï≤òÎ¶¨ ÏÑ±Í≥µ Ïó¨Î∂Ä
        """
        logger.info(f"ÎîîÎ†âÌÜ†Î¶¨ Ï≤òÎ¶¨ ÏãúÏûë: {folder_name}")
        
        try:
            # 0. Ï§ëÎ≥µ Ï≤òÎ¶¨ Ï≤¥ÌÅ¨ (force ÏòµÏÖòÏù¥ ÏóÜÏùÑ ÎïåÎßå)
            if not force:
                if self.db_manager.is_already_processed(folder_name, site_code):
                    logger.info(f"Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìè¥Îçî Í±¥ÎÑàÎúÄ: {folder_name}")
                    return True  # ÏÑ±Í≥µÏúºÎ°ú Ï≤òÎ¶¨ (Ïù¥ÎØ∏ Ï≤òÎ¶¨Îê®)
            
            # 1. Ï†úÏô∏ ÌÇ§ÏõåÎìú Ï≤¥ÌÅ¨
            excluded_keywords = self._check_exclusion_keywords(folder_name)
            
            # 2. content.md ÌååÏùº ÏùΩÍ∏∞
            content_md_path = directory_path / "content.md"
            content_md = ""
            
            if content_md_path.exists():
                try:
                    with open(content_md_path, 'r', encoding='utf-8') as f:
                        content_md = f.read()
                    logger.info(f"content.md ÏùΩÍ∏∞ ÏôÑÎ£å: {len(content_md)} Î¨∏Ïûê")
                except Exception as e:
                    logger.error(f"content.md ÏùΩÍ∏∞ Ïã§Ìå®: {e}")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, "", 
                        status="ollama", error_message=f"content.md ÏùΩÍ∏∞ Ïã§Ìå®: {e}"
                    )
            else:
                logger.warning(f"content.md ÌååÏùºÏù¥ ÏóÜÏùå: {content_md_path}")
            
            # 3. Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ (content.mdÏôÄ Î∂ÑÎ¶¨)
            try:
                combined_content, attachment_filenames = self._process_attachments_separately(directory_path, attach_force)
                
                if not content_md.strip() and not combined_content.strip():
                    logger.warning("Ï≤òÎ¶¨Ìï† ÎÇ¥Ïö©Ïù¥ ÏóÜÏùå")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, combined_content,
                        attachment_filenames=attachment_filenames,
                        status="ollama", error_message="Ï≤òÎ¶¨Ìï† ÎÇ¥Ïö©Ïù¥ ÏóÜÏùå"
                    )
                
                logger.info(f"Ï≤®Î∂ÄÌååÏùº ÎÇ¥Ïö© Ï≤òÎ¶¨ ÏôÑÎ£å: {len(combined_content)} Î¨∏Ïûê, ÌååÏùº {len(attachment_filenames)}Í∞ú")
                
            except Exception as e:
                logger.error(f"Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="ollama", error_message=f"Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ Ïã§Ìå®: {e}"
                )
            
            # 4. Ï†úÏô∏ ÌÇ§ÏõåÎìúÍ∞Ä ÏûàÎäî Í≤ΩÏö∞ Ï†úÏô∏ Ï≤òÎ¶¨
            if excluded_keywords:
                exclusion_msg = f"Ï†úÏô∏ ÌÇ§ÏõåÎìúÍ∞Ä ÏûÖÎ†•ÎêòÏñ¥ ÏûàÏäµÎãàÎã§: {', '.join(excluded_keywords)}"
                logger.info(f"Ï†úÏô∏ Ï≤òÎ¶¨: {folder_name} - {exclusion_msg}")
                
                return self._save_processing_result(
                    folder_name, site_code, content_md, combined_content,
                    attachment_filenames=attachment_filenames,
                    status="Ï†úÏô∏", exclusion_keywords=excluded_keywords,
                    exclusion_reason=exclusion_msg
                )
            
            # 5. Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê 1Ï∞® Ï†ÄÏû• (status: ollama)
            record_id = self._save_processing_result(
                folder_name, site_code, content_md, combined_content, 
                attachment_filenames=attachment_filenames,
                status="ollama", force=True  # force ÏòµÏÖòÏùÄ Ìï≠ÏÉÅ UPSERTÎ°ú Ï≤òÎ¶¨
            )

            #2025.09.03 TEMP  ÎÇòÏ§ëÏóê Ïù¥Í±∞ ÌíÄÏñ¥Ïïº Ìï®. ÌÖåÏä§Ìä∏Î•º ÏúÑÌï¥  Ïû†Ïãú              
            # if not record_id:
            #     logger.error("1Ï∞® Ï†ÄÏû• Ïã§Ìå®")
            #     return False
            
            # 6. content_mdÎ°ú Ï≤´Î≤àÏß∏ ollama Î∂ÑÏÑù
            print("  üìã 1Ï∞® Ollama Î∂ÑÏÑù Ï§ë (content.md)...")
            first_response = None
            first_prompt = ""
            need_second_analysis = False
            
            # EXTRACTED_TARGETÏù¥ ÏûàÎäîÏßÄ ÌôïÏù∏
            def has_valid_target(response):
                if not response:
                    return False
                target = response.get("EXTRACTED_TARGET", "")
                return target and target not in ["Ï†ïÎ≥¥ ÏóÜÏùå", "Ìï¥ÎãπÏóÜÏùå", ""]
            
            # IS_SUPPORT_PROGRAM ÌôïÏù∏
            def is_support_program(response):
                if not response:
                    return False
                return response.get("IS_SUPPORT_PROGRAM", False) == True
            
            if content_md.strip():
                first_response, first_prompt = self._analyze_with_ollama(content_md)
                
                # 2Ï∞® ÏßàÏùò Ï°∞Í±¥ ÌôïÏù∏: IS_SUPPORT_PROGRAM=true Ïù¥Î©¥ÏÑú ÏßÄÏõêÎåÄÏÉÅ Ï†ïÎ≥¥Í∞Ä ÏóÜÎäî Í≤ΩÏö∞Îßå
                need_second_analysis = (is_support_program(first_response) and not has_valid_target(first_response))
                
                if has_valid_target(first_response):
                    # ÏÑ±Í≥µ: ÏßÄÏõêÎåÄÏÉÅ Ï†ïÎ≥¥Í∞Ä ÏûàÏúºÎ©¥ ÏµúÏ¢Ö ÏùëÎãµÏúºÎ°ú ÏÇ¨Ïö©
                    logger.info("1Ï∞® Î∂ÑÏÑù ÏÑ±Í≥µ - content.mdÏóêÏÑú EXTRACTED_TARGET Ï∂îÏ∂úÎê®")
                    return self._update_processing_result(
                        record_id, first_response, first_prompt, status="ÏÑ±Í≥µ"
                    )
                elif not is_support_program(first_response):
                    # IS_SUPPORT_PROGRAM=falseÎ©¥ 2Ï∞® Î∂ÑÏÑù ÏóÜÏù¥ ÏôÑÎ£å
                    logger.info("1Ï∞® Î∂ÑÏÑù ÏôÑÎ£å - ÏßÄÏõêÏÇ¨ÏóÖÏù¥ ÏïÑÎãò (IS_SUPPORT_PROGRAM=false)")
                    return self._update_processing_result(
                        record_id, first_response, first_prompt, status="ÏÑ±Í≥µ"
                    )
                else:
                    # 2Ï∞® Î∂ÑÏÑùÏù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞ (IS_SUPPORT_PROGRAM=trueÏù¥Î©¥ÏÑú ÏßÄÏõêÎåÄÏÉÅ Ï†ïÎ≥¥ ÏóÜÏùå)
                    logger.info("1Ï∞® Î∂ÑÏÑù ÏôÑÎ£å - 2Ï∞® Î∂ÑÏÑù ÌïÑÏöî (IS_SUPPORT_PROGRAM=true, ÏßÄÏõêÎåÄÏÉÅ Ï†ïÎ≥¥ ÏóÜÏùå)")
            
            # 7. combined_contentÎ°ú ÎëêÎ≤àÏß∏ ollama Î∂ÑÏÑù (IS_SUPPORT_PROGRAM=trueÏù¥Î©¥ÏÑú ÏßÄÏõêÎåÄÏÉÅ Ï†ïÎ≥¥Í∞Ä ÏóÜÎäî Í≤ΩÏö∞Îßå)
            second_response = None
            
            if need_second_analysis and combined_content.strip():
                print("  üìã 2Ï∞® Ollama Î∂ÑÏÑù Ï§ë (Ï≤®Î∂ÄÌååÏùº)...")
                logger.info("2Ï∞® Î∂ÑÏÑù ÏãúÏûë - IS_SUPPORT_PROGRAM=trueÏù¥ÏßÄÎßå ÏßÄÏõêÎåÄÏÉÅ Ï†ïÎ≥¥ Î∂ÄÏ°±")
                second_response, second_prompt = self._analyze_with_ollama(combined_content)
                
                # ÏµúÏ¢Ö ÏÉÅÌÉú Í≤∞Ï†ï Î°úÏßÅ
                final_status = self._determine_final_status(first_response, second_response)
                
                return self._update_processing_result(
                    record_id, second_response, second_prompt, 
                    first_response=first_response, status=final_status
                )
            elif need_second_analysis and not combined_content.strip():
                # 2Ï∞® Î∂ÑÏÑùÏù¥ ÌïÑÏöîÌïòÏßÄÎßå Ï≤®Î∂ÄÌååÏùº ÎÇ¥Ïö©Ïù¥ ÏóÜÎäî Í≤ΩÏö∞
                logger.info("2Ï∞® Î∂ÑÏÑù ÌïÑÏöîÌïòÏßÄÎßå Ï≤®Î∂ÄÌååÏùº ÎÇ¥Ïö© ÏóÜÏùå - 1Ï∞® Í≤∞Í≥ºÎßå ÏÇ¨Ïö©")
                final_status = self._determine_final_status(first_response, None)
                return self._update_processing_result(
                    record_id, first_response, first_prompt if first_response else "", 
                    status=final_status
                )
            else:
                # 2Ï∞® Î∂ÑÏÑùÏù¥ ÌïÑÏöîÌïòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ (Ïù¥ÎØ∏ ÏúÑÏóêÏÑú Ï≤òÎ¶¨ÎêòÏóàÏßÄÎßå Ï∂îÍ∞Ä ÏïàÏ†ÑÏû•Ïπò)
                logger.info("2Ï∞® Î∂ÑÏÑù Î∂àÌïÑÏöî - 1Ï∞® Í≤∞Í≥ºÎßå ÏÇ¨Ïö©")
                final_status = self._determine_final_status(first_response, None)
                return self._update_processing_result(
                    record_id, first_response, first_prompt if first_response else "", 
                    status=final_status
                )
                
        except Exception as e:
            logger.error(f"ÎîîÎ†âÌÜ†Î¶¨ Ï≤òÎ¶¨ Ï§ë ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}")
            return self._save_processing_result(
                folder_name, site_code, "", "",
                status="ollama", error_message=f"ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}"
            )
    
    def _check_exclusion_keywords(self, folder_name: str) -> List[str]:
        """Ìè¥ÎçîÎ™ÖÏóêÏÑú Ï†úÏô∏ ÌÇ§ÏõåÎìúÎ•º Ï≤¥ÌÅ¨Ìï©ÎãàÎã§."""
        matched_keywords = []
        
        for keyword_info in self.exclusion_keywords:
            keyword = keyword_info['keyword'].lower()
            if keyword in folder_name.lower():
                matched_keywords.append(keyword_info['keyword'])
                logger.debug(f"Ï†úÏô∏ ÌÇ§ÏõåÎìú Îß§Ïπ≠: '{keyword}' in '{folder_name}'")
        
        return matched_keywords
    
    def _determine_final_status(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]]) -> str:
        """1Ï∞®, 2Ï∞® ÏùëÎãµÏùÑ Í∏∞Î∞òÏúºÎ°ú ÏµúÏ¢Ö ÏÉÅÌÉúÎ•º Í≤∞Ï†ïÌï©ÎãàÎã§."""
        
        # EXTRACTED_TARGETÏù¥ Ïú†Ìö®Ìïú Í∞íÏù∏ÏßÄ ÌôïÏù∏ÌïòÎäî Ìï®Ïàò
        def has_valid_target(response):
            if not response:
                return False
            target = response.get("EXTRACTED_TARGET", "")
            return target and target not in ["Ï†ïÎ≥¥ ÏóÜÏùå", "Ìï¥ÎãπÏóÜÏùå", ""]
        
        # 1Ï∞® ÎòêÎäî 2Ï∞®ÏóêÏÑú EXTRACTED_TARGETÏù¥ ÏûàÏúºÎ©¥ ÏÑ±Í≥µ
        if has_valid_target(first_response) or has_valid_target(second_response):
            return "ÏÑ±Í≥µ"
        
        # 1Ï∞®, 2Ï∞® Î™®Îëê Ï†ïÎ≥¥ ÏóÜÏùåÏù∏ Í≤ΩÏö∞ completed
        first_no_info = not first_response or not has_valid_target(first_response)
        second_no_info = not second_response or not has_valid_target(second_response)
        
        if first_no_info and second_no_info:
            return "completed"
        
        # Í∏∞Î≥∏Í∞í
        return "ollama"
    
    def _format_date_to_standard(self, date_str: str) -> Optional[str]:
        """ÎÇ†Ïßú Î¨∏ÏûêÏó¥ÏùÑ YYYY-MM-DD ÌòïÌÉúÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§."""
        import re
        
        if not date_str or date_str in ["Ï†ïÎ≥¥ ÏóÜÏùå", "Ìï¥ÎãπÏóÜÏùå", ""]:
            return None
        
        # Í≥µÎ∞±Í≥º ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞
        clean_date = re.sub(r'[^\d\.\-/]', '', date_str.strip())
        
        # YYYY-MM-DD Ìå®ÌÑ¥ (Ïù¥ÎØ∏ ÌëúÏ§Ä ÌòïÌÉú)
        if re.match(r'^\d{4}-\d{2}-\d{2}$', clean_date):
            return clean_date
        
        # YYYY.MM.DD Ìå®ÌÑ¥
        match = re.match(r'^(\d{4})\.(\d{2})\.(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYYMMDD Ìå®ÌÑ¥
        match = re.match(r'^(\d{4})(\d{2})(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYY/MM/DD Ìå®ÌÑ¥
        match = re.match(r'^(\d{4})/(\d{2})/(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # Îçî Î≥µÏû°Ìïú Ìå®ÌÑ¥Îì§ Ï≤òÎ¶¨
        # Ïòà: 2024ÎÖÑ 12Ïõî 25Ïùº
        year_month_day = re.search(r'(\d{4})ÎÖÑ?\s*(\d{1,2})Ïõî?\s*(\d{1,2})Ïùº?', date_str)
        if year_month_day:
            year = year_month_day.group(1)
            month = year_month_day.group(2).zfill(2)
            day = year_month_day.group(3).zfill(2)
            return f"{year}-{month}-{day}"
        
        # Ïà´ÏûêÎßå 8ÏûêÎ¶¨Ïù∏ Í≤ΩÏö∞ (YYYYMMDD)
        numbers_only = re.sub(r'[^\d]', '', date_str)
        if len(numbers_only) == 8:
            return f"{numbers_only[:4]}-{numbers_only[4:6]}-{numbers_only[6:8]}"
        
        logger.debug(f"ÎÇ†Ïßú Î≥ÄÌôò Ïã§Ìå®: '{date_str}' -> None")
        return None
    
    def _get_best_value_from_responses(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]], key: str) -> str:
        """first_responseÏôÄ second_response Ï§ëÏóêÏÑú Ïú†Ìö®Ìïú Í∞íÏù¥ ÏûàÎäî Í≤ÉÏùÑ Î∞òÌôòÌï©ÎãàÎã§."""
        
        def is_valid_value(value):
            return value and value not in ["Ï†ïÎ≥¥ ÏóÜÏùå", "Ìï¥ÎãπÏóÜÏùå", ""]
        
        # first_responseÏóêÏÑú Í∞í ÌôïÏù∏ (Ïö∞ÏÑ†ÏàúÏúÑ)
        if first_response and key in first_response:
            first_value = first_response.get(key, "")
            if is_valid_value(first_value):
                logger.debug(f"{key} Í∞íÏùÑ first_responseÏóêÏÑú ÏÇ¨Ïö©: {first_value}")
                return first_value
        
        # second_responseÏóêÏÑú Í∞í ÌôïÏù∏
        if second_response and key in second_response:
            second_value = second_response.get(key, "")
            if is_valid_value(second_value):
                logger.debug(f"{key} Í∞íÏùÑ second_responseÏóêÏÑú ÏÇ¨Ïö©: {second_value}")
                return second_value
        
        # Îëò Îã§ ÏóÜÏúºÎ©¥ Îπà Î¨∏ÏûêÏó¥ Î∞òÌôò
        return ""
    
    def _natural_sort_key(self, path: Path) -> tuple:
        """Ìè¥ÎçîÎ™ÖÏùò Ïà´Ïûê Î∂ÄÎ∂ÑÏùÑ Í∏∞Ï§ÄÏúºÎ°ú ÏûêÏó∞ Ï†ïÎ†¨ÏùÑ ÏúÑÌïú ÌÇ§Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§."""
        import re
        
        folder_name = path.name
        # Ïà´Ïûê_Ï†úÎ™© Ìå®ÌÑ¥ÏóêÏÑú Ïà´Ïûê Î∂ÄÎ∂Ñ Ï∂îÏ∂ú
        match = re.match(r'^(\d+)_(.*)$', folder_name)
        if match:
            number = int(match.group(1))
            title = match.group(2)
            return (number, title)
        else:
            # Ïà´ÏûêÎ°ú ÏãúÏûëÌïòÏßÄ ÏïäÎäî Í≤ΩÏö∞Îäî Îß® Îí§Î°ú
            return (float('inf'), folder_name)
    
    def _process_attachments_separately(self, directory_path: Path, attach_force: bool = False) -> tuple[str, List[str]]:
        """Ï≤®Î∂ÄÌååÏùºÎì§ÏùÑ Ï≤òÎ¶¨ÌïòÏó¨ ÎÇ¥Ïö©ÏùÑ Í≤∞Ìï©ÌïòÍ≥† ÌååÏùºÎ™Ö Î™©Î°ùÏùÑ Î∞òÌôòÌï©ÎãàÎã§."""
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return "", []
        
        combined_content = ""
        attachment_filenames = []
        
        # Ï≤òÎ¶¨ Í∞ÄÎä•Ìïú ÌôïÏû•Ïûê Ï†ïÏùò
        supported_extensions = {'.pdf', '.hwp', '.hwpx', '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.pptx', '.docx', '.xlsx', '.md'}
        
        target_keywords = ['ÏñëÏãù', 'ÏÑúÎ•ò', 'Ïã†Ï≤≠ÏÑú', 'ÎèôÏùòÏÑú']

        for file_path in attachments_dir.iterdir():
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                filename = file_path.stem
                

                logger.info(f"filename===={filename}")
                lowercase_filename = filename.lower()
                
                if any(keyword in lowercase_filename for keyword in target_keywords):                
                    logger.info(f"ÏñëÏãù, Ïã†Ï≤≠ÏÑú Îì±ÏùÄ SKIP===={filename}")
                    continue; 

                # ÌôïÏû•ÏûêÍ∞Ä ÏóÜÍ±∞ÎÇò ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÌååÏùºÏùÄ Í±¥ÎÑàÎõ∞Í∏∞
                if not file_extension or file_extension not in supported_extensions:
                    logger.debug(f"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÌååÏùº ÌòïÏãù Í±¥ÎÑàÎúÄ: {file_path.name}")
                    continue
                
                attachment_filenames.append(file_path.name)  # Ï†ÑÏ≤¥ ÌååÏùºÎ™Ö (ÌôïÏû•Ïûê Ìè¨Ìï®)
                logger.debug(f"Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ ÏãúÏûë: {file_path.name}")
                
                # Ïù¥ÎØ∏ .md ÌååÏùºÏù∏ Í≤ΩÏö∞ ÏßÅÏ†ë ÏùΩÍ∏∞
                if file_extension == '.md':
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ÎÇ¥Ïö©Ïù¥ ÏûàÎäî Í≤ΩÏö∞Îßå Ï∂îÍ∞Ä
                            combined_content += f"\n\n=== {file_path.name} ===\n{content}"
                            logger.debug(f"Ï≤®Î∂ÄÌååÏùº .md ÏßÅÏ†ë ÏùΩÍ∏∞ ÏÑ±Í≥µ: {file_path.name} ({len(content)} Î¨∏Ïûê)")
                        else:
                            logger.warning(f"Ï≤®Î∂ÄÌååÏùº .md ÎÇ¥Ïö©Ïù¥ ÎπÑÏñ¥ÏûàÏùå: {file_path.name}")
                    except Exception as e:
                        logger.error(f"Ï≤®Î∂ÄÌååÏùº .md ÏßÅÏ†ë ÏùΩÍ∏∞ Ïã§Ìå®: {e}")
                    continue  # .md ÌååÏùº Ï≤òÎ¶¨ ÏôÑÎ£å, Îã§Ïùå ÌååÏùºÎ°ú
                
                # Ï≤®Î∂ÄÌååÏùºÎ™Ö.md ÌååÏùºÏù¥ ÏûàÎäîÏßÄ ÌôïÏù∏ (Îã§Î•∏ ÌôïÏû•Ïûê ÌååÏùºÎì§ÏùÑ ÏúÑÌïú)
                md_file_path = attachments_dir / f"{filename}.md"
                
                # attach_forceÍ∞Ä TrueÏù¥Î©¥ Í∏∞Ï°¥ .md ÌååÏùºÏùÑ Î¨¥ÏãúÌïòÍ≥† ÏõêÎ≥∏ÏóêÏÑú Ïû¨Î≥ÄÌôò
                if not attach_force and md_file_path.exists():
                    # .md ÌååÏùºÏù¥ ÏûàÏúºÎ©¥ Í∑∏Í≤ÉÏùÑ ÏùΩÏùå
                    try:
                        with open(md_file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ÎÇ¥Ïö©Ïù¥ ÏûàÎäî Í≤ΩÏö∞Îßå Ï∂îÍ∞Ä
                            combined_content += f"\n\n=== {filename}.md ===\n{content}"
                            logger.debug(f"Ï≤®Î∂ÄÌååÏùº .md ÏùΩÍ∏∞ ÏÑ±Í≥µ: {filename}.md ({len(content)} Î¨∏Ïûê)")
                        else:
                            logger.warning(f"Ï≤®Î∂ÄÌååÏùº .md ÎÇ¥Ïö©Ïù¥ ÎπÑÏñ¥ÏûàÏùå: {filename}.md")
                    except Exception as e:
                        logger.error(f"Ï≤®Î∂ÄÌååÏùº .md ÏùΩÍ∏∞ Ïã§Ìå®: {e}")
                else:
                    # .md ÌååÏùºÏù¥ ÏóÜÍ±∞ÎÇò attach_forceÍ∞Ä TrueÏù¥Î©¥ ÏõêÎ≥∏ ÌååÏùºÏùÑ Î≥ÄÌôò
                    if attach_force and md_file_path.exists():
                        logger.info(f"--attach-force: Í∏∞Ï°¥ .md ÌååÏùº Î¨¥ÏãúÌïòÍ≥† Ïû¨Î≥ÄÌôò: {file_path.name}")
                    else:
                        logger.info(f"Ï≤®Î∂ÄÌååÏùº Î≥ÄÌôò ÏãúÏûë: {file_path.name}")
                        
                    try:
                        content = self.attachment_processor.process_single_file(file_path)
                        
                        if content and content.strip():
                            combined_content += f"\n\n=== {file_path.name} ===\n{content}"
                            logger.info(f"Ï≤®Î∂ÄÌååÏùº Î≥ÄÌôò ÏÑ±Í≥µ: {file_path.name} ({len(content)} Î¨∏Ïûê)")
                            
                            # Î≥ÄÌôòÎêú ÎÇ¥Ïö©ÏùÑ .md ÌååÏùºÎ°ú Ï†ÄÏû•
                            try:
                                with open(md_file_path, 'w', encoding='utf-8') as f:
                                    f.write(content)
                                logger.debug(f"Î≥ÄÌôòÎêú ÎÇ¥Ïö©ÏùÑ .mdÎ°ú Ï†ÄÏû•: {md_file_path}")
                            except Exception as save_e:
                                logger.warning(f".md ÌååÏùº Ï†ÄÏû• Ïã§Ìå®: {save_e}")
                        else:
                            logger.warning(f"Ï≤®Î∂ÄÌååÏùºÏóêÏÑú ÎÇ¥Ïö© Ï∂îÏ∂ú Ïã§Ìå®: {file_path.name}")
                        
                    except Exception as e:
                        logger.error(f"Ï≤®Î∂ÄÌååÏùº Î≥ÄÌôò Ïã§Ìå® ({file_path}): {e}")
        
        logger.info(f"Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ ÏôÑÎ£å: {len(attachment_filenames)}Í∞ú ÌååÏùº, {len(combined_content)} Î¨∏Ïûê")
        return combined_content.strip(), attachment_filenames
    
    def _analyze_with_ollama(self, content: str) -> tuple[Optional[Dict[str, Any]], str]:
        """OllamaÎ•º ÌÜµÌï¥ ÎÇ¥Ïö©ÏùÑ Î∂ÑÏÑùÌï©ÎãàÎã§."""
        try:
            return self.announcement_analyzer.analyze_announcement(content)
        except Exception as e:
            logger.error(f"Ollama Î∂ÑÏÑù Ï§ë Ïò§Î•ò: {e}")
            return None, ""
    
    def _save_processing_result(
        self, 
        folder_name: str, 
        site_code: str, 
        content_md: str, 
        combined_content: str,
        attachment_filenames: List[str] = None,
        status: str = "ollama",
        exclusion_keywords: List[str] = None,
        exclusion_reason: str = None,
        error_message: str = None,
        force: bool = False
    ) -> Optional[int]:
        """Ï≤òÎ¶¨ Í≤∞Í≥ºÎ•º Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•Ìï©ÎãàÎã§."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                if force:
                    # UPSERT Î°úÏßÅ
                    sql = text("""
                        INSERT INTO announcement_prv_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                        ON DUPLICATE KEY UPDATE
                            content_md = VALUES(content_md),
                            combined_content = VALUES(combined_content),
                            attachment_filenames = VALUES(attachment_filenames),
                            exclusion_keyword = VALUES(exclusion_keyword),
                            exclusion_reason = VALUES(exclusion_reason),
                            processing_status = VALUES(processing_status),
                            error_message = VALUES(error_message),
                            updated_at = NOW()
                    """)
                else:
                    # ÏùºÎ∞ò INSERT
                    sql = text("""
                        INSERT INTO announcement_prv_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                    """)
                
                params = {
                    'folder_name': folder_name,
                    'site_code': site_code,
                    'content_md': content_md,
                    'combined_content': combined_content,
                    'attachment_filenames': ', '.join(attachment_filenames) if attachment_filenames else None,
                    'exclusion_keyword': ', '.join(exclusion_keywords) if exclusion_keywords else None,
                    'exclusion_reason': exclusion_reason,
                    'processing_status': status,
                    'error_message': error_message
                }
                
                result = session.execute(sql, params)
                session.commit()
                
                record_id = result.lastrowid
                logger.info(f"Ï≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: ID {record_id}, ÏÉÅÌÉú: {status}")
                return record_id
                
        except Exception as e:
            logger.error(f"Ï≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû• Ïã§Ìå®: {e}")
            return None
    
    def _update_processing_result(
        self,
        record_id: int,
        ollama_response: Optional[Dict[str, Any]],
        ollama_prompt: str,
        first_response: Optional[Dict[str, Any]] = None,
        status: str = "ollama"
    ) -> bool:
        """Í∏∞Ï°¥ Î†àÏΩîÎìúÏóê Ollama Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÏóÖÎç∞Ïù¥Ìä∏Ìï©ÎãàÎã§."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                # Ï∂îÏ∂úÎêú Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
                extracted_data = {}
                if ollama_response:
                    # URLÍ≥º ÎÇ†ÏßúÎäî first_responseÏôÄ ollama_response Ï§ë Í∞íÏù¥ ÏûàÎäî Í≤ÉÏùÑ Ïö∞ÏÑ† ÏÇ¨Ïö©
                    extracted_url = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_URL")
                    extracted_announcement_date = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_ANNOUNCEMENT_DATE")
                    
                    extracted_data = {
                        'extracted_title': ollama_response.get("EXTRACTED_TITLE", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_target': ollama_response.get("EXTRACTED_TARGET", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_target_type': ollama_response.get("EXTRACTED_TARGET_TYPE", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_amount': ollama_response.get("EXTRACTED_AMOUNT", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_period': ollama_response.get("EXTRACTED_PERIOD", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_schedule': ollama_response.get("EXTRACTED_SCHEDULE", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_content': ollama_response.get("EXTRACTED_CONTENT", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_announcement_date': extracted_announcement_date,
                        'original_url': extracted_url,
                        'formatted_announcement_date': self._format_date_to_standard(extracted_announcement_date),
                        'extracted_gov24_url': ollama_response.get("EXTRACTED_GOV24_URL", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'extracted_origin_url': ollama_response.get("EXTRACTED_ORIGIN_URL", "Ï†ïÎ≥¥ ÏóÜÏùå"),
                        'is_support_program': ollama_response.get("IS_SUPPORT_PROGRAM"),
                        'support_program_reason': ollama_response.get("SUPPORT_PROGRAM_REASON", "Ï†ïÎ≥¥ ÏóÜÏùå")
                    }
                
                sql = text("""
                    UPDATE announcement_prv_processing SET
                        ollama_first_response = :ollama_first_response,
                        ollama_response = :ollama_response,
                        ollama_prompt = :ollama_prompt,
                        extracted_title = :extracted_title,
                        extracted_target = :extracted_target,
                        extracted_target_type = :extracted_target_type,
                        extracted_amount = :extracted_amount,
                        extracted_period = :extracted_period,
                        extracted_schedule = :extracted_schedule,
                        extracted_content = :extracted_content,
                        extracted_announcement_date = :extracted_announcement_date,
                        original_url = :original_url,
                        formatted_announcement_date = :formatted_announcement_date,
                        extracted_gov24_url = :extracted_gov24_url,
                        extracted_origin_url = :extracted_origin_url,
                        is_support_program = :is_support_program,
                        support_program_reason = :support_program_reason,
                        processing_status = :processing_status,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                params = {
                    'record_id': record_id,
                    'ollama_first_response': json.dumps(first_response, ensure_ascii=False) if first_response else None,
                    'ollama_response': json.dumps(ollama_response, ensure_ascii=False) if ollama_response else None,
                    'ollama_prompt': ollama_prompt,
                    'processing_status': status,
                    **extracted_data
                }
                
                session.execute(sql, params)
                session.commit()
                
                logger.info(f"Ï≤òÎ¶¨ Í≤∞Í≥º ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å: ID {record_id}, ÏÉÅÌÉú: {status}")
                
                # ÌôîÎ©¥Ïóê Í≤∞Í≥º ÌëúÏãú
                if ollama_response:
                    self._display_ollama_results(ollama_response)
                
                return True
                
        except Exception as e:
            logger.error(f"Ï≤òÎ¶¨ Í≤∞Í≥º ÏóÖÎç∞Ïù¥Ìä∏ Ïã§Ìå®: {e}")
            return False
    
    def _display_ollama_results(self, ollama_response: Dict[str, Any]):
        """Ollama Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌôîÎ©¥Ïóê ÌëúÏãúÌï©ÎãàÎã§."""
        print("  ü§ñ Ollama Î∂ÑÏÑù Í≤∞Í≥º:")
        if "EXTRACTED_TARGET" in ollama_response and ollama_response["EXTRACTED_TARGET"]:
            print(f"     üìå ÏßÄÏõêÎåÄÏÉÅ: {ollama_response['EXTRACTED_TARGET'][:100]}...")
        if "EXTRACTED_TARGET_TYPE" in ollama_response and ollama_response["EXTRACTED_TARGET_TYPE"]:
            print(f"     üè∑Ô∏è ÏßÄÏõêÎåÄÏÉÅÎ∂ÑÎ•ò: {ollama_response['EXTRACTED_TARGET_TYPE'][:50]}...")
        if "EXTRACTED_AMOUNT" in ollama_response and ollama_response["EXTRACTED_AMOUNT"]:
            print(f"     üí∞ ÏßÄÏõêÍ∏àÏï°: {ollama_response['EXTRACTED_AMOUNT'][:100]}...")
        if "EXTRACTED_TITLE" in ollama_response and ollama_response["EXTRACTED_TITLE"]:
            print(f"     üìù Ï†úÎ™©: {ollama_response['EXTRACTED_TITLE'][:100]}...")
        if "EXTRACTED_ANNOUNCEMENT_DATE" in ollama_response and ollama_response["EXTRACTED_ANNOUNCEMENT_DATE"]:
            print(f"     üìÖ Îì±Î°ùÏùº: {ollama_response['EXTRACTED_ANNOUNCEMENT_DATE'][:50]}...")


def get_base_directory(args) -> Path:
    """Î™ÖÎ†πÌñâ Ïù∏Ïûê ÎòêÎäî ÌôòÍ≤ΩÎ≥ÄÏàòÏóêÏÑú Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨Î•º Í∞ÄÏ†∏ÏòµÎãàÎã§."""
    
    # ÎîîÎ†âÌÜ†Î¶¨ Í≤∞Ï†ï
    if args.data:
        directory_name = args.data
    else:
        # ÌôòÍ≤ΩÎ≥ÄÏàòÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞
        directory_name = os.getenv("DEFAULT_DIR", "data")
    
    # ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨ Í∏∞Ï§ÄÏúºÎ°ú Í≤ΩÎ°ú ÏÉùÏÑ±
    current_dir = Path.cwd()
    base_directory = current_dir / directory_name
    
    if not base_directory.exists():
        logger.error(f"ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {base_directory}")
        sys.exit(1)
    
    logger.info(f"Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨: {base_directory}")
    
    return base_directory


def main():
    """Î©îÏù∏ Ìï®Ïàò"""
    parser = argparse.ArgumentParser(
        description="Í≥µÍ≥† Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ Î∞è Î∂ÑÏÑù ÌîÑÎ°úÍ∑∏Îû®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ÏòàÏãú:
  python announcement_prv_processor.py --data data.enhanced
  python announcement_prv_processor.py --data data.origin
  python announcement_prv_processor.py  # ÌôòÍ≤ΩÎ≥ÄÏàò DEFAULT_DIR ÏÇ¨Ïö©
  python announcement_prv_processor.py --data data.enhanced -r  # Ïû¨Í∑ÄÏ†Å Ï≤òÎ¶¨
  python announcement_prv_processor.py --data data.enhanced --attach-force  # Ï≤®Î∂ÄÌååÏùº Í∞ïÏ†ú Ïû¨Ï≤òÎ¶¨
        """
    )
    
    parser.add_argument(
        "--data", 
        type=str,
        help="Îç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨Î™Ö (Í∏∞Î≥∏Í∞í: ÌôòÍ≤ΩÎ≥ÄÏàò DEFAULT_DIR ÎòêÎäî 'data')"
    )
    
    
    parser.add_argument(
        "--skip-processed", 
        action="store_true", 
        help="Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™© Í±¥ÎÑàÎõ∞Í∏∞ (Í∏∞Î≥∏ ÎèôÏûë)"
    )
    
    parser.add_argument(
        "--force", 
        action="store_true", 
        help="Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Ìï≠Î™©ÎèÑ Îã§Ïãú Ï≤òÎ¶¨"
    )
    
    parser.add_argument(
        "-r", "--recursive",
        action="store_true",
        help="ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨Î•º Ïû¨Í∑ÄÏ†ÅÏúºÎ°ú Ï≤òÎ¶¨ (Î™®Îì† ÌïòÏúÑ Í≤ΩÎ°úÏùò content.mdÎÇò attachmentsÎ•º Ï∞æÏïÑÏÑú Ï≤òÎ¶¨)"
    )
    
    parser.add_argument(
        "--attach-force",
        action="store_true",
        help="Ï≤®Î∂ÄÌååÏùº Í∞ïÏ†ú Ïû¨Ï≤òÎ¶¨ (Í∏∞Ï°¥ .md ÌååÏùº Î¨¥ÏãúÌïòÍ≥† ÏõêÎ≥∏ ÌååÏùºÏóêÏÑú Îã§Ïãú Î≥ÄÌôò)"
    )
    
    args = parser.parse_args()
    
    try:
        # Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ Í≤∞Ï†ï
        base_directory = get_base_directory(args)
        
        # ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî
        logger.info("Îã§Ï§ë ÏÇ¨Ïù¥Ìä∏ Í≥µÍ≥† Ï≤òÎ¶¨ ÌîÑÎ°úÍ∑∏Îû® ÏãúÏûë")
        processor = AnnouncementPrvProcessor(attach_force=args.attach_force)
        
        # Î™®Îì† ÏÇ¨Ïù¥Ìä∏ Ï≤òÎ¶¨ Ïã§Ìñâ
        results = processor.process_all_sites(base_directory, args.recursive, args.force, args.attach_force)
        
        # Í≤∞Í≥º Ï∂úÎ†• (process_site_directoriesÏóêÏÑú Ïù¥ÎØ∏ ÏÉÅÏÑ∏ Ï∂úÎ†•Îê®)
        print(f"\n=== ÏµúÏ¢Ö ÏöîÏïΩ ===")
        print(f"Ï†ÑÏ≤¥ ÎåÄÏÉÅ: {results['total']}Í∞ú")
        print(f"Ï≤òÎ¶¨ ÏÑ±Í≥µ: {results['success']}Í∞ú") 
        print(f"Ï≤òÎ¶¨ Ïã§Ìå®: {results['failed']}Í∞ú")
        print(f"Í±¥ÎÑàÎõ¥ Ìï≠Î™©: {results['skipped']}Í∞ú")
        
        if results['failed'] > 0:
            print(f"\nÏã§Ìå®Ìïú Ìï≠Î™©Ïù¥ {results['failed']}Í∞ú ÏûàÏäµÎãàÎã§. Î°úÍ∑∏Î•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.")
            sys.exit(1)
        else:
            print("\nÎ™®Îì† Ï≤òÎ¶¨Í∞Ä ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!")
            sys.exit(0)
            
    except KeyboardInterrupt:
        logger.info("ÏÇ¨Ïö©ÏûêÏóê ÏùòÌï¥ Ï§ëÎã®Îê®")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ÌîÑÎ°úÍ∑∏Îû® Ïã§Ìñâ Ï§ë Ïò§Î•ò: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()