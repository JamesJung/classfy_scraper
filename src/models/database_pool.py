"""
ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ê´€ë¦¬ì
ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì—°ê²° í’€ë§ ì‹œìŠ¤í…œ
"""

import logging
import threading
from contextlib import contextmanager
from datetime import datetime
from typing import Any

from sqlalchemy import create_engine, event, text
from sqlalchemy.orm import scoped_session, sessionmaker
from sqlalchemy.pool import QueuePool

logger = logging.getLogger(__name__)


class DatabaseConnectionPool:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ê´€ë¦¬ì"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        """ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„"""
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, config: dict[str, Any] = None):
        """ì—°ê²° í’€ ì´ˆê¸°í™”"""
        if hasattr(self, "_initialized"):
            return

        self.config = config or {}
        self.engine = None
        self.SessionFactory = None
        self.scoped_session_factory = None

        # í’€ ì„¤ì •
        self.pool_size = self.config.get("pool_size", 10)
        self.max_overflow = self.config.get("max_overflow", 20)
        self.pool_timeout = self.config.get("pool_timeout", 30)
        self.pool_recycle = self.config.get("pool_recycle", 3600)  # 1ì‹œê°„
        self.pool_pre_ping = self.config.get("pool_pre_ping", True)

        # í†µê³„
        self.stats = {
            "total_connections": 0,
            "active_connections": 0,
            "failed_connections": 0,
            "pool_overflows": 0,
            "last_reset": datetime.now(),
        }

        self._initialized = True
        logger.info("DatabaseConnectionPool ì´ˆê¸°í™” ì™„ë£Œ")

    def initialize_pool(self, database_url: str):
        """ì—°ê²° í’€ ì´ˆê¸°í™”"""
        try:
            # ì—”ì§„ ìƒì„± (ì—°ê²° í’€ ì„¤ì • í¬í•¨)
            self.engine = create_engine(
                database_url,
                poolclass=QueuePool,
                pool_size=self.pool_size,
                max_overflow=self.max_overflow,
                pool_timeout=self.pool_timeout,
                pool_recycle=self.pool_recycle,
                pool_pre_ping=self.pool_pre_ping,
                echo=False,  # SQL ë¡œê¹… ë¹„í™œì„±í™” (ì„±ëŠ¥)
                future=True,
                connect_args={
                    "charset": "utf8mb4",
                    "collation": "utf8mb4_unicode_ci",
                    "autocommit": False,
                    "connect_timeout": 10,
                    "read_timeout": 30,
                    "write_timeout": 30,
                },
            )

            # ì„¸ì…˜ íŒ©í† ë¦¬ ìƒì„±
            self.SessionFactory = sessionmaker(
                bind=self.engine,
                autocommit=False,
                autoflush=False,
                expire_on_commit=False,
            )

            # ìŠ¤ì½”í”„ë“œ ì„¸ì…˜ (ìŠ¤ë ˆë“œ ì•ˆì „)
            self.scoped_session_factory = scoped_session(self.SessionFactory)

            # ì—°ê²° í’€ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
            self._register_pool_events()

            # ì—°ê²° í…ŒìŠ¤íŠ¸
            self._test_connection()

            logger.info(
                f"âœ… DB ì—°ê²° í’€ ì´ˆê¸°í™” ì™„ë£Œ - "
                f"Pool Size: {self.pool_size}, Max Overflow: {self.max_overflow}"
            )

        except Exception as e:
            logger.error(f"âŒ DB ì—°ê²° í’€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _register_pool_events(self):
        """ì—°ê²° í’€ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡"""

        @event.listens_for(self.engine, "connect")
        def on_connect(dbapi_connection, connection_record):
            """ì—°ê²° ìƒì„± ì‹œ"""
            self.stats["total_connections"] += 1
            self.stats["active_connections"] += 1
            logger.debug(
                f"ğŸ”— ìƒˆ DB ì—°ê²° ìƒì„± - í™œì„± ì—°ê²°: {self.stats['active_connections']}"
            )

        @event.listens_for(self.engine, "checkout")
        def on_checkout(dbapi_connection, connection_record, connection_proxy):
            """ì—°ê²° ì²´í¬ì•„ì›ƒ ì‹œ"""
            logger.debug("ğŸ“¤ DB ì—°ê²° ì²´í¬ì•„ì›ƒ")

        @event.listens_for(self.engine, "checkin")
        def on_checkin(dbapi_connection, connection_record):
            """ì—°ê²° ì²´í¬ì¸ ì‹œ"""
            logger.debug("ğŸ“¥ DB ì—°ê²° ì²´í¬ì¸")

        @event.listens_for(self.engine, "close")
        def on_close(dbapi_connection, connection_record):
            """ì—°ê²° ì¢…ë£Œ ì‹œ"""
            self.stats["active_connections"] = max(
                0, self.stats["active_connections"] - 1
            )
            logger.debug(
                f"âŒ DB ì—°ê²° ì¢…ë£Œ - í™œì„± ì—°ê²°: {self.stats['active_connections']}"
            )

        # SQLAlchemy ë²„ì „ë³„ ì´ë²¤íŠ¸ ì´ë¦„ ì°¨ì´ ëŒ€ì‘
        try:

            @event.listens_for(self.engine, "invalidate")
            def on_invalidate(dbapi_connection, connection_record, exception):
                """ì—°ê²° ë¬´íš¨í™” ì‹œ (SQLAlchemy 2.x)"""
                self.stats["failed_connections"] += 1
                logger.warning(f"âš ï¸ DB ì—°ê²° ë¬´íš¨í™”: {exception}")

        except Exception:
            try:

                @event.listens_for(self.engine, "invalid")
                def on_invalid(dbapi_connection, connection_record, exception):
                    """ì—°ê²° ë¬´íš¨í™” ì‹œ (SQLAlchemy 1.x)"""
                    self.stats["failed_connections"] += 1
                    logger.warning(f"âš ï¸ DB ì—°ê²° ë¬´íš¨í™”: {exception}")

            except Exception:
                logger.warning(
                    "âš ï¸ ì—°ê²° ë¬´íš¨í™” ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡ ì‹¤íŒ¨ (ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ)"
                )

    def _test_connection(self):
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            with self.get_session() as session:
                result = session.execute(text("SELECT 1")).scalar()
                if result != 1:
                    raise Exception("ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            logger.info("âœ… DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            raise

    @contextmanager
    def get_session(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ì„¸ì…˜ ì œê³µ"""
        if not self.scoped_session_factory:
            raise RuntimeError("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        session = self.scoped_session_factory()
        try:
            yield session
            session.commit()
        except Exception as e:
            session.rollback()
            logger.error(f"DB ì„¸ì…˜ ì˜¤ë¥˜: {e}")
            raise
        finally:
            session.close()
            self.scoped_session_factory.remove()

    @contextmanager
    def get_batch_session(self, autocommit_interval: int = 1000):
        """ë°°ì¹˜ ì²˜ë¦¬ìš© ì„¸ì…˜ (ëŒ€ëŸ‰ INSERTìš©)"""
        if not self.scoped_session_factory:
            raise RuntimeError("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        session = self.scoped_session_factory()
        try:
            session.autoflush = False  # ìë™ í”ŒëŸ¬ì‹œ ë¹„í™œì„±í™”
            batch_count = 0

            def batch_commit():
                nonlocal batch_count
                batch_count += 1
                if batch_count % autocommit_interval == 0:
                    session.commit()
                    logger.debug(f"ë°°ì¹˜ ì»¤ë°‹ #{batch_count // autocommit_interval}")

            # ë°°ì¹˜ ì»¤ë°‹ í•¨ìˆ˜ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
            session.batch_commit = batch_commit

            yield session

            # ë‚¨ì€ ì‘ì—… ì»¤ë°‹
            if batch_count % autocommit_interval != 0:
                session.commit()
                logger.debug("ìµœì¢… ë°°ì¹˜ ì»¤ë°‹")

        except Exception as e:
            session.rollback()
            logger.error(f"ë°°ì¹˜ ì„¸ì…˜ ì˜¤ë¥˜: {e}")
            raise
        finally:
            session.close()
            self.scoped_session_factory.remove()

    def get_pool_status(self) -> dict[str, Any]:
        """ì—°ê²° í’€ ìƒíƒœ ì¡°íšŒ"""
        if not self.engine:
            return {"status": "not_initialized"}

        pool = self.engine.pool

        return {
            "status": "active",
            "pool_size": pool.size(),
            "checked_in": pool.checkedin(),
            "checked_out": pool.checkedout(),
            "overflow": pool.overflow(),
            "stats": self.stats.copy(),
            "uptime_seconds": (
                datetime.now() - self.stats["last_reset"]
            ).total_seconds(),
        }

    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.stats = {
            "total_connections": 0,
            "active_connections": 0,
            "failed_connections": 0,
            "pool_overflows": 0,
            "last_reset": datetime.now(),
        }
        logger.info("ğŸ“Š ì—°ê²° í’€ í†µê³„ ì´ˆê¸°í™”")

    def close_all_connections(self):
        """ëª¨ë“  ì—°ê²° ì¢…ë£Œ"""
        if self.engine:
            self.engine.dispose()
            logger.info("ğŸ”š ëª¨ë“  DB ì—°ê²° ì¢…ë£Œ")

    def health_check(self) -> bool:
        """í—¬ìŠ¤ì²´í¬"""
        try:
            with self.get_session() as session:
                session.execute(text("SELECT 1"))
            return True
        except Exception as e:
            logger.error(f"DB í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
            return False


# ì „ì—­ ì—°ê²° í’€ ì¸ìŠ¤í„´ìŠ¤
_db_pool = None


def get_database_pool(config: dict[str, Any] = None) -> DatabaseConnectionPool:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _db_pool
    if _db_pool is None:
        _db_pool = DatabaseConnectionPool(config)
    return _db_pool


def initialize_database_pool(database_url: str, config: dict[str, Any] = None):
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™”"""
    pool = get_database_pool(config)
    pool.initialize_pool(database_url)
    return pool
