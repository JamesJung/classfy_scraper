# processing_status ì¢…ë¥˜ ë° ë¡œì§ ë¶„ì„

## ğŸ“‹ ì¤‘ìš”: ë‘ ê°€ì§€ ë‹¤ë¥¸ processing_status

ì½”ë“œì— **ì´ë¦„ì€ ê°™ì§€ë§Œ ìš©ë„ê°€ ë‹¤ë¥¸** ë‘ ê°€ì§€ processing_statusê°€ ìˆìŠµë‹ˆë‹¤:

### 1ï¸âƒ£ í•¨ìˆ˜ íŒŒë¼ë¯¸í„° `status` (DB ì €ì¥ìš©)
- **ë³€ìˆ˜ëª…**: `status` (íŒŒë¼ë¯¸í„°)
- **ì €ì¥ ìœ„ì¹˜**: `announcement_pre_processing.processing_status` ì»¬ëŸ¼
- **ìš©ë„**: ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ í‘œì‹œ
- **ì–¸ì–´**: í•œê¸€/ì˜ë¬¸ í˜¼ì¬

### 2ï¸âƒ£ ë¡œì»¬ ë³€ìˆ˜ `processing_status` (ë‚´ë¶€ ë¡œì§ìš©)
- **ë³€ìˆ˜ëª…**: `processing_status` (ë¡œì»¬ ë³€ìˆ˜)
- **ì €ì¥ ìœ„ì¹˜**: ë©”ëª¨ë¦¬ (DB ì €ì¥ ì•ˆ ë¨)
- **ìš©ë„**: UPSERT ê²°ê³¼ë¥¼ duplicate_typeìœ¼ë¡œ ë§¤í•‘í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ë³€ìˆ˜
- **ì–¸ì–´**: ì˜ë¬¸

---

## 1ï¸âƒ£ DB ì €ì¥ìš© `status` íŒŒë¼ë¯¸í„°

### ì¢…ë¥˜ (5ê°€ì§€)

| status ê°’ | ì˜ë¯¸ | ì„¤ì • ìœ„ì¹˜ | ì‚¬ìš© ë¹ˆë„ (ì‹¤ì œ DB) |
|-----------|------|----------|-------------------|
| **"ì„±ê³µ"** | ì •ìƒ ì²˜ë¦¬ ì™„ë£Œ | Line 697, 1860 (ê¸°ë³¸ê°’) | 3,232ê±´ (25.5%) |
| **"ì œì™¸"** | ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­ | Line 674 | 5,885ê±´ (46.5%) |
| **"error"** | ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ | Line 551, 578, 656, 716 | 1ê±´ (0.01%) |
| **"success"** | ì •ìƒ ì²˜ë¦¬ (ì˜ë¬¸) | ? (êµ¬ ë²„ì „?) | 237ê±´ (1.9%) |
| **"archived"** | ì•„ì¹´ì´ë¸Œë¨ | ? (ì™¸ë¶€ ìŠ¤í¬ë¦½íŠ¸?) | 3,387ê±´ (26.7%) |

### ì„¤ì • ë¡œì§

#### Case 1: "ì„±ê³µ" (Line 697)
```python
# ì •ìƒ ì²˜ë¦¬ ì™„ë£Œ
result_id = self._save_processing_result(
    folder_name=folder_name,
    site_code=self.site_code,
    content_md=content_md,
    combined_content=combined_content,
    attachment_filenames=attachment_filenames,
    status="ì„±ê³µ",  # â† ê¸°ë³¸ê°’
    title=title,
    origin_url=origin_url,
    url_key=url_key,
    scraping_url=scraping_url,
    announcement_date=announcement_date,
    attachment_files_info=attachment_files_info,
    force=force,
)
```

#### Case 2: "ì œì™¸" (Line 674)
```python
# ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­
exclusion_keywords_found, exclusion_reason = self._check_exclusion_keywords(
    combined_content
)

if exclusion_keywords_found:
    logger.info(f"ì œì™¸ í‚¤ì›Œë“œ ë°œê²¬: {exclusion_reason}")
    result_id = self._save_processing_result(
        folder_name=folder_name,
        site_code=self.site_code,
        content_md=content_md,
        combined_content=combined_content,
        attachment_filenames=attachment_filenames,
        status="ì œì™¸",  # â† ì œì™¸
        exclusion_keywords=exclusion_keywords_found,
        exclusion_reason=exclusion_reason,
        # ...
    )
```

#### Case 3: "error" (Line 551, 578, 656, 716)
```python
# Line 551: content.md íŒŒì¼ ì—†ìŒ
if not os.path.exists(content_md_path):
    logger.error(f"content.md íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {content_md_path}")
    self._save_processing_result(
        folder_name=folder_name,
        site_code=self.site_code,
        content_md="",
        combined_content="",
        status="error",
        error_message="content.md íŒŒì¼ ì—†ìŒ",
    )
    return

# Line 578: PDF ë³€í™˜ ì‹¤íŒ¨
except Exception as e:
    logger.error(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {pdf_file}, {e}")
    self._save_processing_result(
        folder_name=folder_name,
        site_code=self.site_code,
        content_md=content_md,
        combined_content=combined_content,
        status="error",
        error_message=f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
    )
    return

# Line 656: ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨
except Exception as e:
    logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {folder_path}, {e}")
    self._save_processing_result(
        folder_name=folder_name,
        site_code=self.site_code,
        content_md="",
        combined_content="",
        status="error",
        error_message=str(e),
    )

# Line 716: URL í‚¤ ì¶”ì¶œ ì‹¤íŒ¨
except Exception as e:
    logger.error(f"URL í‚¤ ì¶”ì¶œ ì‹¤íŒ¨: {origin_url}, {e}")
    self._save_processing_result(
        folder_name=folder_name,
        # ...
        status="error",
        error_message=f"URL í‚¤ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}",
    )
```

#### "success"ì™€ "archived"ì˜ ì¶œì²˜
- ì½”ë“œì—ì„œ ì§ì ‘ ì„¤ì •í•˜ëŠ” ê³³ì´ ì—†ìŒ
- ì¶”ì •:
  - `"success"`: êµ¬ ë²„ì „ ì½”ë“œì—ì„œ ì‚¬ìš© (í˜„ì¬ëŠ” "ì„±ê³µ" ì‚¬ìš©)
  - `"archived"`: ì™¸ë¶€ ìŠ¤í¬ë¦½íŠ¸ ë˜ëŠ” ìˆ˜ë™ ì—…ë°ì´íŠ¸

---

## 2ï¸âƒ£ ë‚´ë¶€ ë¡œì§ìš© `processing_status` ë³€ìˆ˜

### ì¢…ë¥˜ (4ê°€ì§€)

| processing_status ê°’ | ì˜ë¯¸ | ì„¤ì • ì¡°ê±´ | duplicate_type ë§¤í•‘ |
|---------------------|------|----------|-------------------|
| **'new_inserted'** | ì‹ ê·œ ì‚½ì… | affected_rows == 1 | 'new_inserted' |
| **'duplicate_updated'** | ì¤‘ë³µ ì—…ë°ì´íŠ¸ | affected_rows == 2 | 'replaced' ë˜ëŠ” 'same_type_duplicate' |
| **'duplicate_preserved'** | ì¤‘ë³µ ìœ ì§€ | affected_rows == 2 + ìš°ì„ ìˆœìœ„ ë‚®ìŒ | 'kept_existing' |
| **'failed'** | ì²˜ë¦¬ ì‹¤íŒ¨ | ë…¼ë¦¬ ì˜¤ë¥˜ ë˜ëŠ” ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš° | 'error' |

### ì„¤ì • ë¡œì§

#### Case 1: 'new_inserted' (Line 2157)
```python
# UPSERT ì‹¤í–‰ í›„
elif affected_rows == 1:
    # ìƒˆë¡œ INSERTë¨
    processing_status = 'new_inserted'  # â† ì¤‘ë³µ ì²´í¬ ê²°ê³¼ (duplicate_typeìš©)
    logger.debug(f"ìƒˆ ë ˆì½”ë“œ ì‚½ì…: ID={record_id}, url_key_hash={url_key_hash[:16]}...")
```

**ì¡°ê±´**:
- `affected_rows == 1` (ì‹ ê·œ INSERT ì„±ê³µ)
- url_keyê°€ ìˆê³  domain_key_configë„ ìˆìŒ

#### Case 2: 'duplicate_updated' (Line 2177, 2190, 2216)
```python
# ìš°ì„ ìˆœìœ„ê°€ ë” ë†’ìŒ (Line 2177)
if current_priority > existing_priority:
    processing_status = 'duplicate_updated'
    duplicate_reason = {
        "reason": f"{self.site_type} (priority {current_priority}) > {existing_site_type} (priority {existing_priority})",
        "current_priority": current_priority,
        "existing_priority": existing_priority,
        "updated": True
    }

# ìš°ì„ ìˆœìœ„ê°€ ê°™ìŒ (Line 2190)
elif current_priority == existing_priority:
    processing_status = 'duplicate_updated'
    duplicate_reason = {
        "reason": f"{self.site_type} (priority {current_priority}) == {existing_site_type} (priority {existing_priority}), ìµœì‹  ë°ì´í„° ìš°ì„ ",
        "current_priority": current_priority,
        "existing_priority": existing_priority,
        "updated": True
    }

# UPSERT ì „ ì¡°íšŒ ì‹¤íŒ¨ (Line 2216)
else:
    processing_status = 'duplicate_updated'
    duplicate_reason = {"reason": "UPSERT ì „ ê¸°ì¡´ ë ˆì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨, ì—…ë°ì´íŠ¸ë¨ìœ¼ë¡œ ê°„ì£¼"}
    logger.warning("UPSERT ì „ ê¸°ì¡´ ë ˆì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨, ì—…ë°ì´íŠ¸ë¨ìœ¼ë¡œ ê°„ì£¼")
```

**ì¡°ê±´**:
- `affected_rows == 2` (UPDATE ë°œìƒ)
- `current_priority >= existing_priority` ë˜ëŠ” ê¸°ì¡´ ë ˆì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨

#### Case 3: 'duplicate_preserved' (Line 2203)
```python
else:
    # í˜„ì¬ê°€ ë” ë‚®ì€ ìš°ì„ ìˆœìœ„ â†’ ê¸°ì¡´ ìœ ì§€
    processing_status = 'duplicate_preserved'
    duplicate_reason = {
        "reason": f"{self.site_type} (priority {current_priority}) < {existing_site_type} (priority {existing_priority})",
        "current_priority": current_priority,
        "existing_priority": existing_priority,
        "updated": False
    }
    logger.info(
        f"âš ï¸  ìš°ì„ ìˆœìœ„ ë‚®ìŒ: {self.site_type}({current_priority}) < "
        f"{existing_site_type}({existing_priority}) â†’ ê¸°ì¡´ ë°ì´í„° ìœ ì§€"
    )
```

**ì¡°ê±´**:
- `affected_rows == 2` (UPDATE ë°œìƒ)
- `current_priority < existing_priority`

#### Case 4: 'failed' (Line 2147, 2222)
```python
# ë…¼ë¦¬ ì˜¤ë¥˜ (Line 2147)
if not domain_has_config:
    logger.error(
        f"âŒ ë…¼ë¦¬ ì˜¤ë¥˜: url_keyëŠ” ìƒì„±ë˜ì—ˆì§€ë§Œ domain_key_configê°€ ì—†ìŒ! "
        f"domain={domain}, url_key={url_key[:50]}... "
        f"fallback ë¡œì§ì´ ì¬í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ë²„ê·¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    processing_status = 'failed'
    duplicate_reason = {
        "reason": f"Logic error: url_key exists but domain_key_config missing (domain={domain})",
        "domain": domain,
        "url_key": url_key
    }

# ì˜ˆìƒì¹˜ ëª»í•œ affected_rows (Line 2222)
else:
    # ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš°
    processing_status = 'failed'
    duplicate_reason = {"reason": f"Unexpected affected_rows: {affected_rows}"}
    logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ affected_rows: {affected_rows}")
```

**ì¡°ê±´**:
- url_keyëŠ” ìˆëŠ”ë° domain_has_configê°€ False (ë…¼ë¦¬ ì˜¤ë¥˜)
- affected_rowsê°€ 1ë„ 2ë„ ì•„ë‹Œ ê²½ìš°

---

## ğŸ”„ processing_status â†’ duplicate_type ë§¤í•‘

### ë§¤í•‘ ë¡œì§ (Line 2260-2268)

```python
# duplicate_type ë§¤í•‘
duplicate_type_map = {
    'new_inserted': 'new_inserted',
    'duplicate_updated': 'replaced',  # ê¸°ë³¸ê°’ (ìš°ì„ ìˆœìœ„ ë¹„êµë¡œ ì„¸ë¶€í™”)
    'duplicate_preserved': 'kept_existing',
    'failed': 'error'
}

# duplicate_type ê²°ì •
announcement_duplicate_type = duplicate_type_map.get(processing_status, 'unknown')  # ê¸°ë³¸ê°’ì„ 'unknown'ìœ¼ë¡œ ë³€ê²½
```

### ì„¸ë¶€ íƒ€ì… ê²°ì • (Line 2271-2281)

```python
# duplicate_updatedì˜ ê²½ìš° ìš°ì„ ìˆœìœ„ ë¹„êµë¡œ ì„¸ë¶€ íƒ€ì… ê²°ì •
if processing_status == 'duplicate_updated' and existing_record_before_upsert:
    current_priority = self._get_priority(self.site_type)
    existing_priority_value = self._get_priority(existing_record_before_upsert.site_type)

    if current_priority == existing_priority_value:
        # ìš°ì„ ìˆœìœ„ ë™ì¼ â†’ same_type_duplicate
        announcement_duplicate_type = 'same_type_duplicate'
    elif current_priority > existing_priority_value:
        # ìš°ì„ ìˆœìœ„ ë†’ìŒ â†’ replaced
        announcement_duplicate_type = 'replaced'
    # current_priority < existing_priority_valueëŠ” ì´ë¡ ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŒ (UPSERT ì¡°ê±´ìƒ)
```

### ìµœì¢… ë§¤í•‘ í…Œì´ë¸”

| processing_status | ìš°ì„ ìˆœìœ„ ì¡°ê±´ | duplicate_type |
|------------------|------------|----------------|
| 'new_inserted' | - | 'new_inserted' |
| 'duplicate_updated' | current == existing | 'same_type_duplicate' |
| 'duplicate_updated' | current > existing | 'replaced' |
| 'duplicate_updated' | current < existing | 'replaced' (ì´ë¡ ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥) |
| 'duplicate_preserved' | current < existing | 'kept_existing' |
| 'failed' | - | 'error' |
| (ê¸°íƒ€) | - | 'unknown' |

---

## ğŸ“Š ì‹¤ì œ ë°ì´í„° ë¶„ì„

### announcement_pre_processing.processing_status (DB ì €ì¥ê°’)
```sql
SELECT processing_status, COUNT(*) as count
FROM announcement_pre_processing
GROUP BY processing_status
ORDER BY count DESC;

+-------------------+-------+
| processing_status | count |
+-------------------+-------+
| ì œì™¸              | 5,885 | (46.5%)
| archived          | 3,387 | (26.7%)
| ì„±ê³µ              | 3,232 | (25.5%)
| success           |   237 | (1.9%)
| error             |     1 | (0.01%)
+-------------------+-------+
```

**ë¶„ì„**:
- "ì œì™¸": ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­ (ì •ìƒ)
- "archived": ì™¸ë¶€ì—ì„œ ì—…ë°ì´íŠ¸ (ì •ìƒ)
- "ì„±ê³µ": ì •ìƒ ì²˜ë¦¬ (ì •ìƒ)
- "success": êµ¬ ë²„ì „ (ì •ìƒ)
- "error": ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (1ê±´ë§Œ ì¡´ì¬)

### announcement_duplicate_log.duplicate_type (ë¡œê·¸ ê°’)
```sql
SELECT duplicate_type, COUNT(*) as count
FROM announcement_duplicate_log
GROUP BY duplicate_type
ORDER BY count DESC;

+---------------------+-------+
| duplicate_type      | count |
+---------------------+-------+
| new_inserted        | 5,476 | (92.81%)
| unknown             |   422 | (7.15%)
| error               |   213 | (3.61%)
| unconfigured_domain |     2 | (0.03%)
+---------------------+-------+
```

**ë¶„ì„**:
- "new_inserted": ì‹ ê·œ ì‚½ì… (ì •ìƒ)
- "unknown": processing_statusê°€ ë§¤í•‘ì— ì—†ëŠ” ê²½ìš° (ë²„ê·¸)
- "error": processing_status='failed' (DomainKeyExtractor ì´ˆê¸°í™” ë¬¸ì œ)
- "unconfigured_domain": url_key ì—†ìŒ (ì •ìƒ)

---

## ğŸ› ë¬¸ì œì  ìš”ì•½

### ë¬¸ì œ 1: ë‘ ê°€ì§€ processing_status í˜¼ë™
- **DB ì €ì¥ìš© `status`**: "ì„±ê³µ", "ì œì™¸", "error" (í•œê¸€/ì˜ë¬¸)
- **ë‚´ë¶€ ë¡œì§ìš© `processing_status`**: 'new_inserted', 'duplicate_updated', etc. (ì˜ë¬¸)
- **í˜¼ë™ ê°€ëŠ¥ì„±**: ê°™ì€ ì´ë¦„ìœ¼ë¡œ ë‹¤ë¥¸ ìš©ë„

### ë¬¸ì œ 2: processing_status='failed' ì˜¤íŒ
- **ì›ì¸ 1**: DomainKeyExtractor ì´ˆê¸°í™” ì‹¤íŒ¨ â†’ domain_has_config í•­ìƒ False
- **ì›ì¸ 2**: API ë°ì´í„°ëŠ” ì™¸ë¶€ ë„ë©”ì¸ ì‚¬ìš©ì´ ì •ìƒì¸ë° 'failed'ë¡œ íŒë‹¨

### ë¬¸ì œ 3: 'unknown' duplicate_type ë°œìƒ
- `processing_status`ê°€ ë§¤í•‘ í…Œì´ë¸”ì— ì—†ëŠ” ê°’ì¸ ê²½ìš° 'unknown' ë°˜í™˜
- 422ê±´ ë°œìƒ (ì›ì¸ ì¡°ì‚¬ í•„ìš”)

---

## âœ… ê¶Œì¥ ì¡°ì¹˜

### 1. ë³€ìˆ˜ëª… ëª…í™•í™” (ì„ íƒ)
```python
# í˜„ì¬
status: str = "ì„±ê³µ"  # DB ì €ì¥ìš©
processing_status = 'new_inserted'  # ë‚´ë¶€ ë¡œì§ìš©

# ê°œì„ ì•ˆ
db_processing_status: str = "ì„±ê³µ"  # DB ì €ì¥ìš©
upsert_result_status = 'new_inserted'  # ë‚´ë¶€ ë¡œì§ìš©
```

### 2. DomainKeyExtractor ì´ˆê¸°í™” ìˆ˜ì • (í•„ìˆ˜)
```python
# announcement_pre_processor.py:67
engine = self.db_manager.SessionLocal().bind
db_config = {
    'host': engine.url.host,
    'user': engine.url.username,
    'password': engine.url.password,
    'database': engine.url.database,
    'port': engine.url.port,
    'charset': 'utf8mb4'
}
self.url_key_extractor = DomainKeyExtractor(db_config=db_config)
```

### 3. 'failed' íŒë‹¨ ë¡œì§ ê°œì„  (ê¶Œì¥)
```python
# Line 2141-2152
if not domain_has_config:
    if self.site_type == 'api_scrap':
        # API ë°ì´í„°ëŠ” ì™¸ë¶€ ë„ë©”ì¸ ì •ìƒ
        processing_status = 'new_inserted'
    else:
        # ì§€ìì²´ ë°ì´í„°ëŠ” ì˜¤ë¥˜
        processing_status = 'failed'
```

### 4. 'unknown' ì›ì¸ ì¡°ì‚¬ (í•„ìˆ˜)
```sql
-- ì–´ë–¤ processing_status ê°’ì´ 'unknown'ì„ ë°œìƒì‹œì¼°ëŠ”ì§€ í™•ì¸
-- (í˜„ì¬ëŠ” ë¡œê·¸ì— ê¸°ë¡ë˜ì§€ ì•Šì•„ í™•ì¸ ë¶ˆê°€)
```

---

**ì‘ì„±ì¼**: 2025-11-05
**ì‘ì„±ì**: AI Assistant
