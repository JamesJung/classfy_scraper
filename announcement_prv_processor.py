#!/usr/bin/env python3
"""
ê³µê³  ì²˜ë¦¬ ë©”ì¸ í”„ë¡œê·¸ë¨

ì‚¬ìš©ë²•:
    python announcement_prv_processor.py [ë””ë ‰í† ë¦¬ëª…] [ì‚¬ì´íŠ¸ì½”ë“œ]
    
ì˜ˆì‹œ:
    python announcement_prv_processor.py data.origin cbt
    python announcement_prv_processor.py  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
"""

import argparse
import json
import os
import sys
import time
import unicodedata
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.config.config import ConfigManager
from src.config.logConfig import setup_logging
from src.utils.attachmentProcessor import AttachmentProcessor
from src.utils.ollamaClient import AnnouncementPrvAnalyzer
from src.models.announcementPrvDatabase import AnnouncementPrvDatabaseManager, create_announcement_prv_tables
from src.utils.announcementFilter import AnnouncementFilter

logger = setup_logging(__name__)
config = ConfigManager().get_config()


class AnnouncementPrvProcessor:
    """ê³µê³  ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, attach_force: bool = False):
        self.attachment_processor = AttachmentProcessor()
        self.announcement_analyzer = AnnouncementPrvAnalyzer()
        self.db_manager = AnnouncementPrvDatabaseManager()
        self.filter = AnnouncementFilter()
        self.attach_force = attach_force
        
        # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)
        self._ensure_database_tables()
        
        # ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ
        self.exclusion_keywords = self._load_exclusion_keywords()
    
    def _ensure_database_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if self.db_manager.test_connection():
                self.db_manager.create_tables()
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ")
            else:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
    
    def _load_exclusion_keywords(self) -> List[Dict[str, Any]]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT EXCLUSION_ID, KEYWORD, DESCRIPTION
                    FROM EXCLUSION_KEYWORDS
                    WHERE IS_ACTIVE = TRUE
                    ORDER BY EXCLUSION_ID
                """))
                
                keywords = []
                for row in result:
                    keywords.append({
                        'id': row[0],
                        'keyword': row[1],
                        'description': row[2]
                    })
                
                logger.info(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ: {len(keywords)}ê°œ")
                return keywords
                
        except Exception as e:
            logger.warning(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def process_directory(self, directory_path: Path, site_code: str) -> bool:
        """
        ë‹¨ì¼ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            directory_path: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        folder_name = directory_path.name
        return self.process_directory_with_custom_name(directory_path, site_code, folder_name)
    
    def _collect_attachment_info(self, directory_path: Path) -> List[Dict[str, Any]]:
        """ì²¨ë¶€íŒŒì¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        attachment_info = []
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return attachment_info
        
        try:
            # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            # attachment_results = self.attachment_processor.process_directory_attachments(directory_path)
            
            # ì‹¤ì œ íŒŒì¼ë“¤ê³¼ ë§¤ì¹­
            for file_path in attachments_dir.iterdir():
                if file_path.is_file():
                    filename = file_path.stem
                    file_extension = file_path.suffix
                    
                    # íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                    try:
                        file_size = file_path.stat().st_size
                    except:
                        file_size = 0
                    
                    # ë³€í™˜ ê²°ê³¼ ì°¾ê¸°
                    # converted_content = attachment_results.get(filename, "")
                    # conversion_success = bool(converted_content)
                    
                    # ë³€í™˜ ë°©ë²• ì¶”ì •
                    # conversion_method = self._guess_conversion_method(file_extension)
                    
                    attachment_info.append({
                        "filename": filename,
                        "file_extension": file_extension,
                        "file_path": str(file_path),
                        "file_size": file_size,
                        # "converted_content": converted_content,
                        # "conversion_method": conversion_method,
                        # "conversion_success": conversion_success
                    })
            
            logger.info(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(attachment_info)}ê°œ")
            
        except Exception as e:
            logger.error(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return attachment_info
    
    def _guess_conversion_method(self, file_extension: str) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë³€í™˜ ë°©ë²•ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
        ext_lower = file_extension.lower()
        
        if ext_lower == '.pdf':
            return 'pdf_docling'
        elif ext_lower in ['.hwp', '.hwpx']:
            return 'hwp_markdown'
        elif ext_lower in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']:
            return 'ocr'
        else:
            return 'unknown'
    
    def _find_target_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        ì²˜ë¦¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            recursive: ì¬ê·€ì  ê²€ìƒ‰ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬ ëª©ë¡
        """
        site_dir = base_dir / site_code
        
        if not site_dir.exists():
            logger.error(f"ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {site_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ content.md ë˜ëŠ” attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
            logger.info(f"ì¬ê·€ì  ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘: {site_dir}")
            
            for root_path in site_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md íŒŒì¼ì´ ìˆê±°ë‚˜ attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬ ë°œê²¬: {root_path.relative_to(site_dir)}")
        else:
            # ê¸°ë³¸ ë™ì‘: ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ì˜ ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë§Œ ê²€ìƒ‰í•˜ê³  í´ë”ëª…ìœ¼ë¡œ ì •ë ¬
            all_directories = [d for d in site_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ë°œê²¬ëœ ì „ì²´ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
        
        # ì²˜ìŒ ëª‡ ê°œ í´ë”ëª… ë¡œê¹…
        if target_directories:
            logger.info(f"ì²« 5ê°œ í´ë”: {[d.name for d in target_directories[:5]]}")
        
        # force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ì œì™¸ (DBì—ì„œ prvë¡œ ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ)
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders("prv"))
            
            filtered_directories = []
            for directory in target_directories:
                # ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
                relative_path = directory.relative_to(site_dir)
                folder_name = self._normalize_korean_text(str(relative_path).replace("/", "_"))  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
            
            logger.info(f"ì „ì²´ ë°œê²¬ëœ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
            logger.info(f"ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {len(filtered_directories)}ê°œ")
            logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”: {len(processed_folders)}ê°œ")
            
            return filtered_directories
        else:
            # force ì˜µì…˜ì´ ìˆìœ¼ë©´ ëª¨ë“  ë””ë ‰í† ë¦¬ ë°˜í™˜
            logger.info(f"--force ì˜µì…˜: ëª¨ë“  ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ({len(target_directories)}ê°œ)")
            return target_directories
    
    def _find_prv_target_directories(self, city_dir: Path, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        PRVì˜ íŠ¹ì • ì‹œêµ° ë””ë ‰í† ë¦¬ì—ì„œ ì²˜ë¦¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            city_dir: ì‹œêµ° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: prv1/ê²½ê¸°ë„/ê°€í‰êµ°)
            recursive: ì¬ê·€ì  ê²€ìƒ‰ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬ ëª©ë¡
        """
        if not city_dir.exists():
            logger.error(f"ì‹œêµ° ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {city_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ content.md ë˜ëŠ” attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
            logger.info(f"ì¬ê·€ì  ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘: {city_dir}")
            
            for root_path in city_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md íŒŒì¼ì´ ìˆê±°ë‚˜ attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬ ë°œê²¬: {root_path.relative_to(city_dir)}")
        else:
            # ê¸°ë³¸ ë™ì‘: ì‹œêµ° ë””ë ‰í† ë¦¬ì˜ ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë§Œ ê²€ìƒ‰í•˜ê³  í´ë”ëª…ìœ¼ë¡œ ì •ë ¬
            all_directories = [d for d in city_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ì‹œêµ° {city_dir.name}ì—ì„œ ë°œê²¬ëœ ê³µê³  ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
        
        # ì²˜ìŒ ëª‡ ê°œ í´ë”ëª… ë¡œê¹…
        if target_directories:
            logger.debug(f"ì²« 5ê°œ ê³µê³  í´ë”: {[d.name for d in target_directories[:5]]}")
        
        # force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ì œì™¸ (DBì—ì„œ prvë¡œ ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ)
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders("prv"))
            
            filtered_directories = []
            for directory in target_directories:
                # ì‹œêµ° ê²½ë¡œë¥¼ í¬í•¨í•œ í´ë”ëª… ìƒì„± (DB ì €ì¥ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)
                city_path_from_base = str(city_dir).split('/')[-2:] # ì§€ì—­/ì‹œêµ° ì¶”ì¶œ
                city_path = '/'.join(city_path_from_base)
                relative_path = directory.relative_to(city_dir)
                folder_name = self._normalize_korean_text(f"{city_path.replace('/', '_')}_{str(relative_path).replace('/', '_')}")
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
            
            logger.info(f"ì‹œêµ° {city_dir.name} - ì „ì²´ ë°œê²¬: {len(target_directories)}ê°œ, ì²˜ë¦¬ ëŒ€ìƒ: {len(filtered_directories)}ê°œ")
            
            return filtered_directories
        else:
            # force ì˜µì…˜ì´ ìˆìœ¼ë©´ ëª¨ë“  ë””ë ‰í† ë¦¬ ë°˜í™˜
            logger.info(f"--force ì˜µì…˜: ì‹œêµ° {city_dir.name}ì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ({len(target_directories)}ê°œ)")
            return target_directories
    
    def process_all_sites(self, base_dir: Path, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        base_dir ë‚´ì˜ ëª¨ë“  ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ì—¬ëŸ¬ ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ í¬í•¨)
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        if not base_dir.exists():
            logger.error(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {base_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # base_dir ë‚´ì˜ ëª¨ë“  ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        site_directories = [d for d in base_dir.iterdir() if d.is_dir()]

        if not site_directories:
            logger.warning("ì²˜ë¦¬í•  ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # ì „ì²´ ê²°ê³¼ í†µê³„
        total_results = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        print(f"\n{'='*80}")
        print(f"ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ê³µê³  ì²˜ë¦¬ ì‹œì‘: {len(site_directories)}ê°œ ì‚¬ì´íŠ¸")
        print(f"ë°œê²¬ëœ ì‚¬ì´íŠ¸: {[d.name for d in site_directories]}")
        print(f"{'='*80}")
        
        # ì „ì²´ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        overall_start_time = time.time()
        
        # PRVëŠ” 2depth êµ¬ì¡°: ì§€ì—­/ì‹œêµ°/ê³µê³  
        for region_idx, region_dir in enumerate(site_directories, 1):
            region_name = region_dir.name
            
            print(f"\nğŸŒ [{region_idx}/{len(site_directories)}] ì§€ì—­ ì²˜ë¦¬ ì‹œì‘: {region_name}")
            print(f"{'â”€'*60}")
            
            # ê° ì§€ì—­ì˜ ì‹œêµ° ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸°
            city_directories = [d for d in region_dir.iterdir() if d.is_dir()]
            
            if not city_directories:
                print(f"   âš ï¸ {region_name}ì— ì‹œêµ° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            region_start_time = time.time()
            region_results = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
            
            for city_idx, city_dir in enumerate(city_directories, 1):
                city_name = city_dir.name
                site_code = "prv"  # PRV í”„ë¡œì„¸ì„œëŠ” site_codeë¥¼ "prv"ë¡œ ê³ ì •
                
                print(f"\nğŸ˜ï¸  [{city_idx}/{len(city_directories)}] ì‹œêµ° ì²˜ë¦¬: {region_name}/{city_name} (DBì €ì¥: {site_code})")
                
                city_start_time = time.time()
                
                # ê°œë³„ ì‹œêµ° ì²˜ë¦¬ - 2depth ê²½ë¡œ ì „ë‹¬
                city_path = f"{region_name}/{city_name}"
                city_results = self.process_prv_city_directories(base_dir, city_path, recursive, force, attach_force)
                
                # ì‹œêµ°ë³„ ê²°ê³¼ë¥¼ ì§€ì—­ ê²°ê³¼ì— í•©ì‚°
                region_results["total"] += city_results["total"]
                region_results["success"] += city_results["success"]
                region_results["failed"] += city_results["failed"]
                region_results["skipped"] += city_results["skipped"]
                
                city_elapsed = time.time() - city_start_time
                
                print(f"     âœ… {city_name} ì™„ë£Œ: ì„±ê³µ {city_results['success']}, ì‹¤íŒ¨ {city_results['failed']}, ê±´ë„ˆë›´ {city_results['skipped']} ({city_elapsed:.1f}ì´ˆ)")
            
            # ì§€ì—­ë³„ ê²°ê³¼ë¥¼ ì „ì²´ ê²°ê³¼ì— í•©ì‚°
            total_results["total"] += region_results["total"]
            total_results["success"] += region_results["success"]
            total_results["failed"] += region_results["failed"]
            total_results["skipped"] += region_results["skipped"]
            
            region_elapsed = time.time() - region_start_time
            
            print(f"\nâœ… ì§€ì—­ '{region_name}' ì²˜ë¦¬ ì™„ë£Œ ({region_elapsed:.1f}ì´ˆ)")
            print(f"   ì „ì²´ ì„±ê³µ: {region_results['success']}, ì‹¤íŒ¨: {region_results['failed']}, ê±´ë„ˆë›´: {region_results['skipped']}")
        
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        overall_elapsed = time.time() - overall_start_time
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ì „ì²´ ì‚¬ì´íŠ¸ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*80}")
        print(f"ì²˜ë¦¬í•œ ì‚¬ì´íŠ¸: {len(site_directories)}ê°œ")
        print(f"ì „ì²´ ëŒ€ìƒ: {total_results['total']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {total_results['success']}ê°œ ({(total_results['success']/max(total_results['total'], 1))*100:.1f}%)")
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {total_results['failed']}ê°œ")
        print(f"ê±´ë„ˆë›´ í•­ëª©: {total_results['skipped']}ê°œ")
        print(f"")
        print(f"ğŸ“Š ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {overall_elapsed:.1f}ì´ˆ ({overall_elapsed/60:.1f}ë¶„)")
        if total_results['total'] > 0:
            avg_time = overall_elapsed / total_results['total']
            print(f"í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time:.1f}ì´ˆ")
        print(f"{'='*80}")
        
        return total_results
        
    def process_site_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        íŠ¹ì • ì‚¬ì´íŠ¸ì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
            site_code: ì‹¤ì œ ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ëª…
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        # PRV í”„ë¡œì„¸ì„œì—ì„œëŠ” DBì— "prv"ë¡œ ì €ì¥
        db_site_code = "prv"
        
        # ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ ì°¾ê¸°
        target_directories = self._find_target_directories(base_dir, site_code, recursive, force)
        
        if not target_directories:
            logger.warning("ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        site_dir = base_dir / site_code
        
        print(f"\n{'='*60}")
        print(f"ê³µê³  ì²˜ë¦¬ ì‹œì‘: {site_code} (DB: {db_site_code}) ({total_count}ê°œ í´ë”)")
        print(f"{'='*60}")
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # ê°œë³„ í•­ëª© ì‹œì‘ ì‹œê°„
                item_start_time = time.time()
                
                # ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
                relative_path = directory.relative_to(site_dir)
                folder_name = self._normalize_korean_text(str(relative_path).replace("/", "_"))  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                progress_pct = (i / total_count) * 100
                print(f"\n[{i}/{total_count} : {progress_pct:.1f}%] {folder_name}")
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© í™•ì¸ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
                if not force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"  âœ“ ì´ë¯¸ ì²˜ë¦¬ë¨, ê±´ë„ˆëœ€ ({skip_elapsed:.1f}ì´ˆ)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    print("  ğŸ”„ ì´ë¯¸ ì²˜ë¦¬ë¨, --force ì˜µì…˜ìœ¼ë¡œ ì¬ì²˜ë¦¬")
                
                success = self.process_directory_with_custom_name(directory, db_site_code, folder_name, attach_force, force)
                
                # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"  âœ“ ì²˜ë¦¬ ì™„ë£Œ ({item_elapsed:.1f}ì´ˆ)")
                else:
                    results["failed"] += 1
                    print(f"  âœ— ì²˜ë¦¬ ì‹¤íŒ¨ ({item_elapsed:.1f}ì´ˆ)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"  âœ— ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}... ({error_elapsed:.1f}ì´ˆ)")
                logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({directory}): {e}")
        
        # ì¢…ë£Œ ì‹œê°„ ë° í†µê³„ ê³„ì‚°
        end_time = time.time()
        total_elapsed = end_time - start_time
        processed_count = results['success'] + results['failed']  # ì‹¤ì œ ì²˜ë¦¬í•œ ê°œìˆ˜ (ê±´ë„ˆë›´ ê²ƒ ì œì™¸)
        
        print(f"\n{'='*60}")
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {results['success']}/{total_count} ì„±ê³µ ({(results['success']/total_count)*100:.1f}%)")
        print(f"ê±´ë„ˆëœ€: {results['skipped']}, ì‹¤íŒ¨: {results['failed']}")
        print(f"")
        print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„ í†µê³„:")
        print(f"   ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ ({total_elapsed/60:.1f}ë¶„)")
        
        if processed_count > 0:
            avg_time_per_item = total_elapsed / processed_count
            print(f"   ì²˜ë¦¬í•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_item:.1f}ì´ˆ")
        
        if results['success'] > 0:
            avg_time_per_success = total_elapsed / results['success'] 
            print(f"   ì„±ê³µí•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_success:.1f}ì´ˆ")
        
        print(f"{'='*60}")
        
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ - ì „ì²´: {results['total']}, ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}, ê±´ë„ˆëœ€: {results['skipped']}")
        
        return results
    
    def process_prv_city_directories(self, base_dir: Path, city_path: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        PRV 2depth êµ¬ì¡°ì—ì„œ íŠ¹ì • ì‹œêµ°ì˜ ë””ë ‰í† ë¦¬ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ 
            city_path: ì‹œêµ° ê²½ë¡œ (ì˜ˆ: "ê²½ê¸°ë„/ê°€í‰êµ°")
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        # PRV í”„ë¡œì„¸ì„œì—ì„œëŠ” DBì— "prv"ë¡œ ì €ì¥
        db_site_code = "prv"
        
        # ì‹¤ì œ ì‹œêµ° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        city_dir = base_dir / city_path
        
        if not city_dir.exists():
            logger.warning(f"ì‹œêµ° ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {city_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ ì°¾ê¸° (ì‹œêµ° ë””ë ‰í† ë¦¬ ë‚´ì˜ ê³µê³  í´ë”ë“¤)
        target_directories = self._find_prv_target_directories(city_dir, recursive, force)
        
        if not target_directories:
            logger.warning(f"ì²˜ë¦¬í•  ê³µê³  ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {city_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # ê°œë³„ í•­ëª© ì‹œì‘ ì‹œê°„
                item_start_time = time.time()
                
                # ì‹œêµ° ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©í•˜ë˜, ì‹œêµ° ê²½ë¡œë„ í¬í•¨
                relative_path = directory.relative_to(city_dir)
                folder_name = self._normalize_korean_text(f"{city_path.replace('/', '_')}_{str(relative_path).replace('/', '_')}")
                
                progress_pct = (i / total_count) * 100
                print(f"     [{i}/{total_count} : {progress_pct:.1f}%] {relative_path.name}")
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© í™•ì¸ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
                if not force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"       âœ“ ì´ë¯¸ ì²˜ë¦¬ë¨, ê±´ë„ˆëœ€ ({skip_elapsed:.1f}ì´ˆ)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    print("       ğŸ”„ ì´ë¯¸ ì²˜ë¦¬ë¨, --force ì˜µì…˜ìœ¼ë¡œ ì¬ì²˜ë¦¬")
                
                success = self.process_directory_with_custom_name(directory, db_site_code, folder_name, attach_force, force)
                
                # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"       âœ“ ì²˜ë¦¬ ì™„ë£Œ ({item_elapsed:.1f}ì´ˆ)")
                else:
                    results["failed"] += 1
                    print(f"       âœ— ì²˜ë¦¬ ì‹¤íŒ¨ ({item_elapsed:.1f}ì´ˆ)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"       âœ— ì˜ˆì™¸ ë°œìƒ: {str(e)[:50]}... ({error_elapsed:.1f}ì´ˆ)")
                logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({directory}): {e}")
        
        logger.info(f"ì‹œêµ° ì²˜ë¦¬ ì™„ë£Œ - ì „ì²´: {results['total']}, ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}, ê±´ë„ˆëœ€: {results['skipped']}")
        
        return results
    
    def process_directory_with_custom_name(self, directory_path: Path, site_code: str, folder_name: str, attach_force: bool = False, force: bool = False) -> bool:
        """
        ì‚¬ìš©ì ì •ì˜ í´ë”ëª…ìœ¼ë¡œ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            directory_path: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            folder_name: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•  í´ë”ëª…
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        logger.info(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì‹œì‘: {folder_name}")
        
        try:
            # 0. ì¤‘ë³µ ì²˜ë¦¬ ì²´í¬ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
            if not force:
                if self.db_manager.is_already_processed(folder_name, site_code):
                    logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
                    return True  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì´ë¯¸ ì²˜ë¦¬ë¨)
            
            # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
            excluded_keywords = self._check_exclusion_keywords(folder_name)
            
            # 2. content.md íŒŒì¼ ì½ê¸°
            content_md_path = directory_path / "content.md"
            content_md = ""
            
            if content_md_path.exists():
                try:
                    with open(content_md_path, 'r', encoding='utf-8') as f:
                        content_md = f.read()
                    logger.info(f"content.md ì½ê¸° ì™„ë£Œ: {len(content_md)} ë¬¸ì")
                except Exception as e:
                    logger.error(f"content.md ì½ê¸° ì‹¤íŒ¨: {e}")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, "", 
                        status="ollama", error_message=f"content.md ì½ê¸° ì‹¤íŒ¨: {e}"
                    )
            else:
                logger.warning(f"content.md íŒŒì¼ì´ ì—†ìŒ: {content_md_path}")
            
            # 3. content.mdë§Œìœ¼ë¡œ ê¸°ë³¸ ê²€ì¦
            if not content_md.strip():
                logger.warning("content.md ë‚´ìš©ì´ ì—†ìŒ")
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="ollama", error_message="content.md ë‚´ìš©ì´ ì—†ìŒ"
                )
            
            # 4. ì œì™¸ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ì œì™¸ ì²˜ë¦¬
            if excluded_keywords:
                exclusion_msg = f"ì œì™¸ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {', '.join(excluded_keywords)}"
                logger.info(f"ì œì™¸ ì²˜ë¦¬: {folder_name} - {exclusion_msg}")
                
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="ì œì™¸", exclusion_keywords=excluded_keywords,
                    exclusion_reason=exclusion_msg
                )
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ì— 1ì°¨ ì €ì¥ (content.mdë§Œìœ¼ë¡œ status: ollama)
            record_id = self._save_processing_result(
                folder_name, site_code, content_md, "", 
                attachment_filenames=[],
                status="ollama", force=True  # force ì˜µì…˜ì€ í•­ìƒ UPSERTë¡œ ì²˜ë¦¬
            )

            #2025.09.03 TEMP  ë‚˜ì¤‘ì— ì´ê±° í’€ì–´ì•¼ í•¨. í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´  ì ì‹œ              
            # if not record_id:
            #     logger.error("1ì°¨ ì €ì¥ ì‹¤íŒ¨")
            #     return False
            
            # 5.5. ì œëª©ì—ì„œ "ì§€ì›" í‚¤ì›Œë“œ í™•ì¸ (Ollama ë¶„ì„ ì „ ì¡°ê¸° ë°˜í™˜)
            if content_md.strip():
                extracted_title = self._extract_title_from_content(content_md)
                logger.info(f"ì¶”ì¶œëœ ì œëª©: {extracted_title}")
                
                if "ì§€ì›" in extracted_title:
                    logger.info(f"ì œëª©ì— 'ì§€ì›' í‚¤ì›Œë“œ ë°œê²¬: {extracted_title}")
                    print(f"  âœ… ì œëª©ì— 'ì§€ì›' í‚¤ì›Œë“œ ë°œê²¬: {extracted_title[:50]}...")
                    
                    # ë°”ë¡œ ì„±ê³µ ì²˜ë¦¬í•˜ê³  ë‹¤ìŒ ê³µê³ ë¡œ ì´ë™
                    return self._update_processing_result_simple(
                        record_id, status="ì„±ê³µ", error_message="ì œëª©ì— ì§€ì›ì´ë¼ëŠ” ê¸€ì ìˆìŒ"
                    )
            
            # 6. content_mdë¡œ ì²«ë²ˆì§¸ ollama ë¶„ì„
            print("  ğŸ“‹ 1ì°¨ Ollama ë¶„ì„ ì¤‘ (content.md)...")
            first_response = None
            first_prompt = ""
            
            # IS_SUPPORT_PROGRAM í™•ì¸
            def is_support_program(response):
                if not response:
                    return False
                return response.get("IS_SUPPORT_PROGRAM", False) == True
            
            first_response, first_prompt = self._analyze_with_ollama(content_md)
            
            # 7. 1ì°¨ ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
            if not is_support_program(first_response):
                # IS_SUPPORT_PROGRAM=falseë©´ ì™„ë£Œ (ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì•ˆí•¨)
                logger.info("1ì°¨ ë¶„ì„ ì™„ë£Œ - ì§€ì›ì‚¬ì—…ì´ ì•„ë‹˜ (IS_SUPPORT_PROGRAM=false)")
                return self._update_processing_result(
                    record_id, first_response, first_prompt, status="ì„±ê³µ"
                )
            
            # 8. ì§€ì›ì‚¬ì—…ì¸ ê²½ìš° ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘
            logger.info("1ì°¨ ë¶„ì„ ê²°ê³¼: ì§€ì›ì‚¬ì—… í™•ì¸ë¨ - ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
            print("  ğŸ“‚ ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì¤‘...")
            
            combined_content = ""
            attachment_filenames = []
            
            try:
                combined_content, attachment_filenames = self._process_attachments_separately(directory_path, attach_force)
                logger.info(f"ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ ì™„ë£Œ: {len(combined_content)} ë¬¸ì, íŒŒì¼ {len(attachment_filenames)}ê°œ")
                
                # ì²¨ë¶€íŒŒì¼ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë°ì´íŠ¸
                self._update_attachment_info(record_id, combined_content, attachment_filenames)
                
            except Exception as e:
                logger.error(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨í•´ë„ 1ì°¨ ë¶„ì„ ê²°ê³¼ë¡œ ì§„í–‰
                combined_content = ""
                attachment_filenames = []
            
            # 9. EXTRACTED_TARGET í™•ì¸ ë° 2ì°¨ ë¶„ì„ í•„ìš”ì„± íŒë‹¨
            def has_valid_target(response):
                if not response:
                    return False
                target = response.get("EXTRACTED_TARGET", "")
                return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
            
            if has_valid_target(first_response):
                # ì„±ê³µ: 1ì°¨ ë¶„ì„ì—ì„œ ì´ë¯¸ ì§€ì›ëŒ€ìƒ ì •ë³´ê°€ ìˆìœ¼ë©´ ì™„ë£Œ
                logger.info("1ì°¨ ë¶„ì„ì—ì„œ EXTRACTED_TARGET ì¶”ì¶œë¨ - ì™„ë£Œ")
                return self._update_processing_result(
                    record_id, first_response, first_prompt, status="ì„±ê³µ"
                )
            
            # 10. 2ì°¨ ollama ë¶„ì„ (ì§€ì›ì‚¬ì—…ì´ì§€ë§Œ ì§€ì›ëŒ€ìƒ ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°)
            if combined_content.strip():
                print("  ğŸ“‹ 2ì°¨ Ollama ë¶„ì„ ì¤‘ (ì²¨ë¶€íŒŒì¼ë§Œ)...")
                logger.info("2ì°¨ ë¶„ì„ ì‹œì‘ - ì§€ì›ì‚¬ì—…ì´ì§€ë§Œ ì§€ì›ëŒ€ìƒ ì •ë³´ ë¶€ì¡±, ì²¨ë¶€íŒŒì¼ë§Œìœ¼ë¡œ ì¬ë¶„ì„")
                
                # ì²¨ë¶€íŒŒì¼ ë‚´ìš©ë§Œìœ¼ë¡œ 2ì°¨ ë¶„ì„
                second_response, second_prompt = self._analyze_with_ollama(combined_content)
                
                # ìµœì¢… ìƒíƒœ ê²°ì • ë¡œì§
                final_status = self._determine_final_status(first_response, second_response)
                
                return self._update_processing_result(
                    record_id, second_response, second_prompt, 
                    first_response=first_response, status=final_status
                )
            else:
                # 2ì°¨ ë¶„ì„ì´ í•„ìš”í•˜ì§€ë§Œ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°
                logger.info("2ì°¨ ë¶„ì„ í•„ìš”í•˜ì§€ë§Œ ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì—†ìŒ - 1ì°¨ ê²°ê³¼ë§Œ ì‚¬ìš©")
                final_status = self._determine_final_status(first_response, None)
                return self._update_processing_result(
                    record_id, first_response, first_prompt, status=final_status
                )
                
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return self._save_processing_result(
                folder_name, site_code, "", "",
                status="ollama", error_message=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}"
            )
    
    def _check_exclusion_keywords(self, folder_name: str) -> List[str]:
        """í´ë”ëª…ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ì²´í¬í•©ë‹ˆë‹¤."""
        matched_keywords = []
        
        for keyword_info in self.exclusion_keywords:
            keyword = keyword_info['keyword'].lower()
            if keyword in folder_name.lower():
                matched_keywords.append(keyword_info['keyword'])
                logger.debug(f"ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­: '{keyword}' in '{folder_name}'")
        
        return matched_keywords
    
    def _determine_final_status(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]]) -> str:
        """1ì°¨, 2ì°¨ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ìƒíƒœë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        
        # EXTRACTED_TARGETì´ ìœ íš¨í•œ ê°’ì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
        def has_valid_target(response):
            if not response:
                return False
            target = response.get("EXTRACTED_TARGET", "")
            return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        # 1ì°¨ ë˜ëŠ” 2ì°¨ì—ì„œ EXTRACTED_TARGETì´ ìˆìœ¼ë©´ ì„±ê³µ
        if has_valid_target(first_response) or has_valid_target(second_response):
            return "ì„±ê³µ"
        
        # 1ì°¨, 2ì°¨ ëª¨ë‘ ì •ë³´ ì—†ìŒì¸ ê²½ìš° completed
        first_no_info = not first_response or not has_valid_target(first_response)
        second_no_info = not second_response or not has_valid_target(second_response)
        
        if first_no_info and second_no_info:
            return "completed"
        
        # ê¸°ë³¸ê°’
        return "ollama"
    
    def _format_date_to_standard(self, date_str: str) -> Optional[str]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        import re
        
        if not date_str or date_str in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]:
            return None
        
        # ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_date = re.sub(r'[^\d\.\-/]', '', date_str.strip())
        
        # YYYY-MM-DD íŒ¨í„´ (ì´ë¯¸ í‘œì¤€ í˜•íƒœ)
        if re.match(r'^\d{4}-\d{2}-\d{2}$', clean_date):
            return clean_date
        
        # YYYY.MM.DD íŒ¨í„´
        match = re.match(r'^(\d{4})\.(\d{2})\.(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYYMMDD íŒ¨í„´
        match = re.match(r'^(\d{4})(\d{2})(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYY/MM/DD íŒ¨í„´
        match = re.match(r'^(\d{4})/(\d{2})/(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # ë” ë³µì¡í•œ íŒ¨í„´ë“¤ ì²˜ë¦¬
        # ì˜ˆ: 2024ë…„ 12ì›” 25ì¼
        year_month_day = re.search(r'(\d{4})ë…„?\s*(\d{1,2})ì›”?\s*(\d{1,2})ì¼?', date_str)
        if year_month_day:
            year = year_month_day.group(1)
            month = year_month_day.group(2).zfill(2)
            day = year_month_day.group(3).zfill(2)
            return f"{year}-{month}-{day}"
        
        # ìˆ«ìë§Œ 8ìë¦¬ì¸ ê²½ìš° (YYYYMMDD)
        numbers_only = re.sub(r'[^\d]', '', date_str)
        if len(numbers_only) == 8:
            return f"{numbers_only[:4]}-{numbers_only[4:6]}-{numbers_only[6:8]}"
        
        logger.debug(f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: '{date_str}' -> None")
        return None
    
    def _get_best_value_from_responses(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]], key: str) -> str:
        """first_responseì™€ second_response ì¤‘ì—ì„œ ìœ íš¨í•œ ê°’ì´ ìˆëŠ” ê²ƒì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        def is_valid_value(value):
            return value and value not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        # first_responseì—ì„œ ê°’ í™•ì¸ (ìš°ì„ ìˆœìœ„)
        if first_response and key in first_response:
            first_value = first_response.get(key, "")
            if is_valid_value(first_value):
                logger.debug(f"{key} ê°’ì„ first_responseì—ì„œ ì‚¬ìš©: {first_value}")
                return first_value
        
        # second_responseì—ì„œ ê°’ í™•ì¸
        if second_response and key in second_response:
            second_value = second_response.get(key, "")
            if is_valid_value(second_value):
                logger.debug(f"{key} ê°’ì„ second_responseì—ì„œ ì‚¬ìš©: {second_value}")
                return second_value
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return ""
    
    def _extract_title_from_content(self, content_md: str) -> str:
        """content.mdì—ì„œ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not content_md:
            return ""
        
        lines = content_md.split('\n')
        
        # ì²« ë²ˆì§¸ ë¹„ì–´ìˆì§€ ì•Šì€ ì¤„ì„ ì°¾ê¸°
        for line in lines[:10]:  # ìƒìœ„ 10ì¤„ë§Œ í™•ì¸
            line = line.strip()
            if line:
                # # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                if line.startswith('#'):
                    title = line.lstrip('#').strip()
                    logger.debug(f"ë§ˆí¬ë‹¤ìš´ í—¤ë”ì—ì„œ ì œëª© ì¶”ì¶œ: {title}")
                    return title
                
                # ì œëª©:, ê³µê³ ëª…: íŒ¨í„´ í™•ì¸
                for prefix in ['ì œëª©:', 'ê³µê³ ëª…:', 'ê³µê³  ì œëª©:', 'ì œëª© :']:
                    if line.lower().startswith(prefix.lower()):
                        title = line[len(prefix):].strip()
                        logger.debug(f"{prefix} íŒ¨í„´ì—ì„œ ì œëª© ì¶”ì¶œ: {title}")
                        return title
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì œëª©ìœ¼ë¡œ ì‚¬ìš© (ì²« ë²ˆì§¸ ì¤„)
                logger.debug(f"ì²« ë²ˆì§¸ ì¤„ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©: {line}")
                return line
        
        return ""
    
    def _normalize_korean_text(self, text: str) -> str:
        """í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ NFC(Composed) í˜•íƒœë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
        
        macOSëŠ” NFD(Decomposed) í˜•íƒœë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì´ ììŒê³¼ ëª¨ìŒìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ì €ì¥ë˜ì§€ë§Œ,
        ìœˆë„ìš°ì—ì„œëŠ” NFC(Composed) í˜•íƒœë¡œ í‘œì‹œí•´ì•¼ í•œê¸€ì´ ì˜¬ë°”ë¥´ê²Œ ë³´ì…ë‹ˆë‹¤.
        """
        return unicodedata.normalize('NFC', text)
    
    def _natural_sort_key(self, path: Path) -> tuple:
        """í´ë”ëª…ì˜ ìˆ«ì ë¶€ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ìì—° ì •ë ¬ì„ ìœ„í•œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        import re
        
        folder_name = path.name
        # ìˆ«ì_ì œëª© íŒ¨í„´ì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
        match = re.match(r'^(\d+)_(.*)$', folder_name)
        if match:
            number = int(match.group(1))
            title = match.group(2)
            return (number, title)
        else:
            # ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ë§¨ ë’¤ë¡œ
            return (float('inf'), folder_name)
    
    def _process_attachments_separately(self, directory_path: Path, attach_force: bool = False) -> tuple[str, List[str]]:
        """ì²¨ë¶€íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ë‚´ìš©ì„ ê²°í•©í•˜ê³  íŒŒì¼ëª… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return "", []
        
        combined_content = ""
        attachment_filenames = []
        
        # ì²˜ë¦¬ ê°€ëŠ¥í•œ í™•ì¥ì ì •ì˜
        supported_extensions = {'.pdf', '.hwp', '.hwpx', '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.pptx', '.docx', '.xlsx', '.md'}
        
        target_keywords = ['ì–‘ì‹', 'ì„œë¥˜', 'ì‹ ì²­ì„œ', 'ë™ì˜ì„œ']

        for file_path in attachments_dir.iterdir():
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                filename = file_path.stem
                

                logger.info(f"filename===={filename}")
                lowercase_filename = filename.lower()
                
                if any(keyword in lowercase_filename for keyword in target_keywords):                
                    logger.info(f"ì–‘ì‹, ì‹ ì²­ì„œ ë“±ì€ SKIP===={filename}")
                    continue; 

                # í™•ì¥ìê°€ ì—†ê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                if not file_extension or file_extension not in supported_extensions:
                    logger.debug(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ê±´ë„ˆëœ€: {file_path.name}")
                    continue
                
                attachment_filenames.append(self._normalize_korean_text(file_path.name))  # ì „ì²´ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
                logger.debug(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")
                
                # ì´ë¯¸ .md íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ì½ê¸°
                if file_extension == '.md':
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            combined_content += f"\n\n=== {self._normalize_korean_text(file_path.name)} ===\n{content}"
                            logger.debug(f"ì²¨ë¶€íŒŒì¼ .md ì§ì ‘ ì½ê¸° ì„±ê³µ: {file_path.name} ({len(content)} ë¬¸ì)")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ .md ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {file_path.name}")
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ .md ì§ì ‘ ì½ê¸° ì‹¤íŒ¨: {e}")
                    continue  # .md íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ, ë‹¤ìŒ íŒŒì¼ë¡œ
                
                # ì²¨ë¶€íŒŒì¼ëª….md íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ë‹¤ë¥¸ í™•ì¥ì íŒŒì¼ë“¤ì„ ìœ„í•œ)
                md_file_path = attachments_dir / f"{filename}.md"
                
                # attach_forceê°€ Trueì´ë©´ ê¸°ì¡´ .md íŒŒì¼ì„ ë¬´ì‹œí•˜ê³  ì›ë³¸ì—ì„œ ì¬ë³€í™˜
                if not attach_force and md_file_path.exists():
                    # .md íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì½ìŒ
                    try:
                        with open(md_file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            combined_content += f"\n\n=== {self._normalize_korean_text(filename)}.md ===\n{content}"
                            logger.debug(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì„±ê³µ: {filename}.md ({len(content)} ë¬¸ì)")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ .md ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {filename}.md")
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì‹¤íŒ¨: {e}")
                else:
                    # .md íŒŒì¼ì´ ì—†ê±°ë‚˜ attach_forceê°€ Trueì´ë©´ ì›ë³¸ íŒŒì¼ì„ ë³€í™˜
                    if attach_force and md_file_path.exists():
                        logger.info(f"--attach-force: ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì¬ë³€í™˜: {file_path.name}")
                    else:
                        logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹œì‘: {file_path.name}")
                        
                    try:
                        content = self.attachment_processor.process_single_file(file_path)
                        
                        if content and content.strip():
                            combined_content += f"\n\n=== {self._normalize_korean_text(file_path.name)} ===\n{content}"
                            logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì„±ê³µ: {file_path.name} ({len(content)} ë¬¸ì)")
                            
                            # ë³€í™˜ëœ ë‚´ìš©ì„ .md íŒŒì¼ë¡œ ì €ì¥
                            try:
                                with open(md_file_path, 'w', encoding='utf-8') as f:
                                    f.write(content)
                                logger.debug(f"ë³€í™˜ëœ ë‚´ìš©ì„ .mdë¡œ ì €ì¥: {md_file_path}")
                            except Exception as save_e:
                                logger.warning(f".md íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_e}")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ì—ì„œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {file_path.name}")
                        
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ ({file_path}): {e}")
        
        logger.info(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(attachment_filenames)}ê°œ íŒŒì¼, {len(combined_content)} ë¬¸ì")
        return combined_content.strip(), attachment_filenames
    
    def _analyze_with_ollama(self, content: str) -> tuple[Optional[Dict[str, Any]], str]:
        """Ollamaë¥¼ í†µí•´ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            return self.announcement_analyzer.analyze_announcement(content)
        except Exception as e:
            logger.error(f"Ollama ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, ""
    
    def _save_processing_result(
        self, 
        folder_name: str, 
        site_code: str, 
        content_md: str, 
        combined_content: str,
        attachment_filenames: List[str] = None,
        status: str = "ollama",
        exclusion_keywords: List[str] = None,
        exclusion_reason: str = None,
        error_message: str = None,
        force: bool = False
    ) -> Optional[int]:
        """ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                if force:
                    # UPSERT ë¡œì§
                    sql = text("""
                        INSERT INTO announcement_prv_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                        ON DUPLICATE KEY UPDATE
                            content_md = VALUES(content_md),
                            combined_content = VALUES(combined_content),
                            attachment_filenames = VALUES(attachment_filenames),
                            exclusion_keyword = VALUES(exclusion_keyword),
                            exclusion_reason = VALUES(exclusion_reason),
                            processing_status = VALUES(processing_status),
                            error_message = VALUES(error_message),
                            updated_at = NOW()
                    """)
                else:
                    # ì¼ë°˜ INSERT
                    sql = text("""
                        INSERT INTO announcement_prv_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                    """)
                
                params = {
                    'folder_name': folder_name,
                    'site_code': site_code,
                    'content_md': content_md,
                    'combined_content': combined_content,
                    'attachment_filenames': ', '.join(attachment_filenames) if attachment_filenames else None,
                    'exclusion_keyword': ', '.join(exclusion_keywords) if exclusion_keywords else None,
                    'exclusion_reason': exclusion_reason,
                    'processing_status': status,
                    'error_message': error_message
                }
                
                result = session.execute(sql, params)
                session.commit()
                
                record_id = result.lastrowid
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                return record_id
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def _update_processing_result_simple(
        self,
        record_id: int,
        status: str = "ì„±ê³µ",
        error_message: str = None
    ) -> bool:
        """ê°„ë‹¨í•œ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì œëª© ê¸°ë°˜ ì²˜ë¦¬ìš©)"""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                sql = text("""
                    UPDATE announcement_prv_processing SET
                        processing_status = :processing_status,
                        error_message = :error_message,
                        is_support_program = :is_support_program,
                        support_program_reason = :support_program_reason,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                params = {
                    'record_id': record_id,
                    'processing_status': status,
                    'error_message': error_message,
                    'is_support_program': 1,
                    'support_program_reason': 'ì œëª©ì— ì§€ì›ì´ë¼ëŠ” ë‹¨ì–´ ë“¤ì–´ê°'
                }
                
                session.execute(sql, params)
                session.commit()
                
                logger.info(f"ê°„ë‹¨í•œ ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}, ì§€ì›ì‚¬ì—…: True")
                return True
                
        except Exception as e:
            logger.error(f"ê°„ë‹¨í•œ ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _update_processing_result(
        self,
        record_id: int,
        ollama_response: Optional[Dict[str, Any]],
        ollama_prompt: str,
        first_response: Optional[Dict[str, Any]] = None,
        status: str = "ollama"
    ) -> bool:
        """ê¸°ì¡´ ë ˆì½”ë“œì— Ollama ë¶„ì„ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                # ì¶”ì¶œëœ ë°ì´í„° ì¤€ë¹„
                extracted_data = {}
                if ollama_response:
                    # URLê³¼ ë‚ ì§œëŠ” first_responseì™€ ollama_response ì¤‘ ê°’ì´ ìˆëŠ” ê²ƒì„ ìš°ì„  ì‚¬ìš©
                    extracted_url = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_URL")
                    extracted_announcement_date = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_ANNOUNCEMENT_DATE")
                    
                    extracted_data = {
                        'extracted_title': ollama_response.get("EXTRACTED_TITLE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_target': ollama_response.get("EXTRACTED_TARGET", "ì •ë³´ ì—†ìŒ"),
                        'extracted_target_type': ollama_response.get("EXTRACTED_TARGET_TYPE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_amount': ollama_response.get("EXTRACTED_AMOUNT", "ì •ë³´ ì—†ìŒ"),
                        'extracted_period': ollama_response.get("EXTRACTED_PERIOD", "ì •ë³´ ì—†ìŒ"),
                        'extracted_schedule': ollama_response.get("EXTRACTED_SCHEDULE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_content': ollama_response.get("EXTRACTED_CONTENT", "ì •ë³´ ì—†ìŒ"),
                        'extracted_announcement_date': extracted_announcement_date,
                        'original_url': extracted_url,
                        'formatted_announcement_date': self._format_date_to_standard(extracted_announcement_date),
                        'extracted_gov24_url': ollama_response.get("EXTRACTED_GOV24_URL", "ì •ë³´ ì—†ìŒ"),
                        'extracted_origin_url': ollama_response.get("EXTRACTED_ORIGIN_URL", "ì •ë³´ ì—†ìŒ"),
                        'is_support_program': ollama_response.get("IS_SUPPORT_PROGRAM"),
                        'support_program_reason': ollama_response.get("SUPPORT_PROGRAM_REASON", "ì •ë³´ ì—†ìŒ")
                    }
                
                sql = text("""
                    UPDATE announcement_prv_processing SET
                        ollama_first_response = :ollama_first_response,
                        ollama_response = :ollama_response,
                        ollama_prompt = :ollama_prompt,
                        extracted_title = :extracted_title,
                        extracted_target = :extracted_target,
                        extracted_target_type = :extracted_target_type,
                        extracted_amount = :extracted_amount,
                        extracted_period = :extracted_period,
                        extracted_schedule = :extracted_schedule,
                        extracted_content = :extracted_content,
                        extracted_announcement_date = :extracted_announcement_date,
                        original_url = :original_url,
                        formatted_announcement_date = :formatted_announcement_date,
                        extracted_gov24_url = :extracted_gov24_url,
                        extracted_origin_url = :extracted_origin_url,
                        is_support_program = :is_support_program,
                        support_program_reason = :support_program_reason,
                        processing_status = :processing_status,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                params = {
                    'record_id': record_id,
                    'ollama_first_response': json.dumps(first_response, ensure_ascii=False) if first_response else None,
                    'ollama_response': json.dumps(ollama_response, ensure_ascii=False) if ollama_response else None,
                    'ollama_prompt': ollama_prompt,
                    'processing_status': status,
                    **extracted_data
                }
                
                session.execute(sql, params)
                session.commit()
                
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                
                # í™”ë©´ì— ê²°ê³¼ í‘œì‹œ
                if ollama_response:
                    self._display_ollama_results(ollama_response)
                
                return True
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    def _update_attachment_info(self, record_id: int, combined_content: str, attachment_filenames: List[str]) -> bool:
        """ì²¨ë¶€íŒŒì¼ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            with self.db_manager.SessionLocal() as session:
                from sqlalchemy import text
                
                # ì²¨ë¶€íŒŒì¼ ì •ë³´ë§Œ ì—…ë°ì´íŠ¸
                sql = text("""
                    UPDATE announcement_prv_processing 
                    SET combined_content = :combined_content,
                        attachment_filenames = :attachment_filenames,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                filenames_str = json.dumps(attachment_filenames, ensure_ascii=False) if attachment_filenames else ""
                
                session.execute(sql, {
                    'record_id': record_id,
                    'combined_content': combined_content,
                    'attachment_filenames': filenames_str
                })
                session.commit()
                
                logger.info(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}")
                return True
                
        except Exception as e:
            logger.error(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _display_ollama_results(self, ollama_response: Dict[str, Any]):
        """Ollama ë¶„ì„ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."""
        print(f"  ğŸ¤– Ollama ë¶„ì„ ê²°ê³¼: ==== {ollama_response}")

        # IS_SUPPORT_PROGRAM í™•ì¸ ë° ì¶œë ¥
        if "IS_SUPPORT_PROGRAM" in ollama_response:
            if ollama_response.get('IS_SUPPORT_PROGRAM') == True:
                print("     âœ… ì§€ì›ì‚¬ì—…ì…ë‹ˆë‹¤.")
                if "SUPPORT_PROGRAM_REASON" in ollama_response and ollama_response["SUPPORT_PROGRAM_REASON"]:
                    print(f"     ğŸ“ ì§€ì›ì‚¬ì—… íŒë‹¨ ê·¼ê±°: {ollama_response['SUPPORT_PROGRAM_REASON'][:100]}...")
            else:
                print("     âŒ ì§€ì›ì‚¬ì—…ì´ ì•„ë‹™ë‹ˆë‹¤.")

        if "EXTRACTED_TARGET" in ollama_response and ollama_response["EXTRACTED_TARGET"]:
            print(f"     ğŸ“Œ ì§€ì›ëŒ€ìƒ: {ollama_response['EXTRACTED_TARGET'][:100]}...")
        if "EXTRACTED_TARGET_TYPE" in ollama_response and ollama_response["EXTRACTED_TARGET_TYPE"]:
            print(f"     ğŸ·ï¸ ì§€ì›ëŒ€ìƒë¶„ë¥˜: {ollama_response['EXTRACTED_TARGET_TYPE'][:50]}...")
        if "EXTRACTED_AMOUNT" in ollama_response and ollama_response["EXTRACTED_AMOUNT"]:
            print(f"     ğŸ’° ì§€ì›ê¸ˆì•¡: {ollama_response['EXTRACTED_AMOUNT'][:100]}...")
        if "EXTRACTED_TITLE" in ollama_response and ollama_response["EXTRACTED_TITLE"]:
            print(f"     ğŸ“ ì œëª©: {ollama_response['EXTRACTED_TITLE'][:100]}...")
        if "EXTRACTED_ANNOUNCEMENT_DATE" in ollama_response and ollama_response["EXTRACTED_ANNOUNCEMENT_DATE"]:
            print(f"     ğŸ“… ë“±ë¡ì¼: {ollama_response['EXTRACTED_ANNOUNCEMENT_DATE'][:50]}...")


def get_base_directory(args) -> Path:
    """ëª…ë ¹í–‰ ì¸ì ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ë””ë ‰í† ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    # ë””ë ‰í† ë¦¬ ê²°ì •
    if args.data:
        directory_name = args.data
    else:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        directory_name = os.getenv("DEFAULT_DIR", "data")
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ìƒì„±
    current_dir = Path.cwd()
    base_directory = current_dir / directory_name
    
    if not base_directory.exists():
        logger.error(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_directory}")
        sys.exit(1)
    
    logger.info(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬: {base_directory}")
    
    return base_directory


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ê³µê³  ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ë° ë¶„ì„ í”„ë¡œê·¸ë¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python announcement_prv_processor.py --data data.enhanced
  python announcement_prv_processor.py --data data.origin
  python announcement_prv_processor.py  # í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ì‚¬ìš©
  python announcement_prv_processor.py --data data.enhanced -r  # ì¬ê·€ì  ì²˜ë¦¬
  python announcement_prv_processor.py --data data.enhanced --attach-force  # ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬
        """
    )
    
    parser.add_argument(
        "--data", 
        type=str,
        help="ë°ì´í„° ë””ë ‰í† ë¦¬ëª… (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ë˜ëŠ” 'data')"
    )
    
    
    parser.add_argument(
        "--skip-processed", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© ê±´ë„ˆë›°ê¸° (ê¸°ë³¸ ë™ì‘)"
    )
    
    parser.add_argument(
        "--force", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬"
    )
    
    parser.add_argument(
        "-r", "--recursive",
        action="store_true",
        help="í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ëª¨ë“  í•˜ìœ„ ê²½ë¡œì˜ content.mdë‚˜ attachmentsë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬)"
    )
    
    parser.add_argument(
        "--attach-force",
        action="store_true",
        help="ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ (ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì›ë³¸ íŒŒì¼ì—ì„œ ë‹¤ì‹œ ë³€í™˜)"
    )
    
    args = parser.parse_args()
    
    try:
        # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²°ì •
        base_directory = get_base_directory(args)
        
        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        logger.info("ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ê³µê³  ì²˜ë¦¬ í”„ë¡œê·¸ë¨ ì‹œì‘")
        processor = AnnouncementPrvProcessor(attach_force=args.attach_force)
        
        # ëª¨ë“  ì‚¬ì´íŠ¸ ì²˜ë¦¬ ì‹¤í–‰
        results = processor.process_all_sites(base_directory, args.recursive, args.force, args.attach_force)
        
        # ê²°ê³¼ ì¶œë ¥ (process_site_directoriesì—ì„œ ì´ë¯¸ ìƒì„¸ ì¶œë ¥ë¨)
        print(f"\n=== ìµœì¢… ìš”ì•½ ===")
        print(f"ì „ì²´ ëŒ€ìƒ: {results['total']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {results['success']}ê°œ") 
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {results['failed']}ê°œ")
        print(f"ê±´ë„ˆë›´ í•­ëª©: {results['skipped']}ê°œ")
        
        if results['failed'] > 0:
            print(f"\nì‹¤íŒ¨í•œ í•­ëª©ì´ {results['failed']}ê°œ ìˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
        else:
            print("\nëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            sys.exit(0)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()