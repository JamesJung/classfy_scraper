#!/usr/bin/env python3
"""
ê³µê³  ì²˜ë¦¬ ë©”ì¸ í”„ë¡œê·¸ë¨

ì‚¬ìš©ë²•:
    python announcement_prv_file.py [ì˜µì…˜ë“¤]
    
ì˜ˆì‹œ:
    python announcement_prv_file.py --data prv7
    python announcement_prv_file.py --data prv8 --date 20250710  # 2025-07-10 ì´ì „ ê³µê³ ë§Œ ì²˜ë¦¬
    python announcement_prv_file.py --data prv7 -r --date 20250801  # ì¬ê·€ì ìœ¼ë¡œ 8ì›” 1ì¼ ì´ì „ ê³µê³ ë§Œ ì²˜ë¦¬
"""

import argparse
import json
import os
import re
import sys
import time
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.config.config import ConfigManager
from src.config.logConfig import setup_logging
from src.utils.attachmentProcessor import AttachmentProcessor
from src.utils.ollamaClient import AnnouncementPrvAnalyzer
from src.models.announcementPrvDatabase import AnnouncementPrvDatabaseManager, create_announcement_prv_tables
from src.utils.announcementFilter import AnnouncementFilter

logger = setup_logging(__name__)
config = ConfigManager().get_config()


class AnnouncementPrvProcessor:
    """ê³µê³  ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, attach_force: bool = False, date_filter: str = None):
        self.attachment_processor = AttachmentProcessor()
        self.announcement_analyzer = AnnouncementPrvAnalyzer()
        self.db_manager = AnnouncementPrvDatabaseManager()
        self.filter = AnnouncementFilter()
        self.attach_force = attach_force
        self.date_filter = date_filter
        
        # ë‚ ì§œ í•„í„° íŒŒì‹±
        self.filter_date = None
        if date_filter:
            self.filter_date = self._parse_date_filter(date_filter)
            if self.filter_date:
                logger.info(f"ë‚ ì§œ í•„í„° ì„¤ì •: {date_filter} ({self.filter_date.strftime('%Y-%m-%d')}) ì´ì „ ê³µê³ ë§Œ ì²˜ë¦¬")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)
        self._ensure_database_tables()
        
        # ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ
        self.exclusion_keywords = self._load_exclusion_keywords()
    
    def _ensure_database_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if self.db_manager.test_connection():
                self.db_manager.create_tables()
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ")
            else:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
    
    def _load_exclusion_keywords(self) -> List[Dict[str, Any]]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT EXCLUSION_ID, KEYWORD, DESCRIPTION
                    FROM EXCLUSION_KEYWORDS
                    WHERE IS_ACTIVE = TRUE
                    ORDER BY EXCLUSION_ID
                """))
                
                keywords = []
                for row in result:
                    keywords.append({
                        'id': row[0],
                        'keyword': row[1],
                        'description': row[2]
                    })
                
                logger.info(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ: {len(keywords)}ê°œ")
                return keywords
                
        except Exception as e:
            logger.warning(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_date_filter(self, date_str: str) -> Optional[datetime]:
        """
        ë‚ ì§œ í•„í„° ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            date_str: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
            
        Returns:
            datetime ê°ì²´ ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ì‹œ)
        """
        try:
            if len(date_str) != 8 or not date_str.isdigit():
                logger.error(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date_str} (YYYYMMDD í˜•ì‹ì´ì–´ì•¼ í•¨)")
                return None
            
            year = int(date_str[:4])
            month = int(date_str[4:6])
            day = int(date_str[6:8])
            
            return datetime(year, month, day)
            
        except ValueError as e:
            logger.error(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str} - {e}")
            return None
    
    def _extract_date_from_content(self, content_md: str) -> Optional[datetime]:
        """
        content.mdì—ì„œ ì‘ì„±ì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            content_md: content.md íŒŒì¼ ë‚´ìš©
            
        Returns:
            ì¶”ì¶œëœ ë‚ ì§œ ë˜ëŠ” None
        """
        if not content_md:
            return None
        
        # ë‹¤ì–‘í•œ ë‚ ì§œ íŒ¨í„´ ì •ì˜
        date_patterns = [
            # YYYY-MM-DD, YYYY/MM/DD, YYYY.MM.DD í˜•ì‹
            r'(\d{4})[-/.](\d{1,2})[-/.](\d{1,2})',
            # YYYYë…„ Mì›” Dì¼ í˜•ì‹
            r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',
            # MM/DD/YYYY, MM-DD-YYYY í˜•ì‹
            r'(\d{1,2})[-/.](\d{1,2})[-/.](\d{4})',
            # ë“±ë¡ì¼, ì‘ì„±ì¼, ê³µê³ ì¼ ë“±ì˜ í‚¤ì›Œë“œì™€ í•¨ê»˜ ë‚˜ì˜¤ëŠ” íŒ¨í„´
            r'(?:ë“±ë¡ì¼|ì‘ì„±ì¼|ê³µê³ ì¼|ê²Œì‹œì¼|ê³µì§€ì¼|ë°œí‘œì¼)[\s:]*(\d{4})[-/.](\d{1,2})[-/.](\d{1,2})',
            r'(?:ë“±ë¡ì¼|ì‘ì„±ì¼|ê³µê³ ì¼|ê²Œì‹œì¼|ê³µì§€ì¼|ë°œí‘œì¼)[\s:]*(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',
        ]
        
        try:
            for pattern in date_patterns:
                matches = re.findall(pattern, content_md)
                
                for match in matches:
                    try:
                        if len(match) == 3:
                            # íŒ¨í„´ì— ë”°ë¼ ë…„, ì›”, ì¼ ìˆœì„œ ê²°ì •
                            if pattern.startswith(r'(\d{1,2})'):  # MM/DD/YYYY í˜•ì‹
                                month, day, year = map(int, match)
                            else:  # YYYY/MM/DD í˜•ì‹
                                year, month, day = map(int, match)
                            
                            # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
                            if 1 <= month <= 12 and 1 <= day <= 31 and 2020 <= year <= 2030:
                                extracted_date = datetime(year, month, day)
                                logger.debug(f"ë‚ ì§œ ì¶”ì¶œ ì„±ê³µ: {extracted_date.strftime('%Y-%m-%d')}")
                                return extracted_date
                                
                    except (ValueError, TypeError):
                        continue
            
            logger.debug("content.mdì—ì„œ ìœ íš¨í•œ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
            
        except Exception as e:
            logger.warning(f"ë‚ ì§œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _should_process_by_date(self, content_md: str) -> bool:
        """
        ë‚ ì§œ í•„í„°ì— ë”°ë¼ ì²˜ë¦¬ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            content_md: content.md íŒŒì¼ ë‚´ìš©
            
        Returns:
            ì²˜ë¦¬ ì—¬ë¶€ (True: ì²˜ë¦¬í•¨, False: ê±´ë„ˆëœ€)
        """
        if not self.filter_date:
            # ë‚ ì§œ í•„í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
            return True
        
        extracted_date = self._extract_date_from_content(content_md)
        
        if not extracted_date:
            logger.warning("ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ€")
            return False
        
        # ì¶”ì¶œëœ ë‚ ì§œê°€ í•„í„° ë‚ ì§œë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ ê²½ìš° ì²˜ë¦¬
        should_process = extracted_date <= self.filter_date
        
        if should_process:
            logger.info(f"ë‚ ì§œ í•„í„° í†µê³¼: {extracted_date.strftime('%Y-%m-%d')} <= {self.filter_date.strftime('%Y-%m-%d')}")
        else:
            logger.info(f"ë‚ ì§œ í•„í„°ë¡œ ê±´ë„ˆëœ€: {extracted_date.strftime('%Y-%m-%d')} > {self.filter_date.strftime('%Y-%m-%d')}")
        
        return should_process
    
    def process_directory(self, directory_path: Path, site_code: str) -> bool:
        """
        ë‹¨ì¼ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            directory_path: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        folder_name = directory_path.name
        return self.process_directory_with_custom_name(directory_path, site_code, folder_name)
    
    def _collect_attachment_info(self, directory_path: Path) -> List[Dict[str, Any]]:
        """ì²¨ë¶€íŒŒì¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        attachment_info = []
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return attachment_info
        
        try:
            # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            # attachment_results = self.attachment_processor.process_directory_attachments(directory_path)
            
            # ì‹¤ì œ íŒŒì¼ë“¤ê³¼ ë§¤ì¹­
            for file_path in attachments_dir.iterdir():
                if file_path.is_file():
                    filename = file_path.stem
                    file_extension = file_path.suffix
                    
                    # íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                    try:
                        file_size = file_path.stat().st_size
                    except:
                        file_size = 0
                    
                    # ë³€í™˜ ê²°ê³¼ ì°¾ê¸°
                    # converted_content = attachment_results.get(filename, "")
                    # conversion_success = bool(converted_content)
                    
                    # ë³€í™˜ ë°©ë²• ì¶”ì •
                    # conversion_method = self._guess_conversion_method(file_extension)
                    
                    attachment_info.append({
                        "filename": filename,
                        "file_extension": file_extension,
                        "file_path": str(file_path),
                        "file_size": file_size,
                        # "converted_content": converted_content,
                        # "conversion_method": conversion_method,
                        # "conversion_success": conversion_success
                    })
            
            logger.info(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(attachment_info)}ê°œ")
            
        except Exception as e:
            logger.error(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return attachment_info
    
    def _guess_conversion_method(self, file_extension: str) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë³€í™˜ ë°©ë²•ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
        ext_lower = file_extension.lower()
        
        if ext_lower == '.pdf':
            return 'pdf_docling'
        elif ext_lower in ['.hwp', '.hwpx']:
            return 'hwp_markdown'
        elif ext_lower in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']:
            return 'ocr'
        else:
            return 'unknown'
    
    def _find_target_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        ì²˜ë¦¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            recursive: ì¬ê·€ì  ê²€ìƒ‰ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬ ëª©ë¡
        """
        site_dir = base_dir / site_code
        
        if not site_dir.exists():
            logger.error(f"ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {site_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ content.md ë˜ëŠ” attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
            logger.info(f"ì¬ê·€ì  ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘: {site_dir}")
            
            for root_path in site_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md íŒŒì¼ì´ ìˆê±°ë‚˜ attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬ ë°œê²¬: {root_path.relative_to(site_dir)}")
        else:
            # ê¸°ë³¸ ë™ì‘: ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ì˜ ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë§Œ ê²€ìƒ‰í•˜ê³  í´ë”ëª…ìœ¼ë¡œ ì •ë ¬
            all_directories = [d for d in site_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ë°œê²¬ëœ ì „ì²´ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
        
        # ì²˜ìŒ ëª‡ ê°œ í´ë”ëª… ë¡œê¹…
        if target_directories:
            logger.info(f"ì²« 5ê°œ í´ë”: {[d.name for d in target_directories[:5]]}")
        
        # force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ì œì™¸ (DBì—ì„œ prvë¡œ ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ)
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders("prv"))
            
            filtered_directories = []
            for directory in target_directories:
                # ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
                relative_path = directory.relative_to(site_dir)
                folder_name = self._normalize_korean_text(str(relative_path).replace("/", "_"))  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
            
            logger.info(f"ì „ì²´ ë°œê²¬ëœ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
            logger.info(f"ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {len(filtered_directories)}ê°œ")
            logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”: {len(processed_folders)}ê°œ")
            
            return filtered_directories
        else:
            # force ì˜µì…˜ì´ ìˆìœ¼ë©´ ëª¨ë“  ë””ë ‰í† ë¦¬ ë°˜í™˜
            logger.info(f"--force ì˜µì…˜: ëª¨ë“  ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ({len(target_directories)}ê°œ)")
            return target_directories
    
    def _find_prv_target_directories(self, city_dir: Path, recursive: bool = False, force: bool = False) -> List[Path]:
        """
        PRVì˜ íŠ¹ì • ì‹œêµ° ë””ë ‰í† ë¦¬ì—ì„œ ì²˜ë¦¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            city_dir: ì‹œêµ° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: prv1/ê²½ê¸°ë„/ê°€í‰êµ°)
            recursive: ì¬ê·€ì  ê²€ìƒ‰ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬ ëª©ë¡
        """
        if not city_dir.exists():
            logger.error(f"ì‹œêµ° ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {city_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ content.md ë˜ëŠ” attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
            logger.info(f"ì¬ê·€ì  ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘: {city_dir}")
            
            for root_path in city_dir.rglob("*"):
                if root_path.is_dir():
                    # content.md íŒŒì¼ì´ ìˆê±°ë‚˜ attachments í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬ ë°œê²¬: {root_path.relative_to(city_dir)}")
        else:
            # ê¸°ë³¸ ë™ì‘: ì‹œêµ° ë””ë ‰í† ë¦¬ì˜ ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë§Œ ê²€ìƒ‰í•˜ê³  í´ë”ëª…ìœ¼ë¡œ ì •ë ¬
            all_directories = [d for d in city_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ì‹œêµ° {city_dir.name}ì—ì„œ ë°œê²¬ëœ ê³µê³  ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
        
        # ì²˜ìŒ ëª‡ ê°œ í´ë”ëª… ë¡œê¹…
        if target_directories:
            logger.debug(f"ì²« 5ê°œ ê³µê³  í´ë”: {[d.name for d in target_directories[:5]]}")
        
        # force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ì œì™¸ (DBì—ì„œ prvë¡œ ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ)
        if not force:
            processed_folders = set(self.db_manager.get_processed_folders("prv"))
            
            filtered_directories = []
            for directory in target_directories:
                # ì‹œêµ° ê²½ë¡œë¥¼ í¬í•¨í•œ í´ë”ëª… ìƒì„± (DB ì €ì¥ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)
                city_path_from_base = str(city_dir).split('/')[-2:] # ì§€ì—­/ì‹œêµ° ì¶”ì¶œ
                city_path = '/'.join(city_path_from_base)
                relative_path = directory.relative_to(city_dir)
                folder_name = self._normalize_korean_text(f"{city_path.replace('/', '_')}_{str(relative_path).replace('/', '_')}")
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
            
            logger.info(f"ì‹œêµ° {city_dir.name} - ì „ì²´ ë°œê²¬: {len(target_directories)}ê°œ, ì²˜ë¦¬ ëŒ€ìƒ: {len(filtered_directories)}ê°œ")
            
            return filtered_directories
        else:
            # force ì˜µì…˜ì´ ìˆìœ¼ë©´ ëª¨ë“  ë””ë ‰í† ë¦¬ ë°˜í™˜
            logger.info(f"--force ì˜µì…˜: ì‹œêµ° {city_dir.name}ì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ({len(target_directories)}ê°œ)")
            return target_directories
    
    def process_all_sites(self, base_dir: Path, recursive: bool = False, force: bool = False, attach_force: bool = False, flat: bool = False) -> Dict[str, int]:
        """
        base_dir ë‚´ì˜ ëª¨ë“  ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ì—¬ëŸ¬ ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ í¬í•¨)
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            flat: í‰íƒ„í™”ëœ êµ¬ì¡° ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        if not base_dir.exists():
            logger.error(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {base_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # base_dir ë‚´ì˜ ëª¨ë“  ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        site_directories = [d for d in base_dir.iterdir() if d.is_dir()]

        if not site_directories:
            logger.warning("ì²˜ë¦¬í•  ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # ì „ì²´ ê²°ê³¼ í†µê³„
        total_results = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        print(f"\n{'='*80}")
        print(f"ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ê³µê³  ì²˜ë¦¬ ì‹œì‘: {len(site_directories)}ê°œ ì‚¬ì´íŠ¸")
        print(f"ë°œê²¬ëœ ì‚¬ì´íŠ¸: {[d.name for d in site_directories]}")
        print(f"{'='*80}")
        
        # ì „ì²´ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        overall_start_time = time.time()
        
        if flat:
            # í‰íƒ„í™”ëœ êµ¬ì¡° ì²˜ë¦¬: base_dir ë°”ë¡œ í•˜ìœ„ì— ê³µê³  í´ë”ë“¤ì´ ìˆìŒ
            print(f"ğŸ“ í‰íƒ„í™”ëœ êµ¬ì¡°ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            
            # ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ê³µê³  í´ë”ë¡œ ê°„ì£¼
            for folder_idx, announcement_dir in enumerate(site_directories, 1):
                folder_name = announcement_dir.name
                
                print(f"\nğŸ“‹ [{folder_idx}/{len(site_directories)}] ê³µê³  ì²˜ë¦¬: {folder_name}")
                
                start_time = time.time()
                
                # ê³µê³  í´ë”ë¥¼ ì§ì ‘ ì²˜ë¦¬ (site_codeëŠ” prvë¡œ ê³ ì •)
                success = self.process_directory_with_custom_name(
                    announcement_dir, "prv", folder_name, attach_force, force
                )
                
                processing_time = time.time() - start_time
                
                # ê²°ê³¼ ì§‘ê³„
                total_results["total"] += 1
                if success:
                    total_results["success"] += 1
                    status = "âœ… ì„±ê³µ"
                else:
                    total_results["failed"] += 1  
                    status = "âŒ ì‹¤íŒ¨"
                
                print(f"   {status} ({processing_time:.2f}ì´ˆ)")
                
        else:
            # ê¸°ì¡´ 2depth êµ¬ì¡°: ì§€ì—­/ì‹œêµ°/ê³µê³  
            for region_idx, region_dir in enumerate(site_directories, 1):
                region_name = region_dir.name
                
                print(f"\nğŸŒ [{region_idx}/{len(site_directories)}] ì§€ì—­ ì²˜ë¦¬ ì‹œì‘: {region_name}")
                print(f"{'â”€'*60}")
                
                # ê° ì§€ì—­ì˜ ì‹œêµ° ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸°
                city_directories = [d for d in region_dir.iterdir() if d.is_dir()]
                
                if not city_directories:
                    print(f"   âš ï¸ {region_name}ì— ì‹œêµ° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                    
                region_start_time = time.time()
                region_results = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
                
                for city_idx, city_dir in enumerate(city_directories, 1):
                    city_name = city_dir.name
                    site_code = "prv"  # PRV í”„ë¡œì„¸ì„œëŠ” site_codeë¥¼ "prv"ë¡œ ê³ ì •
                    
                    print(f"\nğŸ˜ï¸  [{city_idx}/{len(city_directories)}] ì‹œêµ° ì²˜ë¦¬: {region_name}/{city_name} (DBì €ì¥: {site_code})")
                    
                    city_start_time = time.time()
                    
                    # ê°œë³„ ì‹œêµ° ì²˜ë¦¬ - 2depth ê²½ë¡œ ì „ë‹¬
                    city_path = f"{region_name}/{city_name}"
                    city_results = self.process_prv_city_directories(base_dir, city_path, recursive, force, attach_force)
                    
                    # ì‹œêµ°ë³„ ê²°ê³¼ë¥¼ ì§€ì—­ ê²°ê³¼ì— í•©ì‚°
                    region_results["total"] += city_results["total"]
                    region_results["success"] += city_results["success"]
                    region_results["failed"] += city_results["failed"]
                    region_results["skipped"] += city_results["skipped"]
                    
                    city_elapsed = time.time() - city_start_time
                    
                    print(f"     âœ… {city_name} ì™„ë£Œ: ì„±ê³µ {city_results['success']}, ì‹¤íŒ¨ {city_results['failed']}, ê±´ë„ˆë›´ {city_results['skipped']} ({city_elapsed:.1f}ì´ˆ)")
                
                # ì§€ì—­ë³„ ê²°ê³¼ë¥¼ ì „ì²´ ê²°ê³¼ì— í•©ì‚°
                total_results["total"] += region_results["total"]
                total_results["success"] += region_results["success"]
                total_results["failed"] += region_results["failed"]
                total_results["skipped"] += region_results["skipped"]
                
                region_elapsed = time.time() - region_start_time
                
                print(f"\nâœ… ì§€ì—­ '{region_name}' ì²˜ë¦¬ ì™„ë£Œ ({region_elapsed:.1f}ì´ˆ)")
                print(f"   ì „ì²´ ì„±ê³µ: {region_results['success']}, ì‹¤íŒ¨: {region_results['failed']}, ê±´ë„ˆë›´: {region_results['skipped']}")
        
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        overall_elapsed = time.time() - overall_start_time
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ì „ì²´ ì‚¬ì´íŠ¸ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*80}")
        print(f"ì²˜ë¦¬í•œ ì‚¬ì´íŠ¸: {len(site_directories)}ê°œ")
        print(f"ì „ì²´ ëŒ€ìƒ: {total_results['total']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {total_results['success']}ê°œ ({(total_results['success']/max(total_results['total'], 1))*100:.1f}%)")
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {total_results['failed']}ê°œ")
        print(f"ê±´ë„ˆë›´ í•­ëª©: {total_results['skipped']}ê°œ")
        print(f"")
        print(f"ğŸ“Š ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {overall_elapsed:.1f}ì´ˆ ({overall_elapsed/60:.1f}ë¶„)")
        if total_results['total'] > 0:
            avg_time = overall_elapsed / total_results['total']
            print(f"í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time:.1f}ì´ˆ")
        print(f"{'='*80}")
        
        return total_results
        
    def process_site_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        íŠ¹ì • ì‚¬ì´íŠ¸ì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬
            site_code: ì‹¤ì œ ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ëª…
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        # PRV í”„ë¡œì„¸ì„œì—ì„œëŠ” DBì— "prv"ë¡œ ì €ì¥
        db_site_code = "prv"
        
        # ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ ì°¾ê¸°
        target_directories = self._find_target_directories(base_dir, site_code, recursive, force)
        
        if not target_directories:
            logger.warning("ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        site_dir = base_dir / site_code
        
        print(f"\n{'='*60}")
        print(f"ê³µê³  ì²˜ë¦¬ ì‹œì‘: {site_code} (DB: {db_site_code}) ({total_count}ê°œ í´ë”)")
        print(f"{'='*60}")
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # ê°œë³„ í•­ëª© ì‹œì‘ ì‹œê°„
                item_start_time = time.time()
                
                # ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
                relative_path = directory.relative_to(site_dir)
                folder_name = self._normalize_korean_text(str(relative_path).replace("/", "_"))  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                progress_pct = (i / total_count) * 100
                print(f"\n[{i}/{total_count} : {progress_pct:.1f}%] {folder_name}")
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© í™•ì¸ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
                if not force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"  âœ“ ì´ë¯¸ ì²˜ë¦¬ë¨, ê±´ë„ˆëœ€ ({skip_elapsed:.1f}ì´ˆ)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    print("  ğŸ”„ ì´ë¯¸ ì²˜ë¦¬ë¨, --force ì˜µì…˜ìœ¼ë¡œ ì¬ì²˜ë¦¬")
                
                success = self.process_directory_with_custom_name(directory, db_site_code, folder_name, attach_force, force)
                
                # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"  âœ“ ì²˜ë¦¬ ì™„ë£Œ ({item_elapsed:.1f}ì´ˆ)")
                else:
                    results["failed"] += 1
                    print(f"  âœ— ì²˜ë¦¬ ì‹¤íŒ¨ ({item_elapsed:.1f}ì´ˆ)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"  âœ— ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}... ({error_elapsed:.1f}ì´ˆ)")
                logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({directory}): {e}")
        
        # ì¢…ë£Œ ì‹œê°„ ë° í†µê³„ ê³„ì‚°
        end_time = time.time()
        total_elapsed = end_time - start_time
        processed_count = results['success'] + results['failed']  # ì‹¤ì œ ì²˜ë¦¬í•œ ê°œìˆ˜ (ê±´ë„ˆë›´ ê²ƒ ì œì™¸)
        
        print(f"\n{'='*60}")
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {results['success']}/{total_count} ì„±ê³µ ({(results['success']/total_count)*100:.1f}%)")
        print(f"ê±´ë„ˆëœ€: {results['skipped']}, ì‹¤íŒ¨: {results['failed']}")
        print(f"")
        print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„ í†µê³„:")
        print(f"   ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ ({total_elapsed/60:.1f}ë¶„)")
        
        if processed_count > 0:
            avg_time_per_item = total_elapsed / processed_count
            print(f"   ì²˜ë¦¬í•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_item:.1f}ì´ˆ")
        
        if results['success'] > 0:
            avg_time_per_success = total_elapsed / results['success'] 
            print(f"   ì„±ê³µí•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_success:.1f}ì´ˆ")
        
        print(f"{'='*60}")
        
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ - ì „ì²´: {results['total']}, ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}, ê±´ë„ˆëœ€: {results['skipped']}")
        
        return results
    
    def process_prv_city_directories(self, base_dir: Path, city_path: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """
        PRV 2depth êµ¬ì¡°ì—ì„œ íŠ¹ì • ì‹œêµ°ì˜ ë””ë ‰í† ë¦¬ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ 
            city_path: ì‹œêµ° ê²½ë¡œ (ì˜ˆ: "ê²½ê¸°ë„/ê°€í‰êµ°")
            recursive: ì¬ê·€ì  ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        # PRV í”„ë¡œì„¸ì„œì—ì„œëŠ” DBì— "prv"ë¡œ ì €ì¥
        db_site_code = "prv"
        
        # ì‹¤ì œ ì‹œêµ° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        city_dir = base_dir / city_path
        
        if not city_dir.exists():
            logger.warning(f"ì‹œêµ° ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {city_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        # ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ ì°¾ê¸° (ì‹œêµ° ë””ë ‰í† ë¦¬ ë‚´ì˜ ê³µê³  í´ë”ë“¤)
        target_directories = self._find_prv_target_directories(city_dir, recursive, force)
        
        if not target_directories:
            logger.warning(f"ì²˜ë¦¬í•  ê³µê³  ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {city_dir}")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        
        for i, directory in enumerate(target_directories, 1):
            try:
                # ê°œë³„ í•­ëª© ì‹œì‘ ì‹œê°„
                item_start_time = time.time()
                
                # ì‹œêµ° ë””ë ‰í† ë¦¬ë¡œë¶€í„°ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©í•˜ë˜, ì‹œêµ° ê²½ë¡œë„ í¬í•¨
                relative_path = directory.relative_to(city_dir)
                folder_name = self._normalize_korean_text(f"{city_path.replace('/', '_')}_{str(relative_path).replace('/', '_')}")
                
                progress_pct = (i / total_count) * 100
                print(f"     [{i}/{total_count} : {progress_pct:.1f}%] {relative_path.name}")
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© í™•ì¸ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
                if not force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    skip_elapsed = time.time() - item_start_time
                    print(f"       âœ“ ì´ë¯¸ ì²˜ë¦¬ë¨, ê±´ë„ˆëœ€ ({skip_elapsed:.1f}ì´ˆ)")
                    results["skipped"] += 1
                    continue
                elif force and self.db_manager.is_already_processed(folder_name, db_site_code):
                    print("       ğŸ”„ ì´ë¯¸ ì²˜ë¦¬ë¨, --force ì˜µì…˜ìœ¼ë¡œ ì¬ì²˜ë¦¬")
                
                success = self.process_directory_with_custom_name(directory, db_site_code, folder_name, attach_force, force)
                
                # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                item_elapsed = time.time() - item_start_time
                
                if success:
                    results["success"] += 1
                    print(f"       âœ“ ì²˜ë¦¬ ì™„ë£Œ ({item_elapsed:.1f}ì´ˆ)")
                else:
                    results["failed"] += 1
                    print(f"       âœ— ì²˜ë¦¬ ì‹¤íŒ¨ ({item_elapsed:.1f}ì´ˆ)")
                    
            except Exception as e:
                error_elapsed = time.time() - item_start_time
                results["failed"] += 1
                print(f"       âœ— ì˜ˆì™¸ ë°œìƒ: {str(e)[:50]}... ({error_elapsed:.1f}ì´ˆ)")
                logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({directory}): {e}")
        
        logger.info(f"ì‹œêµ° ì²˜ë¦¬ ì™„ë£Œ - ì „ì²´: {results['total']}, ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}, ê±´ë„ˆëœ€: {results['skipped']}")
        
        return results
    
    def process_directory_with_custom_name(self, directory_path: Path, site_code: str, folder_name: str, attach_force: bool = False, force: bool = False) -> bool:
        """
        ì‚¬ìš©ì ì •ì˜ í´ë”ëª…ìœ¼ë¡œ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            directory_path: ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            site_code: ì‚¬ì´íŠ¸ ì½”ë“œ
            folder_name: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•  í´ë”ëª…
            attach_force: ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ ì—¬ë¶€
            force: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        logger.info(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì‹œì‘: {folder_name}")
        
        try:
            # 0. folder_name ì¤‘ë³µ ì²´í¬ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
            if not force:
                if self._check_folder_name_exists(folder_name, site_code):
                    logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
                    return True  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì´ë¯¸ ì²˜ë¦¬ë¨)
            
            # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
            excluded_keywords = self._check_exclusion_keywords(folder_name)
            
            # 2. content.md íŒŒì¼ ì½ê¸°
            content_md_path = directory_path / "content.md"
            content_md = ""
            
            if content_md_path.exists():
                try:
                    with open(content_md_path, 'r', encoding='utf-8') as f:
                        content_md = f.read()
                    logger.info(f"content.md ì½ê¸° ì™„ë£Œ: {len(content_md)} ë¬¸ì")
                except Exception as e:
                    logger.error(f"content.md ì½ê¸° ì‹¤íŒ¨: {e}")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, "", 
                        status="error", error_message=f"content.md ì½ê¸° ì‹¤íŒ¨: {e}"
                    )
            else:
                logger.warning(f"content.md íŒŒì¼ì´ ì—†ìŒ: {content_md_path}")
            # 3. content.mdë§Œìœ¼ë¡œ ê¸°ë³¸ ê²€ì¦
            if not content_md.strip():
                logger.warning("content.md ë‚´ìš©ì´ ì—†ìŒ")
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="error", error_message="content.md ë‚´ìš©ì´ ì—†ìŒ"
                )
            
            title = self._extract_title_from_content(content_md) or "ì •ë³´ ì—†ìŒ"
            gov24_url = self._extract_gov24_url_from_content(content_md) or "ì •ë³´ ì—†ìŒ"
            origin_url = self._extract_origin_url_from_content(content_md) or "ì •ë³´ ì—†ìŒ"
            announcement_date = self._extract_announcement_date_from_content(content_md) or "ì •ë³´ ì—†ìŒ"
            
            # 0.5. origin_url ì¤‘ë³µ ì²´í¬
            is_duplicate_url = False
            if origin_url and origin_url != "ì •ë³´ ì—†ìŒ":
                is_duplicate_url = self._check_origin_url_exists(origin_url, site_code)
            # 3. ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ (content.mdì™€ ë¶„ë¦¬)
            try:
                combined_content, attachment_filenames, attachment_files_info = self._process_attachments_separately(directory_path, attach_force)
                
                if not content_md.strip() and not combined_content.strip():
                    logger.warning("ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŒ")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, combined_content,
                        attachment_filenames=attachment_filenames,
                        attachment_files_info=attachment_files_info,
                        status="error", error_message="ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŒ"
                    )
                
                logger.info(f"ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ ì™„ë£Œ: {len(combined_content)} ë¬¸ì, íŒŒì¼ {len(attachment_filenames)}ê°œ")
                
            except Exception as e:
                logger.error(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="ollama", error_message=f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                )
                        
            # 2.5. ë‚ ì§œ í•„í„°ë§ ê²€ì‚¬
            # if not self._should_process_by_date(content_md):
            #     logger.info(f"ë‚ ì§œ í•„í„°ë¡œ ì¸í•´ ê±´ë„ˆë›°ëŠ” í´ë”: {folder_name}")
            #     return self._save_processing_result(
            #         folder_name, site_code, content_md, "",
            #         attachment_filenames=[],
            #         status="ê±´ë„ˆëœ€", error_message="ë‚ ì§œ í•„í„° ì¡°ê±´ì— ë§ì§€ ì•ŠìŒ"
            #     )
            
            
            # 4. ì œì™¸ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ì œì™¸ ì²˜ë¦¬
            if excluded_keywords:
                exclusion_msg = f"ì œì™¸ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {', '.join(excluded_keywords)}"
                logger.info(f"ì œì™¸ ì²˜ë¦¬: {folder_name} - {exclusion_msg}")
                
                return self._save_processing_result(
                    folder_name, site_code, content_md, combined_content,
                    attachment_filenames=attachment_filenames,
                    attachment_files_info=attachment_files_info,
                    status="ì œì™¸", 
                    title=title,
                    announcement_date=announcement_date,
                    gov24_url=gov24_url,
                    origin_url=origin_url,
                    exclusion_keywords=excluded_keywords,
                    exclusion_reason=exclusion_msg
                )
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ì— 1ì°¨ ì €ì¥ (ì¤‘ë³µ URL ì—¬ë¶€ì— ë”°ë¼ ìƒíƒœ ê²°ì •)
            final_status = "ì¤‘ë³µ" if is_duplicate_url else "ì„±ê³µ"
            
            record_id = self._save_processing_result(
                folder_name, site_code, content_md, combined_content, 
                attachment_filenames=attachment_filenames,
                attachment_files_info=attachment_files_info,
                title=title,
                announcement_date=announcement_date,
                gov24_url=gov24_url,
                origin_url=origin_url,
                status=final_status, force=True  # force ì˜µì…˜ì€ í•­ìƒ UPSERTë¡œ ì²˜ë¦¬
            )
            
            if is_duplicate_url:
                logger.info(f"origin_url ì¤‘ë³µìœ¼ë¡œ 'ì¤‘ë³µ' ìƒíƒœë¡œ ì €ì¥: {folder_name}")
            
            if record_id:
                logger.info(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì™„ë£Œ: {folder_name}")
                return True
            else:
                logger.error(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {folder_name}")
                return False
                
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            result = self._save_processing_result(
                folder_name, site_code, "", "",
                status="error", error_message=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}"
            )
            return result is not None
    
    def _check_exclusion_keywords(self, folder_name: str) -> List[str]:
        """í´ë”ëª…ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ì²´í¬í•©ë‹ˆë‹¤."""
        matched_keywords = []
        
        for keyword_info in self.exclusion_keywords:
            keyword = keyword_info['keyword'].lower()
            if keyword in folder_name.lower():
                matched_keywords.append(keyword_info['keyword'])
                logger.debug(f"ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­: '{keyword}' in '{folder_name}'")
        
        return matched_keywords
    
    def _check_folder_name_exists(self, folder_name: str, site_code: str) -> bool:
        """folder_nameì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT COUNT(*) FROM announcement_prv_file 
                    WHERE folder_name = :folder_name AND site_code = :site_code
                """), {
                    'folder_name': folder_name,
                    'site_code': site_code
                })
                
                count = result.scalar()
                exists = count > 0
                
                if exists:
                    logger.debug(f"folder_name ì¤‘ë³µ ë°œê²¬: {folder_name}")
                
                return exists
                
        except Exception as e:
            logger.error(f"folder_name ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def _check_origin_url_exists(self, origin_url: str, site_code: str) -> bool:
        """origin_urlì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT COUNT(*) FROM announcement_prv_file 
                    WHERE origin_url = :origin_url AND site_code = :site_code
                """), {
                    'origin_url': origin_url,
                    'site_code': site_code
                })
                
                count = result.scalar()
                exists = count > 0
                
                if exists:
                    logger.debug(f"origin_url ì¤‘ë³µ ë°œê²¬: {origin_url}")
                
                return exists
                
        except Exception as e:
            logger.error(f"origin_url ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def _determine_final_status(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]]) -> str:
        """1ì°¨, 2ì°¨ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ìƒíƒœë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        
        # EXTRACTED_TARGETì´ ìœ íš¨í•œ ê°’ì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
        def has_valid_target(response):
            if not response:
                return False
            target = response.get("EXTRACTED_TARGET", "")
            return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        # 1ì°¨ ë˜ëŠ” 2ì°¨ì—ì„œ EXTRACTED_TARGETì´ ìˆìœ¼ë©´ ì„±ê³µ
        if has_valid_target(first_response) or has_valid_target(second_response):
            return "ì„±ê³µ"
        
        # 1ì°¨, 2ì°¨ ëª¨ë‘ ì •ë³´ ì—†ìŒì¸ ê²½ìš° completed
        first_no_info = not first_response or not has_valid_target(first_response)
        second_no_info = not second_response or not has_valid_target(second_response)
        
        if first_no_info and second_no_info:
            return "completed"
        
        # ê¸°ë³¸ê°’
        return "ollama"
    
    
    def _format_date_to_standard(self, date_str: str) -> Optional[str]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        import re
        
        if not date_str or date_str in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]:
            return None
        
        # ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_date = re.sub(r'[^\d\.\-/]', '', date_str.strip())
        
        # YYYY-MM-DD íŒ¨í„´ (ì´ë¯¸ í‘œì¤€ í˜•íƒœ)
        if re.match(r'^\d{4}-\d{2}-\d{2}$', clean_date):
            return clean_date
        
        # YYYY.MM.DD íŒ¨í„´
        match = re.match(r'^(\d{4})\.(\d{2})\.(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYYMMDD íŒ¨í„´
        match = re.match(r'^(\d{4})(\d{2})(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # YYYY/MM/DD íŒ¨í„´
        match = re.match(r'^(\d{4})/(\d{2})/(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        # ë” ë³µì¡í•œ íŒ¨í„´ë“¤ ì²˜ë¦¬
        # ì˜ˆ: 2024ë…„ 12ì›” 25ì¼
        year_month_day = re.search(r'(\d{4})ë…„?\s*(\d{1,2})ì›”?\s*(\d{1,2})ì¼?', date_str)
        if year_month_day:
            year = year_month_day.group(1)
            month = year_month_day.group(2).zfill(2)
            day = year_month_day.group(3).zfill(2)
            return f"{year}-{month}-{day}"
        
        # ìˆ«ìë§Œ 8ìë¦¬ì¸ ê²½ìš° (YYYYMMDD)
        numbers_only = re.sub(r'[^\d]', '', date_str)
        if len(numbers_only) == 8:
            return f"{numbers_only[:4]}-{numbers_only[4:6]}-{numbers_only[6:8]}"
        
        logger.debug(f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: '{date_str}' -> None")
        return None
    
    def _get_best_value_from_responses(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]], key: str) -> str:
        """first_responseì™€ second_response ì¤‘ì—ì„œ ìœ íš¨í•œ ê°’ì´ ìˆëŠ” ê²ƒì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        def is_valid_value(value):
            return value and value not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        # first_responseì—ì„œ ê°’ í™•ì¸ (ìš°ì„ ìˆœìœ„)
        if first_response and key in first_response:
            first_value = first_response.get(key, "")
            if is_valid_value(first_value):
                logger.debug(f"{key} ê°’ì„ first_responseì—ì„œ ì‚¬ìš©: {first_value}")
                return first_value
        
        # second_responseì—ì„œ ê°’ í™•ì¸
        if second_response and key in second_response:
            second_value = second_response.get(key, "")
            if is_valid_value(second_value):
                logger.debug(f"{key} ê°’ì„ second_responseì—ì„œ ì‚¬ìš©: {second_value}")
                return second_value
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return ""
    
    def _extract_title_from_content(self, content_md: str) -> str:
        """content.mdì—ì„œ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not content_md:
            return ""
        
        lines = content_md.split('\n')
        
        # ì²« ë²ˆì§¸ ë¹„ì–´ìˆì§€ ì•Šì€ ì¤„ì„ ì°¾ê¸°
        for line in lines[:10]:  # ìƒìœ„ 10ì¤„ë§Œ í™•ì¸
            line = line.strip()
            if line:
                # # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                if line.startswith('#'):
                    title = line.lstrip('#').strip()
                    logger.debug(f"ë§ˆí¬ë‹¤ìš´ í—¤ë”ì—ì„œ ì œëª© ì¶”ì¶œ: {title}")
                    return title
                
                # ì œëª©:, ê³µê³ ëª…: íŒ¨í„´ í™•ì¸
                for prefix in ['ì œëª©:', 'ê³µê³ ëª…:', 'ê³µê³  ì œëª©:', 'ì œëª© :']:
                    if line.lower().startswith(prefix.lower()):
                        title = line[len(prefix):].strip()
                        logger.debug(f"{prefix} íŒ¨í„´ì—ì„œ ì œëª© ì¶”ì¶œ: {title}")
                        return title
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì œëª©ìœ¼ë¡œ ì‚¬ìš© (ì²« ë²ˆì§¸ ì¤„)
                logger.debug(f"ì²« ë²ˆì§¸ ì¤„ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©: {line}")
                return line
        
        return ""
    
    def _extract_gov24_url_from_content(self, content_md: str) -> str:
        """content.mdì—ì„œ ì •ë¶€24 URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not content_md:
            return ""
        
        # ì •ë¶€24 URL íŒ¨í„´ ì°¾ê¸°
        gov24_patterns = [
            r'\*\*ì •ë¶€24 URL\*\*[:\s]*(.+?)(?:\n|$)',
            r'ì •ë¶€24 URL[:\s]*(.+?)(?:\n|$)',
            r'ì •ë¶€24[:\s]*(.+?)(?:\n|$)',
            r'(https?://(?:www\.)?gov\.kr[^\s\)]+)'
        ]
        
        for pattern in gov24_patterns:
            matches = re.findall(pattern, content_md, re.IGNORECASE)
            if matches:
                url = matches[0].strip()
                if url and url.startswith('http') and 'gov.kr' in url:
                    logger.debug(f"ì •ë¶€24 URL ì¶”ì¶œ ì„±ê³µ: {url[:50]}...")
                    return url
        
        logger.debug("content.mdì—ì„œ ì •ë¶€24 URLì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return ""
    
    def _extract_origin_url_from_content(self, content_md: str) -> str:
        """content.mdì—ì„œ ì›ë³¸ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not content_md:
            return ""
        
        # ì›ë³¸ URL íŒ¨í„´ ì°¾ê¸°
        origin_patterns = [
            r'\*\*ì›ë³¸ URL\*\*[:\s]*(.+?)(?:\n|$)',
            r'ì›ë³¸ URL[:\s]*(.+?)(?:\n|$)',
            r'ì›ë³¸[:\s]*(.+?)(?:\n|$)',
            r'(https?://[^\s\)]+(?:\.go\.kr|\.or\.kr)[^\s\)]*)'
        ]
        
        for pattern in origin_patterns:
            matches = re.findall(pattern, content_md, re.IGNORECASE)
            if matches:
                url = matches[0].strip()
                if url and url.startswith('http'):
                    logger.debug(f"ì›ë³¸ URL ì¶”ì¶œ ì„±ê³µ: {url[:50]}...")
                    return url
        
        logger.debug("content.mdì—ì„œ ì›ë³¸ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return ""
    
    def _extract_announcement_date_from_content(self, content_md: str) -> str:
        """content.mdì—ì„œ ê³µê³ ì¼ì„ ë¬¸ìì—´ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤ (ë‚ ì§œ í•„í„°ë§ìš©ê³¼ ë³„ê°œ)."""
        if not content_md:
            return ""
        
        # ì‘ì„±ì¼ íŒ¨í„´ ì°¾ê¸° (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
        date_patterns = [
            r'\*\*ì‘ì„±ì¼\*\*[:\s]*(.+?)(?:\n|$)',
            r'ì‘ì„±ì¼[:\s]*(.+?)(?:\n|$)',
            r'\*\*ë“±ë¡ì¼\*\*[:\s]*(.+?)(?:\n|$)',
            r'ë“±ë¡ì¼[:\s]*(.+?)(?:\n|$)',
            r'\*\*ê³µê³ ì¼\*\*[:\s]*(.+?)(?:\n|$)',
            r'ê³µê³ ì¼[:\s]*(.+?)(?:\n|$)'
        ]
        
        for pattern in date_patterns:
            matches = re.findall(pattern, content_md, re.IGNORECASE)
            if matches:
                date_str = matches[0].strip()
                if date_str:
                    logger.debug(f"ê³µê³ ì¼ ì¶”ì¶œ ì„±ê³µ: {date_str}")
                    return date_str
        
        logger.debug("content.mdì—ì„œ ê³µê³ ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return ""
    
    def _normalize_korean_text(self, text: str) -> str:
        """í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ NFC(Composed) í˜•íƒœë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
        
        macOSëŠ” NFD(Decomposed) í˜•íƒœë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì´ ììŒê³¼ ëª¨ìŒìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ì €ì¥ë˜ì§€ë§Œ,
        ìœˆë„ìš°ì—ì„œëŠ” NFC(Composed) í˜•íƒœë¡œ í‘œì‹œí•´ì•¼ í•œê¸€ì´ ì˜¬ë°”ë¥´ê²Œ ë³´ì…ë‹ˆë‹¤.
        """
        return unicodedata.normalize('NFC', text)
    
    def _natural_sort_key(self, path: Path) -> tuple:
        """í´ë”ëª…ì˜ ìˆ«ì ë¶€ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ìì—° ì •ë ¬ì„ ìœ„í•œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        import re
        
        folder_name = path.name
        # ìˆ«ì_ì œëª© íŒ¨í„´ì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
        match = re.match(r'^(\d+)_(.*)$', folder_name)
        if match:
            number = int(match.group(1))
            title = match.group(2)
            return (number, title)
        else:
            # ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ë§¨ ë’¤ë¡œ
            return (float('inf'), folder_name)
    
    def _process_attachments_separately(self, directory_path: Path, attach_force: bool = False) -> tuple[str, List[str], List[Dict[str, Any]]]:
        """ì²¨ë¶€íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ë‚´ìš©ì„ ê²°í•©í•˜ê³  íŒŒì¼ëª… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return "", [], []
        
        combined_content = ""
        attachment_filenames = []
        attachment_files_info = []
        
        # ì²˜ë¦¬ ê°€ëŠ¥í•œ í™•ì¥ì ì •ì˜
        supported_extensions = {'.pdf', '.hwp', '.hwpx', '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.pptx', '.docx', '.xlsx', '.md'}
        
        target_keywords = ['ì–‘ì‹', 'ì„œë¥˜', 'ì‹ ì²­ì„œ', 'ë™ì˜ì„œ']

        for file_path in attachments_dir.iterdir():
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                filename = file_path.stem
                

                logger.info(f"filename===={filename}")
                lowercase_filename = filename.lower()
                
                if any(keyword in lowercase_filename for keyword in target_keywords):                
                    logger.info(f"ì–‘ì‹, ì‹ ì²­ì„œ ë“±ì€ SKIP===={filename}")
                    continue; 

                # í™•ì¥ìê°€ ì—†ê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                if not file_extension or file_extension not in supported_extensions:
                    logger.debug(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ê±´ë„ˆëœ€: {file_path.name}")
                    continue
                
                attachment_filenames.append(self._normalize_korean_text(file_path.name))  # ì „ì²´ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
                logger.debug(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")
                
                # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                file_info = {
                    "filename": file_path.stem,
                    "file_extension": file_extension,
                    "file_path": str(file_path),
                    "file_size": file_path.stat().st_size if file_path.exists() else 0,
                    "conversion_success": False,  # ì´ˆê¸°ê°’, ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
                    "conversion_method": self._guess_conversion_method(file_extension)
                }
                attachment_files_info.append(file_info)
                
                # ì´ë¯¸ .md íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ì½ê¸°
                if file_extension == '.md':
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            combined_content += f"\n\n=== {self._normalize_korean_text(file_path.name)} ===\n{content}"
                            logger.debug(f"ì²¨ë¶€íŒŒì¼ .md ì§ì ‘ ì½ê¸° ì„±ê³µ: {file_path.name} ({len(content)} ë¬¸ì)")
                            file_info["conversion_success"] = True
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ .md ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {file_path.name}")
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ .md ì§ì ‘ ì½ê¸° ì‹¤íŒ¨: {e}")
                    continue  # .md íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ, ë‹¤ìŒ íŒŒì¼ë¡œ
                
                # ì²¨ë¶€íŒŒì¼ëª….md íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ë‹¤ë¥¸ í™•ì¥ì íŒŒì¼ë“¤ì„ ìœ„í•œ)
                md_file_path = attachments_dir / f"{filename}.md"
                
                # attach_forceê°€ Trueì´ë©´ ê¸°ì¡´ .md íŒŒì¼ì„ ë¬´ì‹œí•˜ê³  ì›ë³¸ì—ì„œ ì¬ë³€í™˜
                if not attach_force and md_file_path.exists():
                    # .md íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì½ìŒ
                    try:
                        with open(md_file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            combined_content += f"\n\n=== {self._normalize_korean_text(filename)}.md ===\n{content}"
                            logger.debug(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì„±ê³µ: {filename}.md ({len(content)} ë¬¸ì)")
                            file_info["conversion_success"] = True
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ .md ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {filename}.md")
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì‹¤íŒ¨: {e}")
                else:
                    # .md íŒŒì¼ì´ ì—†ê±°ë‚˜ attach_forceê°€ Trueì´ë©´ ì›ë³¸ íŒŒì¼ì„ ë³€í™˜
                    if attach_force and md_file_path.exists():
                        logger.info(f"--attach-force: ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì¬ë³€í™˜: {file_path.name}")
                    else:
                        logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹œì‘: {file_path.name}")
                        
                    try:
                        content = self.attachment_processor.process_single_file(file_path)
                        
                        if content and content.strip():
                            combined_content += f"\n\n=== {self._normalize_korean_text(file_path.name)} ===\n{content}"
                            logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì„±ê³µ: {file_path.name} ({len(content)} ë¬¸ì)")
                            file_info["conversion_success"] = True
                            
                            # ë³€í™˜ëœ ë‚´ìš©ì„ .md íŒŒì¼ë¡œ ì €ì¥
                            try:
                                with open(md_file_path, 'w', encoding='utf-8') as f:
                                    f.write(content)
                                logger.debug(f"ë³€í™˜ëœ ë‚´ìš©ì„ .mdë¡œ ì €ì¥: {md_file_path}")
                            except Exception as save_e:
                                logger.warning(f".md íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_e}")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ì—ì„œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {file_path.name}")
                        
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ ({file_path}): {e}")
        
        logger.info(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(attachment_filenames)}ê°œ íŒŒì¼, {len(combined_content)} ë¬¸ì")
        return combined_content.strip(), attachment_filenames, attachment_files_info
    
    def _save_processing_result(
        self, 
        folder_name: str, 
        site_code: str, 
        content_md: str, 
        combined_content: str,
        attachment_filenames: List[str] = None,
        status: str = "ollama",
        exclusion_keywords: List[str] = None,
        exclusion_reason: str = None,
        error_message: str = None,
        force: bool = False,
        title: str = None,
        gov24_url: str = None,
        origin_url: str = None,
        announcement_date: str = None,
        attachment_files_info: List[Dict[str, Any]] = None
    ) -> Optional[int]:
        """ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.db_manager.SessionLocal() as session:
                if force:
                    # UPSERT ë¡œì§
                    sql = text("""
                        INSERT INTO announcement_prv_file (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, attachment_files_list, exclusion_keyword, exclusion_reason, 
                            title, origin_url, gov24_url, announcement_date,
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :attachment_files_list, :exclusion_keyword, :exclusion_reason, 
                            :title, :origin_url, :gov24_url, :announcement_date,
                            :processing_status, :error_message, NOW(), NOW()
                        )
                        ON DUPLICATE KEY UPDATE
                            content_md = VALUES(content_md),
                            combined_content = VALUES(combined_content),
                            attachment_filenames = VALUES(attachment_filenames),
                            attachment_files_list = VALUES(attachment_files_list),
                            exclusion_keyword = VALUES(exclusion_keyword),
                            exclusion_reason = VALUES(exclusion_reason),
                            processing_status = VALUES(processing_status),
                            title = VALUES(title),
                            origin_url = VALUES(origin_url),
                            gov24_url = VALUES(gov24_url),
                            announcement_date = VALUES(announcement_date),
                            error_message = VALUES(error_message),
                            updated_at = NOW()
                    """)
                else:
                    # ì¼ë°˜ INSERT
                    sql = text("""
                        INSERT INTO announcement_prv_file (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, attachment_files_list, exclusion_keyword, exclusion_reason, 
                            title, origin_url, gov24_url, announcement_date,
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :attachment_files_list, :exclusion_keyword, :exclusion_reason, 
                            :title, :origin_url, :gov24_url, :announcement_date,
                            :processing_status, :error_message, NOW(), NOW()
                        )
                    """)
                
                # JSONìœ¼ë¡œ ì§ë ¬í™”
                attachment_files_json = json.dumps(attachment_files_info, ensure_ascii=False) if attachment_files_info else None
                
                params = {
                    'folder_name': folder_name,
                    'site_code': site_code,
                    'content_md': content_md,
                    'combined_content': combined_content,
                    'attachment_filenames': ', '.join(attachment_filenames) if attachment_filenames else None,
                    'attachment_files_list': attachment_files_json,
                    'exclusion_keyword': ', '.join(exclusion_keywords) if exclusion_keywords else None,
                    'exclusion_reason': exclusion_reason,
                    'title': title,
                    'origin_url': origin_url,
                    'gov24_url': gov24_url,
                    'announcement_date': announcement_date,
                    'processing_status': status,
                    'error_message': error_message
                }
                
                result = session.execute(sql, params)
                session.commit()
                
                record_id = result.lastrowid
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                return record_id
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    



    def _update_attachment_info(self, record_id: int, combined_content: str, attachment_filenames: List[str]) -> bool:
        """ì²¨ë¶€íŒŒì¼ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            with self.db_manager.SessionLocal() as session:
                from sqlalchemy import text
                
                # ì²¨ë¶€íŒŒì¼ ì •ë³´ë§Œ ì—…ë°ì´íŠ¸
                sql = text("""
                    UPDATE announcement_prv_processing 
                    SET combined_content = :combined_content,
                        attachment_filenames = :attachment_filenames,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                filenames_str = json.dumps(attachment_filenames, ensure_ascii=False) if attachment_filenames else ""
                
                session.execute(sql, {
                    'record_id': record_id,
                    'combined_content': combined_content,
                    'attachment_filenames': filenames_str
                })
                session.commit()
                
                logger.info(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}")
                return True
                
        except Exception as e:
            logger.error(f"ì²¨ë¶€íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    


def get_base_directory(args) -> Path:
    """ëª…ë ¹í–‰ ì¸ì ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ë””ë ‰í† ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    # ë””ë ‰í† ë¦¬ ê²°ì •
    if args.data:
        directory_name = args.data
    else:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        directory_name = os.getenv("DEFAULT_DIR", "data")
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ìƒì„±
    current_dir = Path.cwd()
    base_directory = current_dir / directory_name
    
    if not base_directory.exists():
        logger.error(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_directory}")
        sys.exit(1)
    
    logger.info(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬: {base_directory}")
    
    return base_directory


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ê³µê³  ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ë° ë¶„ì„ í”„ë¡œê·¸ë¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python announcement_prv_file.py --data prv7
  python announcement_prv_file.py --data prv8
  python announcement_prv_file.py --data prv7 --date 20250710  # 2025-07-10 ì´ì „ ê³µê³ ë§Œ ì²˜ë¦¬
  python announcement_prv_file.py --data prv8 -r --date 20250801  # ì¬ê·€ì ìœ¼ë¡œ 8ì›” 1ì¼ ì´ì „ ê³µê³ ë§Œ ì²˜ë¦¬
  python announcement_prv_file.py --data prv7 --flat  # í‰íƒ„í™”ëœ êµ¬ì¡° ì²˜ë¦¬ (ì§€ì—­_ì‹œêµ°_ê³µê³  í˜•íƒœ)
  python announcement_prv_file.py --data prv8 --flat --date 20250715  # í‰íƒ„í™” êµ¬ì¡°ì—ì„œ ë‚ ì§œ í•„í„°ë§
  python announcement_prv_file.py --data prv7 --attach-force  # ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬
        """
    )
    
    parser.add_argument(
        "--data", 
        type=str,
        help="ë°ì´í„° ë””ë ‰í† ë¦¬ëª… (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ë˜ëŠ” 'data')"
    )
    
    
    parser.add_argument(
        "--skip-processed", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© ê±´ë„ˆë›°ê¸° (ê¸°ë³¸ ë™ì‘)"
    )
    
    parser.add_argument(
        "--force", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬"
    )
    
    parser.add_argument(
        "-r", "--recursive",
        action="store_true",
        help="í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ëª¨ë“  í•˜ìœ„ ê²½ë¡œì˜ content.mdë‚˜ attachmentsë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬)"
    )
    
    parser.add_argument(
        "--attach-force",
        action="store_true",
        help="ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ (ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì›ë³¸ íŒŒì¼ì—ì„œ ë‹¤ì‹œ ë³€í™˜)"
    )
    
    parser.add_argument(
        "--date",
        type=str,
        help="ë‚ ì§œ í•„í„°ë§ (YYYYMMDD í˜•ì‹, í•´ë‹¹ ë‚ ì§œ ì´ì „ ê³µê³ ë§Œ ì²˜ë¦¬)"
    )
    
    parser.add_argument(
        "--flat",
        action="store_true",
        help="í‰íƒ„í™”ëœ êµ¬ì¡° ì²˜ë¦¬ (2depth êµ¬ì¡° ì—†ì´ ë°”ë¡œ ê³µê³  í´ë”ë“¤ ì²˜ë¦¬)"
    )
    
    args = parser.parse_args()
    
    try:
        # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²°ì •
        base_directory = get_base_directory(args)
        
        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        logger.info("ë‹¤ì¤‘ ì‚¬ì´íŠ¸ ê³µê³  ì²˜ë¦¬ í”„ë¡œê·¸ë¨ ì‹œì‘")
        processor = AnnouncementPrvProcessor(attach_force=args.attach_force, date_filter=args.date)
        
        # ëª¨ë“  ì‚¬ì´íŠ¸ ì²˜ë¦¬ ì‹¤í–‰
        results = processor.process_all_sites(base_directory, args.recursive, args.force, args.attach_force, args.flat)
        
        # ê²°ê³¼ ì¶œë ¥ (process_site_directoriesì—ì„œ ì´ë¯¸ ìƒì„¸ ì¶œë ¥ë¨)
        print(f"\n=== ìµœì¢… ìš”ì•½ ===")
        print(f"ì „ì²´ ëŒ€ìƒ: {results['total']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {results['success']}ê°œ") 
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {results['failed']}ê°œ")
        print(f"ê±´ë„ˆë›´ í•­ëª©: {results['skipped']}ê°œ")
        
        if results['failed'] > 0:
            print(f"\nì‹¤íŒ¨í•œ í•­ëª©ì´ {results['failed']}ê°œ ìˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
        else:
            print("\nëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            sys.exit(0)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()