#!/usr/bin/env python3
import os
import sys
import subprocess
import time
import pymysql
from dotenv import load_dotenv
from datetime import datetime
from pathlib import Path
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import json
import argparse

load_dotenv()

DB_HOST = os.getenv("DB_HOST")
DB_PORT = int(os.getenv("DB_PORT", 3306))
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# Ïù¥Î©îÏùº ÏÑ§Ï†ï
SMTP_HOST = os.getenv("SMTP_HOST", "smtp.gmail.com")
SMTP_PORT = int(os.getenv("SMTP_PORT", 587))
SMTP_USER = os.getenv("SMTP_USER")
SMTP_PASSWORD = os.getenv("SMTP_PASSWORD")
ALERT_RECIPIENTS = os.getenv("ALERT_RECIPIENTS", "").split(",")
ALERT_SENDER_NAME = os.getenv("ALERT_SENDER_NAME", "Scraper Alert System")
ALERT_ENABLED = os.getenv("ALERT_ENABLED", "true").lower() == "true"

NODE_DIR = Path(__file__).parent / "node"
SCRAPER_DIR = NODE_DIR / "scraper"
BASE_OUTPUT_DIR = Path(__file__).parent / "scraped_incremental_v2"


def get_db_connection():
    return pymysql.connect(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME,
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )


def save_scraper_log(
    site_code,
    status,
    elapsed_time=0,
    error_message=None,
    scraper_file=None,
    from_date=None,
    output_dir=None,
    scraped_count=0,
):
    """Ïä§ÌÅ¨ÎûòÌçº Ïã§Ìñâ Î°úÍ∑∏Î•º DBÏóê Ï†ÄÏû•"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # ÌÖåÏù¥Î∏îÏù¥ ÏóÜÏúºÎ©¥ ÏÉùÏÑ±
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS scraper_execution_log (
                    id INT PRIMARY KEY AUTO_INCREMENT,
                    site_code VARCHAR(50) NOT NULL,
                    execution_date DATE NOT NULL,
                    status VARCHAR(20) NOT NULL,
                    error_message TEXT,
                    elapsed_time FLOAT,
                    scraper_file VARCHAR(255),
                    from_date DATE,
                    to_date DATE,
                    output_dir VARCHAR(500),
                    scraped_count INT DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    INDEX idx_site_code (site_code),
                    INDEX idx_execution_date (execution_date),
                    INDEX idx_status (status)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """
            )

            # Î°úÍ∑∏ Ï†ÄÏû•
            cursor.execute(
                """
                INSERT INTO scraper_execution_log 
                (site_code, execution_date, status, error_message, elapsed_time, 
                 scraper_file, from_date, to_date, output_dir, scraped_count)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """,
                (
                    site_code,
                    datetime.now().date(),
                    status,
                    error_message,
                    elapsed_time,
                    scraper_file,
                    from_date,
                    datetime.now().date(),
                    output_dir,
                    scraped_count,
                ),
            )

            log_id = cursor.lastrowid
            conn.commit()
            return log_id
    except Exception as e:
        print(f"Î°úÍ∑∏ Ï†ÄÏû• Ïã§Ìå®: {e}")
        return None
    finally:
        conn.close()


def save_alert_history(log_id, site_code, alert_type, alert_message, recipients):
    """ÏïåÎ¶º Î∞úÏÜ° Í∏∞Î°ùÏùÑ DBÏóê Ï†ÄÏû•"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # ÌÖåÏù¥Î∏îÏù¥ ÏóÜÏúºÎ©¥ ÏÉùÏÑ±
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS scraper_alert_history (
                    id INT PRIMARY KEY AUTO_INCREMENT,
                    log_id INT,
                    site_code VARCHAR(50) NOT NULL,
                    alert_type VARCHAR(20) NOT NULL,
                    alert_message TEXT,
                    recipients TEXT,
                    sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    INDEX idx_site_code (site_code),
                    INDEX idx_alert_type (alert_type)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """
            )

            cursor.execute(
                """
                INSERT INTO scraper_alert_history 
                (log_id, site_code, alert_type, alert_message, recipients)
                VALUES (%s, %s, %s, %s, %s)
            """,
                (log_id, site_code, alert_type, alert_message, json.dumps(recipients)),
            )
            conn.commit()
    except Exception as e:
        print(f"ÏïåÎ¶º Í∏∞Î°ù Ï†ÄÏû• Ïã§Ìå®: {e}")
    finally:
        conn.close()


def send_summary_email(results, total_elapsed):
    """Ïã§Ìñâ ÏôÑÎ£å ÌõÑ Î¨∏Ï†úÍ∞Ä ÏûàÏóàÎçò ÏÇ¨Ïù¥Ìä∏Îì§Ïóê ÎåÄÌïú Ï¢ÖÌï© Î≥¥Í≥†ÏÑú Ïù¥Î©îÏùº Î∞úÏÜ°"""
    if not ALERT_ENABLED or not SMTP_USER or not SMTP_PASSWORD:
        return False

    if not ALERT_RECIPIENTS or ALERT_RECIPIENTS == [""]:
        return False

    try:
        # Î¨∏Ï†úÍ∞Ä ÏûàÏóàÎçò ÏÇ¨Ïù¥Ìä∏Îì§ Ï†ïÎ¶¨
        problems = []

        for item in results.get("timeout", []):
            problems.append(
                {
                    "site": item["site_code"],
                    "status": "TIMEOUT",
                    "error": item.get("error", "15Î∂Ñ ÌÉÄÏûÑÏïÑÏõÉ Ï¥àÍ≥º"),
                    "time": item.get("elapsed_time", 0),
                }
            )

        for item in results.get("error", []):
            problems.append(
                {
                    "site": item["site_code"],
                    "status": "ERROR",
                    "error": item.get("error", "Ïïå Ïàò ÏóÜÎäî Ïò§Î•ò"),
                    "time": item.get("elapsed_time", 0),
                }
            )

        for item in results.get("failed", []):
            problems.append(
                {
                    "site": item["site_code"],
                    "status": "FAILED",
                    "error": item.get("error", "Ïã§Ìñâ Ïã§Ìå®"),
                    "time": item.get("elapsed_time", 0),
                }
            )

        if not problems:
            return False

        # HTML ÌÖåÏù¥Î∏î ÏÉùÏÑ±
        problem_rows = ""
        for p in problems:
            problem_rows += f"""
            <tr>
                <td>{p['site']}</td>
                <td style="color: {'red' if p['status'] == 'TIMEOUT' else 'orange'};">{p['status']}</td>
                <td>{p['error'][:100]}...</td>
                <td>{p['time']:.1f}Ï¥à</td>
            </tr>
            """

        subject = f"[Ïä§ÌÅ¨ÎûòÌçº ÏùºÏùº Î≥¥Í≥†ÏÑú] {datetime.now().strftime('%Y-%m-%d')} - Î¨∏Ï†ú Î∞úÏÉù {len(problems)}Í±¥"

        html_body = f"""
        <html>
            <head>
                <style>
                    body {{ font-family: Arial, sans-serif; }}
                    .summary-box {{
                        background-color: #f0f0f0;
                        padding: 15px;
                        margin: 10px 0;
                        border-radius: 5px;
                    }}
                    .problem-table {{
                        border-collapse: collapse;
                        width: 100%;
                        margin-top: 20px;
                    }}
                    .problem-table th {{
                        background-color: #333;
                        color: white;
                        padding: 10px;
                        text-align: left;
                    }}
                    .problem-table td {{
                        padding: 8px;
                        border-bottom: 1px solid #ddd;
                    }}
                    .stats-grid {{
                        display: grid;
                        grid-template-columns: repeat(3, 1fr);
                        gap: 10px;
                        margin: 20px 0;
                    }}
                    .stat-card {{
                        background: white;
                        border: 1px solid #ddd;
                        padding: 10px;
                        text-align: center;
                        border-radius: 5px;
                    }}
                    .stat-number {{
                        font-size: 24px;
                        font-weight: bold;
                        color: #333;
                    }}
                    .stat-label {{
                        color: #666;
                        font-size: 12px;
                        margin-top: 5px;
                    }}
                </style>
            </head>
            <body>
                <h2>üìä Ïä§ÌÅ¨ÎûòÌçº ÏùºÏùº Ïã§Ìñâ Î≥¥Í≥†ÏÑú</h2>
                
                <div class="summary-box">
                    <h3>Ïã§Ìñâ ÏöîÏïΩ</h3>
                    <div class="stats-grid">
                        <div class="stat-card">
                            <div class="stat-number">{len(results.get('success', []))}</div>
                            <div class="stat-label">ÏÑ±Í≥µ</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number" style="color: orange;">{len(results.get('failed', []))}</div>
                            <div class="stat-label">Ïã§Ìå®</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number" style="color: red;">{len(results.get('timeout', []))}</div>
                            <div class="stat-label">ÌÉÄÏûÑÏïÑÏõÉ</div>
                        </div>
                    </div>
                    <p>
                        <strong>Ïã§Ìñâ ÏãúÍ∞Ñ:</strong> {total_elapsed:.1f}Ï¥à ({total_elapsed/60:.1f}Î∂Ñ)<br>
                        <strong>ÏôÑÎ£å ÏãúÍ∞Å:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                    </p>
                </div>
                
                <h3>‚ö†Ô∏è Î¨∏Ï†ú Î∞úÏÉù ÏÇ¨Ïù¥Ìä∏ ({len(problems)}Í±¥)</h3>
                <table class="problem-table">
                    <thead>
                        <tr>
                            <th>ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú</th>
                            <th>ÏÉÅÌÉú</th>
                            <th>Ïò§Î•ò Î©îÏãúÏßÄ</th>
                            <th>Ïã§Ìñâ ÏãúÍ∞Ñ</th>
                        </tr>
                    </thead>
                    <tbody>
                        {problem_rows}
                    </tbody>
                </table>
                
                <p style="margin-top: 30px; color: #666; font-size: 12px;">
                    Ïù¥ Î©îÏùºÏùÄ ÏûêÎèôÏúºÎ°ú Î∞úÏÜ°ÎêòÏóàÏäµÎãàÎã§. Î¨∏ÏùòÏÇ¨Ìï≠ÏùÄ ÏãúÏä§ÌÖú Í¥ÄÎ¶¨ÏûêÏóêÍ≤å Ïó∞ÎùΩÏ£ºÏÑ∏Ïöî.
                </p>
            </body>
        </html>
        """

        # Ïù¥Î©îÏùº Í∞ùÏ≤¥ ÏÉùÏÑ±
        msg = MIMEMultipart("alternative")
        msg["Subject"] = subject
        msg["From"] = f"{ALERT_SENDER_NAME} <{SMTP_USER}>"
        msg["To"] = ", ".join(
            [email.strip() for email in ALERT_RECIPIENTS if email.strip()]
        )

        # HTML ÌååÌä∏ Ï∂îÍ∞Ä
        html_part = MIMEText(html_body, "html")
        msg.attach(html_part)

        # SMTP ÏÑúÎ≤Ñ Ïó∞Í≤∞ Î∞è Î∞úÏÜ°
        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:
            server.starttls()
            server.login(SMTP_USER, SMTP_PASSWORD)
            server.send_message(msg)

        print(f"\nüìß ÏùºÏùº Ï¢ÖÌï© Î≥¥Í≥†ÏÑú Î∞úÏÜ° ÏôÑÎ£å: {', '.join(ALERT_RECIPIENTS)}")
        return True

    except Exception as e:
        print(f"\n‚ùå Ï¢ÖÌï© Î≥¥Í≥†ÏÑú Î∞úÏÜ° Ïã§Ìå®: {e}")
        return False


def send_alert_email(site_code, status, error_message, elapsed_time, from_date):
    """ÌÉÄÏûÑÏïÑÏõÉ ÎòêÎäî Ïò§Î•ò Î∞úÏÉùÏãú Ïù¥Î©îÏùº ÏïåÎ¶º Î∞úÏÜ°"""
    if not ALERT_ENABLED or not SMTP_USER or not SMTP_PASSWORD:
        print("Ïù¥Î©îÏùº ÏïåÎ¶ºÏù¥ ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ ÏûàÍ±∞ÎÇò ÏÑ§Ï†ïÏù¥ ÏóÜÏäµÎãàÎã§.")
        return False

    if not ALERT_RECIPIENTS or ALERT_RECIPIENTS == [""]:
        print("ÏàòÏã†Ïûê Ïù¥Î©îÏùºÏù¥ ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
        return False

    try:
        # Ïù¥Î©îÏùº ÎÇ¥Ïö© Íµ¨ÏÑ±
        subject = f"[Ïä§ÌÅ¨ÎûòÌçº ÏïåÎ¶º] {site_code} - {status}"

        html_body = f"""
        <html>
            <head>
                <style>
                    body {{ font-family: Arial, sans-serif; }}
                    .alert-box {{ 
                        border: 2px solid #ff0000;
                        padding: 15px;
                        margin: 10px 0;
                        background-color: #fff5f5;
                    }}
                    .info-table {{
                        border-collapse: collapse;
                        width: 100%;
                        margin-top: 10px;
                    }}
                    .info-table td {{
                        padding: 8px;
                        border: 1px solid #ddd;
                    }}
                    .info-table td:first-child {{
                        font-weight: bold;
                        background-color: #f2f2f2;
                        width: 30%;
                    }}
                </style>
            </head>
            <body>
                <h2>Ïä§ÌÅ¨ÎûòÌçº Ïã§Ìñâ ÏïåÎ¶º</h2>
                <div class="alert-box">
                    <h3>‚ö†Ô∏è {status.upper()} Î∞úÏÉù</h3>
                    <table class="info-table">
                        <tr>
                            <td>ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú</td>
                            <td>{site_code}</td>
                        </tr>
                        <tr>
                            <td>ÏÉÅÌÉú</td>
                            <td>{status}</td>
                        </tr>
                        <tr>
                            <td>ÏãúÏûë ÎÇ†Ïßú</td>
                            <td>{from_date}</td>
                        </tr>
                        <tr>
                            <td>Ïã§Ìñâ ÏãúÍ∞Ñ</td>
                            <td>{elapsed_time:.1f}Ï¥à</td>
                        </tr>
                        <tr>
                            <td>Ïò§Î•ò Î©îÏãúÏßÄ</td>
                            <td><pre>{error_message or 'N/A'}</pre></td>
                        </tr>
                        <tr>
                            <td>Î∞úÏÉù ÏãúÍ∞Å</td>
                            <td>{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</td>
                        </tr>
                    </table>
                </div>
                <p>Ïù¥ Î©îÏùºÏùÄ ÏûêÎèôÏúºÎ°ú Î∞úÏÜ°ÎêòÏóàÏäµÎãàÎã§.</p>
            </body>
        </html>
        """

        # Ïù¥Î©îÏùº Í∞ùÏ≤¥ ÏÉùÏÑ±
        msg = MIMEMultipart("alternative")
        msg["Subject"] = subject
        msg["From"] = f"{ALERT_SENDER_NAME} <{SMTP_USER}>"
        msg["To"] = ", ".join(
            [email.strip() for email in ALERT_RECIPIENTS if email.strip()]
        )

        # HTML ÌååÌä∏ Ï∂îÍ∞Ä
        html_part = MIMEText(html_body, "html")
        msg.attach(html_part)

        # SMTP ÏÑúÎ≤Ñ Ïó∞Í≤∞ Î∞è Î∞úÏÜ°
        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:
            server.starttls()
            server.login(SMTP_USER, SMTP_PASSWORD)
            server.send_message(msg)

        print(f"  üìß ÏïåÎ¶º Ïù¥Î©îÏùº Î∞úÏÜ° ÏôÑÎ£å: {', '.join(ALERT_RECIPIENTS)}")
        return True

    except Exception as e:
        print(f"  ‚ùå Ïù¥Î©îÏùº Î∞úÏÜ° Ïã§Ìå®: {e}")
        return False


def get_sites_to_scrape(site_code=None):
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            if site_code:
                # ÌäπÏ†ï ÏÇ¨Ïù¥Ìä∏Îßå Ï°∞Ìöå
                cursor.execute(
                    """
                    SELECT 
                        site_code,
                        latest_announcement_date
                    FROM homepage_site_announcement_date
                    WHERE site_code = %s
                    """,
                    (site_code,)
                )
            else:
                # Î™®Îì† ÏÇ¨Ïù¥Ìä∏ Ï°∞Ìöå
                cursor.execute(
                    """
                    SELECT 
                        site_code,
                        latest_announcement_date
                    FROM homepage_site_announcement_date
                    ORDER BY site_code
                    """
                )
            return cursor.fetchall()
    finally:
        conn.close()


def get_latest_date_from_scraped_files(site_code, output_dir):
    """Ïä§ÌÅ¨ÎûòÌïëÎêú ÌååÏùºÏóêÏÑú ÏµúÏã† ÎÇ†ÏßúÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§."""
    from pathlib import Path
    import re

    output_path = Path(output_dir)
    if not output_path.exists():
        return None

    # 001_Î°ú ÏãúÏûëÌïòÎäî Ï≤´ Î≤àÏß∏ Ìè¥Îçî Ï∞æÍ∏∞
    first_dir = None
    for item_dir in sorted(output_path.iterdir()):
        if item_dir.is_dir() and item_dir.name.startswith("001_"):
            first_dir = item_dir
            break

    if not first_dir:
        # 001_Î°ú ÏãúÏûëÌïòÎäî Ìè¥ÎçîÍ∞Ä ÏóÜÏúºÎ©¥ Ï≤´ Î≤àÏß∏ ÎîîÎ†âÌÜ†Î¶¨ ÏÇ¨Ïö©
        dirs = [d for d in output_path.iterdir() if d.is_dir()]
        if dirs:
            first_dir = sorted(dirs)[0]
        else:
            return None

    # content.md ÌååÏùº ÏùΩÍ∏∞
    content_md_path = first_dir / "content.md"
    if not content_md_path.exists():
        print(f"  ‚ö†Ô∏è content.md ÌååÏùº ÏóÜÏùå: {first_dir.name}")
        return None

    try:
        with open(content_md_path, "r", encoding="utf-8") as f:
            content = f.read()

        # ÎÇ†Ïßú Ï∂îÏ∂ú Ìå®ÌÑ¥ (Ïö∞ÏÑ†ÏàúÏúÑ ÏàúÏÑú)
        date_patterns = [
            r"\*\*ÏûëÏÑ±Ïùº\*\*[:\s]*(.+?)(?:\n|$)",
            r"\*\*Îì±Î°ùÏùº\*\*[:\s]*(.+?)(?:\n|$)",
            r"\*\*Í≥µÍ≥†Ïùº\*\*[:\s]*(.+?)(?:\n|$)",
            r"ÏûëÏÑ±Ïùº[:\s]*(.+?)(?:\n|$)",
            r"Îì±Î°ùÏùº[:\s]*(.+?)(?:\n|$)",
            r"Í≥µÍ≥†Ïùº[:\s]*(.+?)(?:\n|$)",
            r"ÎÇ†Ïßú\s*[:\s]*(.+?)(?:\n|$)",  # ÎÇ†Ïßú: ÌòïÏãù Ï∂îÍ∞Ä
            r"^\d{4}[-.ÎÖÑ]\d{1,2}[-.Ïõî]\d{1,2}[Ïùº]?$",  # ÎÇ†ÏßúÎßå ÏûàÎäî ÎùºÏù∏
        ]

        announcement_date = None
        for pattern in date_patterns:
            date_match = re.search(pattern, content, re.IGNORECASE | re.MULTILINE)
            if date_match:
                # Ìå®ÌÑ¥Ïóê Í∑∏Î£πÏù¥ ÏûàÎäî Í≤ΩÏö∞
                if date_match.groups():
                    announcement_date = date_match.group(1).strip()
                else:
                    announcement_date = date_match.group(0).strip()
                break

        if announcement_date:
            print(
                f"  üìÑ ÌååÏùºÏóêÏÑú Ï∂îÏ∂úÌïú ÏµúÏã† ÎÇ†Ïßú: {announcement_date} (from {first_dir.name})"
            )
            return announcement_date
        else:
            print(f"  ‚ö†Ô∏è ÎÇ†Ïßú Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏùå: {first_dir.name}")
            return None

    except Exception as e:
        print(f"  ‚ùå ÌååÏùº ÏùΩÍ∏∞ Ïò§Î•ò: {e}")
        return None


def update_latest_announcement_date(site_code, output_dir=None):
    """Ïä§ÌÅ¨ÎûòÌïë ÏôÑÎ£å ÌõÑ Ìï¥Îãπ ÏÇ¨Ïù¥Ìä∏Ïùò ÏµúÏã† Í≥µÍ≥† ÎÇ†ÏßúÎ•º ÏóÖÎç∞Ïù¥Ìä∏Ìï©ÎãàÎã§."""

    # Ïä§ÌÅ¨ÎûòÌïëÎêú ÌååÏùºÏóêÏÑú ÏµúÏã† ÎÇ†Ïßú Í∞ÄÏ†∏Ïò§Í∏∞
    latest_date_str = None
    if output_dir:
        latest_date_str = get_latest_date_from_scraped_files(site_code, output_dir)

    if not latest_date_str:
        print(f"  ‚ö†Ô∏è ÎÇ†Ïßú Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏñ¥ DB ÏóÖÎç∞Ïù¥Ìä∏ Ïä§ÌÇµ")
        return False

    # ÎÇ†Ïßú ÌòïÏãù Î≥ÄÌôò (YYYY-MM-DD ÌòïÏãùÏúºÎ°ú)
    from datetime import datetime
    import re

    try:
        # Îã§ÏñëÌïú ÎÇ†Ïßú ÌòïÏãù Ï≤òÎ¶¨
        date_obj = None

        # HH:MM:SS ÌòïÏãù (ÏãúÍ∞ÑÎßå ÏûàÎäî Í≤ΩÏö∞ - Ïò§Îäò ÎÇ†ÏßúÎ°ú Ï≤òÎ¶¨)
        if re.match(r"^\d{1,2}:\d{2}:\d{2}$", latest_date_str):
            print(f"  ‚ö†Ô∏è ÏãúÍ∞ÑÎßå ÏûàÏùå ({latest_date_str}), Ïò§Îäò ÎÇ†ÏßúÎ°ú ÏÑ§Ï†ï")
            date_obj = datetime.now()
        # YYYY-MM-DD ÌòïÏãù
        elif re.match(r"^\d{4}-\d{2}-\d{2}$", latest_date_str):
            date_obj = datetime.strptime(latest_date_str, "%Y-%m-%d")
        # YYYY.MM.DD ÌòïÏãù
        elif re.match(r"^\d{4}\.\d{2}\.\d{2}$", latest_date_str):
            date_obj = datetime.strptime(latest_date_str, "%Y.%m.%d")
        # YYYYMMDD ÌòïÏãù
        elif re.match(r"^\d{8}$", latest_date_str):
            date_obj = datetime.strptime(latest_date_str, "%Y%m%d")
        # YYYYÎÖÑ MMÏõî DDÏùº ÌòïÏãù (ÏãúÍ∞Ñ Ìè¨Ìï® Í∞ÄÎä•)
        elif re.match(r"^\d{4}ÎÖÑ\s*\d{1,2}Ïõî\s*\d{1,2}Ïùº", latest_date_str):
            # ÏãúÍ∞Ñ Î∂ÄÎ∂Ñ Ï†úÍ±∞ÌïòÍ≥† ÎÇ†ÏßúÎßå Ï∂îÏ∂ú
            match = re.match(r"(\d{4})ÎÖÑ\s*(\d{1,2})Ïõî\s*(\d{1,2})Ïùº", latest_date_str)
            if match:
                year, month, day = match.groups()
                formatted_date_str = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                date_obj = datetime.strptime(formatted_date_str, "%Y-%m-%d")
        else:
            print(f"  ‚ö†Ô∏è Ïïå Ïàò ÏóÜÎäî ÎÇ†Ïßú ÌòïÏãù: {latest_date_str}")
            return False

        # YYYY-MM-DD ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
        formatted_date = date_obj.strftime("%Y-%m-%d")

        # DB ÏóÖÎç∞Ïù¥Ìä∏
        conn = get_db_connection()
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    """
                    UPDATE homepage_site_announcement_date
                    SET latest_announcement_date = %s
                    WHERE site_code = %s
                """,
                    (formatted_date, site_code),
                )

                conn.commit()
                print(f"  üìÖ DB ÏóÖÎç∞Ïù¥Ìä∏ ÏÑ±Í≥µ: {site_code} ‚Üí {formatted_date}")
                return True
        finally:
            conn.close()

    except Exception as e:
        print(f"  ‚ùå DB ÏóÖÎç∞Ïù¥Ìä∏ Ïò§Î•ò: {site_code} - {e}")
        return False


def check_scraper_exists(site_code):
    scraper_path = SCRAPER_DIR / f"{site_code}_scraper.js"
    return scraper_path.exists(), scraper_path


def run_scraper(site_code, from_date):
    start_time = time.time()

    exists, scraper_path = check_scraper_exists(site_code)

    if not exists:
        return {
            "site_code": site_code,
            "status": "skipped",
            "reason": f"Ïä§ÌÅ¨ÎûòÌçº ÌååÏùº ÏóÜÏùå: {scraper_path}",
            "elapsed_time": time.time() - start_time,
        }

    target_year = from_date.year
    from_date_str = from_date.strftime("%Y-%m-%d")
    today_str = datetime.now().strftime("%Y-%m-%d")

    # Ïä§ÌÅ¨ÎûòÌçºÍ∞Ä ÎÇ¥Î∂ÄÏ†ÅÏúºÎ°ú site_codeÎ•º Ï∂îÍ∞ÄÌïòÎØÄÎ°ú, Ïó¨Í∏∞ÏÑúÎäî ÎÇ†Ïßú ÎîîÎ†âÌÜ†Î¶¨ÍπåÏßÄÎßå ÏÉùÏÑ±
    base_dir_for_date = BASE_OUTPUT_DIR / today_str
    base_dir_for_date.mkdir(parents=True, exist_ok=True)

    # Ïã§Ï†ú output_dirÎäî Ïä§ÌÅ¨ÎûòÌçºÍ∞Ä ÏÉùÏÑ±Ìï† Í≤ÉÏù¥ÎØÄÎ°ú Ïó¨Í∏∞ÏÑúÎäî base_dirÎßå Ï†ÑÎã¨
    expected_output_dir = base_dir_for_date / site_code  # ÏòàÏÉÅ Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ (Î°úÍπÖÏö©)

    # Ïù¥ÎØ∏ Ïä§ÌÅ¨ÎûòÌïëÎêú ÌååÏùºÏù¥ ÏûàÎäîÏßÄ ÌôïÏù∏
    if expected_output_dir.exists():
        print(f"  üìÅ Í∏∞Ï°¥ Ïä§ÌÅ¨ÎûòÌïë ÌååÏùº Î∞úÍ≤¨: {expected_output_dir}")

        # Ï≤´ Î≤àÏß∏ Ìè¥ÎçîÏùò content.mdÏóêÏÑú ÎÇ†Ïßú ÌôïÏù∏
        latest_scraped_date = get_latest_date_from_scraped_files(
            site_code, expected_output_dir
        )

        if latest_scraped_date:
            # DBÏùò ÎÇ†ÏßúÏôÄ ÎπÑÍµê
            db_date_str = from_date_str

            # ÎÇ†Ïßú ÌòïÏãù ÌÜµÏùºÌïòÏó¨ ÎπÑÍµê
            try:
                # Ïä§ÌÅ¨ÎûòÌïëÎêú ÎÇ†ÏßúÎ•º YYYY-MM-DD ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
                import re

                scraped_date_normalized = None

                if re.match(r"^\d{4}-\d{2}-\d{2}$", latest_scraped_date):
                    scraped_date_normalized = latest_scraped_date
                elif re.match(r"^\d{4}\.\d{2}\.\d{2}$", latest_scraped_date):
                    scraped_date_normalized = latest_scraped_date.replace(".", "-")
                elif re.match(r"^\d{8}$", latest_scraped_date):
                    scraped_date_normalized = f"{latest_scraped_date[:4]}-{latest_scraped_date[4:6]}-{latest_scraped_date[6:8]}"

                if scraped_date_normalized and scraped_date_normalized == db_date_str:
                    print(
                        f"  ‚äô Ïù¥ÎØ∏ ÏµúÏã† Îç∞Ïù¥ÌÑ∞: DB ÎÇ†Ïßú({db_date_str}) = Ïä§ÌÅ¨ÎûòÌïë ÎÇ†Ïßú({scraped_date_normalized})"
                    )
                    return {
                        "site_code": site_code,
                        "status": "skipped",
                        "reason": f"Ïù¥ÎØ∏ ÏµúÏã† Îç∞Ïù¥ÌÑ∞ Î≥¥Ïú† (ÎÇ†Ïßú: {db_date_str})",
                        "elapsed_time": time.time() - start_time,
                    }
                else:
                    print(
                        f"  üìÖ ÎÇ†Ïßú Ï∞®Ïù¥ Î∞úÍ≤¨: DB({db_date_str}) != Ïä§ÌÅ¨ÎûòÌïë({scraped_date_normalized or latest_scraped_date})"
                    )
            except Exception as e:
                print(f"  ‚ö†Ô∏è ÎÇ†Ïßú ÎπÑÍµê Ï§ë Ïò§Î•ò: {e}")
    else:
        print(f"  üìÇ Ïã†Í∑ú Ïä§ÌÅ¨ÎûòÌïë (Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏùå)")

    try:
        # Ïä§ÌÅ¨ÎûòÌçºÏóê Ï†ÑÎã¨Ìï† arguments (named arguments ÌòïÏãù)
        cmd = [
            "node",
            str(scraper_path),
            "--output",
            str(base_dir_for_date),  # ÎÇ†Ïßú ÎîîÎ†âÌÜ†Î¶¨ÍπåÏßÄÎßå Ï†ÑÎã¨
            "--date",
            from_date_str,  # ÏãúÏûë ÎÇ†Ïßú
            # "--site",
            # site_code,  # ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú
            # "--force",  # Í∏∞Ï°¥ Ìè¥Îçî ÎçÆÏñ¥Ïì∞Í∏∞
        ]

        print(f"\n[{site_code}] Ïä§ÌÅ¨ÎûòÌçº Ïã§Ìñâ")
        print(f"  Ïä§ÌÅ¨ÎûòÌçº ÌååÏùº: {scraper_path}")
        print(f"  ÏãúÏûëÏùº: {from_date_str}")
        print(f"  Ï¢ÖÎ£åÏùº: {today_str}")
        print(f"  Í∏∞Î≥∏ Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨: {base_dir_for_date}")
        # print(f"  ÏòàÏÉÅ ÏµúÏ¢Ö ÎîîÎ†âÌÜ†Î¶¨: {expected_output_dir}")
        # print(f"  ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨: {NODE_DIR}")
        print(f"  Î™ÖÎ†π: {' '.join(cmd)}")

        # ÌôòÍ≤ΩÎ≥ÄÏàò ÏÑ§Ï†ï (ÌïÑÏöîÏãú)
        env = os.environ.copy()
        env["NODE_ENV"] = "production"

        # Ïã§ÏãúÍ∞Ñ Ï∂úÎ†•ÏùÑ ÏúÑÌï¥ subprocess.Popen ÏÇ¨Ïö©
        process = subprocess.Popen(
            cmd,
            cwd=str(NODE_DIR),
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # stderrÎ•º stdoutÏúºÎ°ú Ìï©Ïπ®
            text=True,
            bufsize=1,  # ÎùºÏù∏ Î≤ÑÌçºÎßÅ
            env=env,
        )
        
        # Ïã§ÏãúÍ∞Ñ Î°úÍ∑∏ Ï∂úÎ†•
        stdout_lines = []
        for line in iter(process.stdout.readline, ''):
            if line:
                line = line.rstrip()
                print(f"  [{site_code}] {line}")  # Ïã§ÏãúÍ∞Ñ Ï∂úÎ†•
                stdout_lines.append(line)
        
        process.stdout.close()
        return_code = process.wait(timeout=1200)  # ÏµúÎåÄ 20Î∂Ñ ÎåÄÍ∏∞
        
        # subprocess.runÍ≥º Ïú†ÏÇ¨Ìïú Í≤∞Í≥º Í∞ùÏ≤¥ ÏÉùÏÑ±
        result = type('Result', (), {
            'returncode': return_code,
            'stdout': '\n'.join(stdout_lines),
            'stderr': ''  # stderrÎäî stdoutÏúºÎ°ú Ìï©Ï≥§Ïùå
        })()

        if result.returncode == 0:
            # stdoutÏù¥ ÏóÜÏñ¥ÎèÑ ÏÑ±Í≥µÏúºÎ°ú Ï≤òÎ¶¨Ìï† Ïàò ÏûàÎèÑÎ°ù Ï≤¥ÌÅ¨
            scraped_count = 0
            if "scraped" in result.stdout.lower():
                # stdoutÏóêÏÑú Ïä§ÌÅ¨ÎûòÌïë Í∞úÏàò Ï∂îÏ∂ú ÏãúÎèÑ
                import re

                match = re.search(
                    r"(\d+)\s*(?:items?|announcements?|Í≥µÍ≥†)", result.stdout
                )
                if match:
                    scraped_count = int(match.group(1))

            elapsed_time = time.time() - start_time
            return {
                "site_code": site_code,
                "status": "success",
                "output_dir": str(expected_output_dir),
                "scraped_count": scraped_count,
                "elapsed_time": elapsed_time,
                "stdout": (
                    result.stdout[-500:] if len(result.stdout) > 500 else result.stdout
                ),
            }
        else:
            elapsed_time = time.time() - start_time
            return {
                "site_code": site_code,
                "status": "failed",
                "returncode": result.returncode,
                "error": result.stderr if result.stderr else result.stdout,
                "elapsed_time": elapsed_time,
                "stdout": (
                    result.stdout[-500:] if len(result.stdout) > 500 else result.stdout
                ),
            }

    except subprocess.TimeoutExpired:
        elapsed_time = time.time() - start_time
        return {
            "site_code": site_code,
            "status": "timeout",
            "error": "15Î∂Ñ ÌÉÄÏûÑÏïÑÏõÉ Ï¥àÍ≥º",
            "elapsed_time": elapsed_time,
        }
    except Exception as e:
        elapsed_time = time.time() - start_time
        return {
            "site_code": site_code,
            "status": "error",
            "error": str(e),
            "elapsed_time": elapsed_time,
        }


def main():
    # Ïª§Îß®ÎìúÎùºÏù∏ Ïù∏Ïûê ÌååÏã±
    parser = argparse.ArgumentParser(description='ÌôàÌéòÏù¥ÏßÄ Í≥†Ïãú/Í≥µÍ≥† Ï†êÏßÑÏ†Å Ïä§ÌÅ¨ÎûòÌïë v2')
    parser.add_argument('--site-code', type=str, help='ÌäπÏ†ï ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìúÎßå Ï≤òÎ¶¨ (Ïòà: --site-code acci)')
    args = parser.parse_args()
    
    total_start_time = time.time()

    print("=" * 80)
    print("ÌôàÌéòÏù¥ÏßÄ Í≥†Ïãú/Í≥µÍ≥† Ï†êÏßÑÏ†Å Ïä§ÌÅ¨ÎûòÌïë v2")
    print(f"Ïã§Ìñâ ÏãúÏûë: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    if args.site_code:
        print(f"ÎåÄÏÉÅ ÏÇ¨Ïù¥Ìä∏: {args.site_code}")
    print("=" * 80)

    sites = get_sites_to_scrape(args.site_code)
    
    if not sites:
        if args.site_code:
            print(f"\n‚ùå ÏÇ¨Ïù¥Ìä∏ ÏΩîÎìú '{args.site_code}'Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        else:
            print("\n‚ùå Ï≤òÎ¶¨Ìï† ÏÇ¨Ïù¥Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return
    
    print(f"\nÏ¥ù {len(sites)}Í∞ú ÏÇ¨Ïù¥Ìä∏ ÎåÄÏÉÅ")

    BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    results = {"success": [], "failed": [], "skipped": [], "timeout": [], "error": []}

    for idx, site in enumerate(sites, 1):
        site_code = site["site_code"]
        from_date = site["latest_announcement_date"]

        print(f"\n{'='*80}")
        print(f"[{idx}/{len(sites)}] {site_code}")
        print(f"{'='*80}")

        result = run_scraper(site_code, from_date)
        status = result["status"]
        results[status].append(result)

        elapsed = result.get("elapsed_time", 0)

        # Î™®Îì† ÏÉÅÌÉúÏóê ÎåÄÌï¥ Î°úÍ∑∏ Ï†ÄÏû•
        scraper_file = f"{site_code}_scraper.js"

        if status == "success":
            print(f"  ‚úì ÏÑ±Í≥µ: {result['output_dir']} (ÏÜåÏöîÏãúÍ∞Ñ: {elapsed:.1f}Ï¥à)")
            # Ïä§ÌÅ¨ÎûòÌïë ÏÑ±Í≥µ Ïãú DB ÏóÖÎç∞Ïù¥Ìä∏
            update_latest_announcement_date(site_code, result["output_dir"])
            # ÏÑ±Í≥µ Î°úÍ∑∏ Ï†ÄÏû•
            save_scraper_log(
                site_code=site_code,
                status="success",
                elapsed_time=elapsed,
                scraper_file=scraper_file,
                from_date=from_date,
                output_dir=result.get("output_dir"),
                scraped_count=result.get("scraped_count", 0),
            )
        elif status == "skipped":
            print(f"  ‚äò Ïä§ÌÇµ: {result['reason']} (ÏÜåÏöîÏãúÍ∞Ñ: {elapsed:.1f}Ï¥à)")
            # Ïä§ÌÇµ Î°úÍ∑∏ Ï†ÄÏû• (ÏÑ†ÌÉùÏ†Å)
            save_scraper_log(
                site_code=site_code,
                status="skipped",
                elapsed_time=elapsed,
                error_message=result.get("reason"),
                scraper_file=scraper_file,
                from_date=from_date,
            )
        elif status == "failed":
            print(f"  ‚úó Ïã§Ìå®: {result['error'][:200]} (ÏÜåÏöîÏãúÍ∞Ñ: {elapsed:.1f}Ï¥à)")
            # Ïã§Ìå® Î°úÍ∑∏ Ï†ÄÏû•
            log_id = save_scraper_log(
                site_code=site_code,
                status="failed",
                elapsed_time=elapsed,
                error_message=result.get("error"),
                scraper_file=scraper_file,
                from_date=from_date,
            )
            # Ïù¥Î©îÏùº ÏïåÎ¶º Î∞úÏÜ° (ÏÑ†ÌÉùÏ†Å)
            if ALERT_ENABLED:
                if send_alert_email(
                    site_code, "failed", result.get("error"), elapsed, from_date
                ):
                    save_alert_history(
                        log_id,
                        site_code,
                        "failure",
                        result.get("error"),
                        ALERT_RECIPIENTS,
                    )
        elif status == "timeout":
            print(f"  ‚è± ÌÉÄÏûÑÏïÑÏõÉ: {result['error']} (ÏÜåÏöîÏãúÍ∞Ñ: {elapsed:.1f}Ï¥à)")
            # ÌÉÄÏûÑÏïÑÏõÉ Î°úÍ∑∏ Ï†ÄÏû•
            log_id = save_scraper_log(
                site_code=site_code,
                status="timeout",
                elapsed_time=elapsed,
                error_message=result.get("error"),
                scraper_file=scraper_file,
                from_date=from_date,
            )
            # ÌÉÄÏûÑÏïÑÏõÉÏùÄ Ìï≠ÏÉÅ Ïù¥Î©îÏùº ÏïåÎ¶º Î∞úÏÜ°
            if send_alert_email(
                site_code, "timeout", result.get("error"), elapsed, from_date
            ):
                save_alert_history(
                    log_id, site_code, "timeout", result.get("error"), ALERT_RECIPIENTS
                )
        elif status == "error":
            print(f"  ‚ö† Ïò§Î•ò: {result['error'][:200]} (ÏÜåÏöîÏãúÍ∞Ñ: {elapsed:.1f}Ï¥à)")
            # Ïò§Î•ò Î°úÍ∑∏ Ï†ÄÏû•
            log_id = save_scraper_log(
                site_code=site_code,
                status="error",
                elapsed_time=elapsed,
                error_message=result.get("error"),
                scraper_file=scraper_file,
                from_date=from_date,
            )
            # Ïò§Î•òÎèÑ Ïù¥Î©îÏùº ÏïåÎ¶º Î∞úÏÜ°
            if send_alert_email(
                site_code, "error", result.get("error"), elapsed, from_date
            ):
                save_alert_history(
                    log_id, site_code, "error", result.get("error"), ALERT_RECIPIENTS
                )

    total_elapsed = time.time() - total_start_time

    print("\n" + "=" * 80)
    print("Ï≤òÎ¶¨ Í≤∞Í≥º ÏöîÏïΩ")
    print("=" * 80)
    print(f"ÏÑ±Í≥µ: {len(results['success'])}Í∞ú")
    print(f"Ïã§Ìå®: {len(results['failed'])}Í∞ú")
    print(f"Ïä§ÌÇµ: {len(results['skipped'])}Í∞ú")
    print(f"ÌÉÄÏûÑÏïÑÏõÉ: {len(results['timeout'])}Í∞ú")
    print(f"Ïò§Î•ò: {len(results['error'])}Í∞ú")

    if results["skipped"]:
        print(f"\nÏä§ÌÇµÎêú ÏÇ¨Ïù¥Ìä∏ ({len(results['skipped'])}Í∞ú):")
        for r in results["skipped"][:10]:
            print(f"  - {r['site_code']}")
        if len(results["skipped"]) > 10:
            print(f"  ... Ïô∏ {len(results['skipped']) - 10}Í∞ú")

    print("\n" + "=" * 80)
    print(f"Ï¥ù Ïã§Ìñâ ÏãúÍ∞Ñ: {total_elapsed:.1f}Ï¥à ({total_elapsed/60:.1f}Î∂Ñ)")
    print(f"Ï¢ÖÎ£å ÏãúÍ∞Ñ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    # ÌÉÄÏûÑÏïÑÏõÉÏù¥ÎÇò Ïò§Î•òÍ∞Ä ÏûàÏóàÎã§Î©¥ Ï¢ÖÌï© Î≥¥Í≥†ÏÑú Ïù¥Î©îÏùº Î∞úÏÜ°
    if (results["timeout"] or results["error"] or results["failed"]) and ALERT_ENABLED:
        send_summary_email(results, total_elapsed)


if __name__ == "__main__":
    main()
