#!/usr/bin/env python3
"""
ê³µê³  ì²˜ë¦¬ ë©”ì¸ í”„ë¡œê·¸ë¨ - 2ê°œ ì›Œì»¤ ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „

ì‚¬ìš©ë²•:
    python announcement_processor_parallel.py --site-code [ì‚¬ì´íŠ¸ì½”ë“œ] [ì˜µì…˜ë“¤]
    
ì˜ˆì‹œ:
    python announcement_processor_parallel.py --site-code acci --data data.origin
    python announcement_processor_parallel.py --site-code cbt --workers 2
"""

import argparse
import json
import os
import sys
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.config.config import ConfigManager
from src.config.logConfig import setup_logging
from src.utils.attachmentProcessor import AttachmentProcessor
from src.utils.ollamaClient import AnnouncementAnalyzer
from src.models.announcementDatabase import AnnouncementDatabaseManager, create_announcement_tables
from src.utils.announcementFilter import AnnouncementFilter

logger = setup_logging(__name__)
config = ConfigManager().get_config()

@dataclass
class ProcessingTask:
    """ì²˜ë¦¬ ì‘ì—… ì •ë³´"""
    directory_path: Path
    site_code: str
    folder_name: str
    attach_force: bool
    force: bool
    task_id: str

@dataclass
class ProcessingResult:
    """ì²˜ë¦¬ ê²°ê³¼ ì •ë³´"""
    task_id: str
    folder_name: str
    success: bool
    error_message: Optional[str] = None
    processing_time: float = 0.0

class ParallelAnnouncementProcessor:
    """ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „ì˜ ê³µê³  ì²˜ë¦¬ í´ë˜ìŠ¤ (2ê°œ ì›Œì»¤ ìµœì í™”)"""
    
    def __init__(self, attach_force: bool = False, max_workers: int = 2):
        self.attach_force = attach_force
        self.max_workers = max_workers
        
        # ìŠ¤ë ˆë“œë³„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìœ„í•œ ThreadLocal ì €ì¥ì†Œ
        self._local = threading.local()
        
        # ì „ì—­ DB ë§¤ë‹ˆì € (ì—°ê²° í’€ë§ìš©)
        self.global_db_manager = AnnouncementDatabaseManager()
        
        # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)
        self._ensure_database_tables()
        
        # ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ (í•œ ë²ˆë§Œ)
        self.exclusion_keywords = self._load_exclusion_keywords()
        
        # í†µê³„ ì¶”ì ìš©
        self._stats_lock = threading.Lock()
        self._processing_stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'skipped_tasks': 0,
            'start_time': None,
            'active_workers': 0
        }
    
    def _get_local_instances(self):
        """ìŠ¤ë ˆë“œë³„ ë¡œì»¬ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        if not hasattr(self._local, 'initialized'):
            # ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self._local.attachment_processor = AttachmentProcessor()
            self._local.announcement_analyzer = AnnouncementAnalyzer()
            self._local.db_manager = AnnouncementDatabaseManager()
            self._local.filter = AnnouncementFilter()
            self._local.initialized = True
            
            logger.info(f"ìŠ¤ë ˆë“œë³„ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {threading.current_thread().name}")
        
        return (
            self._local.attachment_processor,
            self._local.announcement_analyzer,
            self._local.db_manager,
            self._local.filter
        )
    
    def _ensure_database_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if self.global_db_manager.test_connection():
                self.global_db_manager.create_tables()
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ")
            else:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤ (DB ì €ì¥ ë¶ˆê°€)")
    
    def _load_exclusion_keywords(self) -> List[Dict[str, Any]]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with self.global_db_manager.SessionLocal() as session:
                result = session.execute(text("""
                    SELECT EXCLUSION_ID, KEYWORD, DESCRIPTION
                    FROM EXCLUSION_KEYWORDS
                    WHERE IS_ACTIVE = TRUE
                    ORDER BY EXCLUSION_ID
                """))
                
                keywords = []
                for row in result:
                    keywords.append({
                        'id': row[0],
                        'keyword': row[1],
                        'description': row[2]
                    })
                
                logger.info(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ: {len(keywords)}ê°œ")
                return keywords
                
        except Exception as e:
            logger.warning(f"ì œì™¸ í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def _update_stats(self, stat_name: str, increment: int = 1):
        """í†µê³„ë¥¼ ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        with self._stats_lock:
            self._processing_stats[stat_name] += increment
    
    def _print_progress(self, completed: int, total: int, worker_name: str, folder_name: str, elapsed: float):
        """ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        progress_pct = (completed / total) * 100 if total > 0 else 0
        print(f"[{worker_name}] [{completed}/{total} : {progress_pct:.1f}%] {folder_name} ({elapsed:.1f}ì´ˆ)")
    
    def process_single_directory(self, task: ProcessingTask) -> ProcessingResult:
        """ë‹¨ì¼ ë””ë ‰í† ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ìŠ¤ë ˆë“œ ì•ˆì „)."""
        worker_name = threading.current_thread().name
        start_time = time.time()
        
        try:
            # ìŠ¤ë ˆë“œë³„ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            attachment_processor, announcement_analyzer, db_manager, filter_instance = self._get_local_instances()
            
            logger.info(f"[{worker_name}] ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì‹œì‘: {task.folder_name}")
            
            # ì¤‘ë³µ ì²˜ë¦¬ ì²´í¬ (force ì˜µì…˜ì´ ì—†ì„ ë•Œë§Œ)
            if not task.force:
                if db_manager.is_already_processed(task.folder_name, task.site_code):
                    elapsed = time.time() - start_time
                    logger.info(f"[{worker_name}] ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {task.folder_name}")
                    return ProcessingResult(
                        task_id=task.task_id,
                        folder_name=task.folder_name,
                        success=True,
                        processing_time=elapsed
                    )
            
            # ì‹¤ì œ ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰ (ê¸°ì¡´ process_directory_with_custom_nameê³¼ ë™ì¼)
            success = self._process_directory_core(
                task, attachment_processor, announcement_analyzer, db_manager, filter_instance
            )
            
            elapsed = time.time() - start_time
            
            return ProcessingResult(
                task_id=task.task_id,
                folder_name=task.folder_name,
                success=success,
                processing_time=elapsed
            )
            
        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
            logger.error(f"[{worker_name}] {error_msg} ({task.folder_name})")
            
            return ProcessingResult(
                task_id=task.task_id,
                folder_name=task.folder_name,
                success=False,
                error_message=error_msg,
                processing_time=elapsed
            )
    
    def _process_directory_core(self, task: ProcessingTask, attachment_processor, announcement_analyzer, db_manager, filter_instance) -> bool:
        """ë””ë ‰í† ë¦¬ ì²˜ë¦¬ í•µì‹¬ ë¡œì§ (ìŠ¤ë ˆë“œë³„ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)"""
        directory_path = task.directory_path
        site_code = task.site_code
        folder_name = task.folder_name
        attach_force = task.attach_force
        force = task.force
        
        try:
            # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
            excluded_keywords = self._check_exclusion_keywords(folder_name)
            
            # 2. content.md íŒŒì¼ ì½ê¸°
            content_md_path = directory_path / "content.md"
            content_md = ""
            
            if content_md_path.exists():
                try:
                    with open(content_md_path, 'r', encoding='utf-8') as f:
                        content_md = f.read()
                    logger.info(f"content.md ì½ê¸° ì™„ë£Œ: {len(content_md)} ë¬¸ì")
                except Exception as e:
                    logger.error(f"content.md ì½ê¸° ì‹¤íŒ¨: {e}")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, "", 
                        status="ollama", error_message=f"content.md ì½ê¸° ì‹¤íŒ¨: {e}",
                        db_manager=db_manager
                    )
            else:
                logger.warning(f"content.md íŒŒì¼ì´ ì—†ìŒ: {content_md_path}")
            
            # 3. ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ (content.mdì™€ ë¶„ë¦¬)
            try:
                combined_content, attachment_filenames = self._process_attachments_separately(
                    directory_path, attach_force, attachment_processor
                )
                
                if not content_md.strip() and not combined_content.strip():
                    logger.warning("ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŒ")
                    return self._save_processing_result(
                        folder_name, site_code, content_md, combined_content,
                        attachment_filenames=attachment_filenames,
                        status="ollama", error_message="ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŒ",
                        db_manager=db_manager
                    )
                
                logger.info(f"ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ ì™„ë£Œ: {len(combined_content)} ë¬¸ì, íŒŒì¼ {len(attachment_filenames)}ê°œ")
                
            except Exception as e:
                logger.error(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                return self._save_processing_result(
                    folder_name, site_code, content_md, "",
                    attachment_filenames=[],
                    status="ollama", error_message=f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}",
                    db_manager=db_manager
                )
            
            # 4. ì œì™¸ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ì œì™¸ ì²˜ë¦¬
            if excluded_keywords:
                exclusion_msg = f"ì œì™¸ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {', '.join(excluded_keywords)}"
                logger.info(f"ì œì™¸ ì²˜ë¦¬: {folder_name} - {exclusion_msg}")
                
                return self._save_processing_result(
                    folder_name, site_code, content_md, combined_content,
                    attachment_filenames=attachment_filenames,
                    status="ì œì™¸", exclusion_keywords=excluded_keywords,
                    exclusion_reason=exclusion_msg,
                    db_manager=db_manager
                )
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ì— 1ì°¨ ì €ì¥ (status: ollama)
            record_id = self._save_processing_result(
                folder_name, site_code, content_md, combined_content, 
                attachment_filenames=attachment_filenames,
                status="ollama", force=True,  # force ì˜µì…˜ì€ í•­ìƒ UPSERTë¡œ ì²˜ë¦¬
                db_manager=db_manager
            )

            # 5.5. ì œëª©ì—ì„œ "ì§€ì›" í‚¤ì›Œë“œ í™•ì¸ (Ollama ë¶„ì„ ì „ ì¡°ê¸° ë°˜í™˜)
            if content_md.strip():
                extracted_title = self._extract_title_from_content(content_md)
                logger.info(f"ì¶”ì¶œëœ ì œëª©: {extracted_title}")
                
                if "ì§€ì›" in extracted_title:
                    logger.info(f"ì œëª©ì— 'ì§€ì›' í‚¤ì›Œë“œ ë°œê²¬: {extracted_title}")
                    print(f"  âœ… ì œëª©ì— 'ì§€ì›' í‚¤ì›Œë“œ ë°œê²¬: {extracted_title[:50]}...")
                    
                    # ë°”ë¡œ ì„±ê³µ ì²˜ë¦¬í•˜ê³  ë‹¤ìŒ ê³µê³ ë¡œ ì´ë™
                    return self._update_processing_result_simple(
                        record_id, status="ì„±ê³µ", error_message="ì œëª©ì— ì§€ì›ì´ë¼ëŠ” ê¸€ì ìˆìŒ",
                        db_manager=db_manager
                    )
            
            # 6. content_mdë¡œ ì²«ë²ˆì§¸ ollama ë¶„ì„
            print("  ğŸ“‹ 1ì°¨ Ollama ë¶„ì„ ì¤‘ (content.md)...")
            first_response = None
            
            if content_md.strip():
                first_response, first_prompt = self._analyze_with_ollama(content_md, announcement_analyzer)
                
                # EXTRACTED_TARGETì´ ìˆëŠ”ì§€ í™•ì¸
                def has_valid_target(response):
                    if not response:
                        return False
                    target = response.get("EXTRACTED_TARGET", "")
                    return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
                
                if has_valid_target(first_response):
                    # ì„±ê³µ: ìµœì¢… ì‘ë‹µìœ¼ë¡œ ì‚¬ìš©
                    logger.info("1ì°¨ ë¶„ì„ ì„±ê³µ - content.mdì—ì„œ EXTRACTED_TARGET ì¶”ì¶œë¨")
                    return self._update_processing_result(
                        record_id, first_response, first_prompt, status="ì„±ê³µ",
                        db_manager=db_manager
                    )
            
            # 7. combined_contentë¡œ ë‘ë²ˆì§¸ ollama ë¶„ì„
            print("  ğŸ“‹ 2ì°¨ Ollama ë¶„ì„ ì¤‘ (ì²¨ë¶€íŒŒì¼)...")
            second_response = None
            
            if combined_content.strip():
                second_response, second_prompt = self._analyze_with_ollama(combined_content, announcement_analyzer)
                
                # ìµœì¢… ìƒíƒœ ê²°ì • ë¡œì§
                final_status = self._determine_final_status(first_response, second_response)
                
                return self._update_processing_result(
                    record_id, second_response, second_prompt, 
                    first_response=first_response, status=final_status,
                    db_manager=db_manager
                )
            else:
                # combined_contentê°€ ì—†ëŠ” ê²½ìš° 1ì°¨ ê²°ê³¼ë§Œ ì‚¬ìš©
                final_status = self._determine_final_status(first_response, None)
                return self._update_processing_result(
                    record_id, first_response, first_prompt if first_response else "", 
                    status=final_status,
                    db_manager=db_manager
                )
                
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return self._save_processing_result(
                folder_name, site_code, "", "",
                status="ollama", error_message=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}",
                db_manager=db_manager
            )
    
    def process_site_directories_parallel(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False, attach_force: bool = False) -> Dict[str, int]:
        """íŠ¹ì • ì‚¬ì´íŠ¸ì˜ ëª¨ë“  ë””ë ‰í† ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        # ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ ì°¾ê¸°
        target_directories = self._find_target_directories(base_dir, site_code, recursive, force)
        
        if not target_directories:
            logger.warning("ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}
        
        total_count = len(target_directories)
        site_dir = base_dir / site_code
        
        # ì‘ì—… ëª©ë¡ ìƒì„±
        tasks = []
        for i, directory in enumerate(target_directories):
            relative_path = directory.relative_to(site_dir)
            folder_name = str(relative_path).replace("/", "_")  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
            
            task = ProcessingTask(
                directory_path=directory,
                site_code=site_code,
                folder_name=folder_name,
                attach_force=attach_force,
                force=force,
                task_id=f"{site_code}_{i}"
            )
            tasks.append(task)
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        return self._execute_parallel_processing(tasks, site_code)
    
    def _execute_parallel_processing(self, tasks: List[ProcessingTask], context_name: str = "") -> Dict[str, int]:
        """ì‘ì—… ëª©ë¡ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        total_count = len(tasks)
        results = {"total": total_count, "success": 0, "failed": 0, "skipped": 0}
        
        if total_count == 0:
            return results
        
        start_time = time.time()
        processed_count = 0
        
        print(f"\nğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {context_name} ({total_count}ê°œ ì‘ì—…, {self.max_workers}ê°œ ì›Œì»¤)")
        print(f"{'='*60}")
        
        with ThreadPoolExecutor(max_workers=self.max_workers, thread_name_prefix="Worker") as executor:
            # ëª¨ë“  ì‘ì—…ì„ submit
            future_to_task = {executor.submit(self.process_single_directory, task): task for task in tasks}
            
            # ì™„ë£Œë˜ëŠ” ëŒ€ë¡œ ê²°ê³¼ ì²˜ë¦¬
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                processed_count += 1
                
                try:
                    result = future.result()
                    
                    if result.success:
                        results["success"] += 1
                        status_icon = "âœ…"
                        status_text = "ì„±ê³µ"
                    else:
                        results["failed"] += 1
                        status_icon = "âŒ"
                        status_text = f"ì‹¤íŒ¨: {result.error_message or 'Unknown error'}"
                    
                    progress_pct = (processed_count / total_count) * 100
                    print(f"[{processed_count}/{total_count} : {progress_pct:.1f}%] {status_icon} {result.folder_name} ({result.processing_time:.1f}ì´ˆ)")
                    
                except Exception as e:
                    results["failed"] += 1
                    print(f"[{processed_count}/{total_count}] âŒ {task.folder_name} - ì˜ˆì™¸: {str(e)[:50]}...")
                    logger.error(f"Future ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        total_elapsed = time.time() - start_time
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {context_name}")
        print(f"ì „ì²´: {results['total']}, ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}")
        print(f"ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ ({total_elapsed/60:.1f}ë¶„)")
        if results['success'] > 0:
            avg_time = total_elapsed / results['success']
            print(f"ì„±ê³µí•œ í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time:.1f}ì´ˆ")
        
        # ì„±ëŠ¥ í–¥ìƒ ê³„ì‚° (ìˆœì°¨ ëŒ€ë¹„ ì¶”ì •)
        if results['success'] > 0:
            estimated_sequential_time = total_elapsed * self.max_workers  # ëŒ€ëµì  ì¶”ì •
            speedup_ratio = estimated_sequential_time / total_elapsed
            print(f"ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: {speedup_ratio:.2f}x (ëŒ€ëµì  ì¶”ì •)")
        
        print(f"{'='*60}")
        
        return results
    
    # ê¸°ì¡´ AnnouncementProcessorì˜ í—¬í¼ ë©”ì„œë“œë“¤ì„ ë³µì‚¬ (ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê³ ë ¤)
    def _find_target_directories(self, base_dir: Path, site_code: str, recursive: bool = False, force: bool = False) -> List[Path]:
        """ì²˜ë¦¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
        site_dir = base_dir / site_code
        
        if not site_dir.exists():
            logger.error(f"ì‚¬ì´íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {site_dir}")
            return []
        
        target_directories = []
        
        if recursive:
            logger.info(f"ì¬ê·€ì  ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘: {site_dir}")
            
            for root_path in site_dir.rglob("*"):
                if root_path.is_dir():
                    has_content_md = (root_path / "content.md").exists()
                    has_attachments = (root_path / "attachments").exists() and any((root_path / "attachments").iterdir())
                    
                    if has_content_md or has_attachments:
                        target_directories.append(root_path)
                        logger.debug(f"ëŒ€ìƒ ë””ë ‰í† ë¦¬ ë°œê²¬: {root_path.relative_to(site_dir)}")
        else:
            all_directories = [d for d in site_dir.iterdir() if d.is_dir()]
            target_directories = sorted(all_directories, key=self._natural_sort_key)
        
        logger.info(f"ë°œê²¬ëœ ì „ì²´ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
        
        if target_directories:
            logger.info(f"ì²« 5ê°œ í´ë”: {[d.name for d in target_directories[:5]]}")
        
        if not force:
            processed_folders = set(self.global_db_manager.get_processed_folders(site_code))
            
            filtered_directories = []
            for directory in target_directories:
                relative_path = directory.relative_to(site_dir)
                folder_name = str(relative_path).replace("/", "_")  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                
                if folder_name not in processed_folders:
                    filtered_directories.append(directory)
                else:
                    logger.debug(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë” ê±´ë„ˆëœ€: {folder_name}")
            
            logger.info(f"ì „ì²´ ë°œê²¬ëœ ë””ë ‰í† ë¦¬: {len(target_directories)}ê°œ")
            logger.info(f"ì²˜ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {len(filtered_directories)}ê°œ")
            logger.info(f"ì´ë¯¸ ì²˜ë¦¬ëœ í´ë”: {len(processed_folders)}ê°œ")
            
            return filtered_directories
        else:
            logger.info(f"--force ì˜µì…˜: ëª¨ë“  ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ({len(target_directories)}ê°œ)")
            return target_directories
    
    def _check_exclusion_keywords(self, folder_name: str) -> List[str]:
        """í´ë”ëª…ì—ì„œ ì œì™¸ í‚¤ì›Œë“œë¥¼ ì²´í¬í•©ë‹ˆë‹¤."""
        matched_keywords = []
        
        for keyword_info in self.exclusion_keywords:
            keyword = keyword_info['keyword'].lower()
            if keyword in folder_name.lower():
                matched_keywords.append(keyword_info['keyword'])
                logger.debug(f"ì œì™¸ í‚¤ì›Œë“œ ë§¤ì¹­: '{keyword}' in '{folder_name}'")
        
        return matched_keywords
    
    def _extract_title_from_content(self, content_md: str) -> str:
        """content.mdì—ì„œ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not content_md:
            return ""
        
        lines = content_md.split('\n')
        
        # ì²« ë²ˆì§¸ ë¹„ì–´ìˆì§€ ì•Šì€ ì¤„ì„ ì°¾ê¸°
        for line in lines[:10]:  # ìƒìœ„ 10ì¤„ë§Œ í™•ì¸
            line = line.strip()
            if line:
                # # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                if line.startswith('#'):
                    title = line.lstrip('#').strip()
                    logger.debug(f"ë§ˆí¬ë‹¤ìš´ í—¤ë”ì—ì„œ ì œëª© ì¶”ì¶œ: {title}")
                    return title
                
                # ì œëª©:, ê³µê³ ëª…: íŒ¨í„´ í™•ì¸
                for prefix in ['ì œëª©:', 'ê³µê³ ëª…:', 'ê³µê³  ì œëª©:', 'ì œëª© :']:
                    if line.lower().startswith(prefix.lower()):
                        title = line[len(prefix):].strip()
                        logger.debug(f"{prefix} íŒ¨í„´ì—ì„œ ì œëª© ì¶”ì¶œ: {title}")
                        return title
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì œëª©ìœ¼ë¡œ ì‚¬ìš© (ì²« ë²ˆì§¸ ì¤„)
                logger.debug(f"ì²« ë²ˆì§¸ ì¤„ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©: {line}")
                return line
        
        return ""
    
    def _natural_sort_key(self, path: Path) -> tuple:
        """í´ë”ëª…ì˜ ìˆ«ì ë¶€ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ìì—° ì •ë ¬ì„ ìœ„í•œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        import re
        
        folder_name = path.name
        match = re.match(r'^(\d+)_(.*)$', folder_name)
        if match:
            number = int(match.group(1))
            title = match.group(2)
            return (number, title)
        else:
            return (float('inf'), folder_name)
    
    def _process_attachments_separately(self, directory_path: Path, attach_force: bool, attachment_processor) -> Tuple[str, List[str]]:
        """ì²¨ë¶€íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ë‚´ìš©ì„ ê²°í•©í•˜ê³  íŒŒì¼ëª… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        attachments_dir = directory_path / "attachments"
        
        if not attachments_dir.exists():
            return "", []
        
        combined_content = ""
        attachment_filenames = []
        
        supported_extensions = {'.pdf', '.hwp', '.hwpx', '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.pptx', '.docx', '.xlsx'}
        target_keywords = ['ì–‘ì‹', 'ì„œë¥˜', 'ì‹ ì²­ì„œ', 'ë™ì˜ì„œ']

        for file_path in attachments_dir.iterdir():
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                filename = file_path.stem
                
                lowercase_filename = filename.lower()
                
                if any(keyword in lowercase_filename for keyword in target_keywords):                
                    logger.info(f"ì–‘ì‹, ì‹ ì²­ì„œ ë“±ì€ SKIP===={filename}")
                    continue

                if not file_extension or file_extension not in supported_extensions:
                    logger.debug(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ê±´ë„ˆëœ€: {file_path.name}")
                    continue
                
                attachment_filenames.append(file_path.name)  # ì „ì²´ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
                logger.debug(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")
                
                md_file_path = attachments_dir / f"{filename}.md"
                
                if not attach_force and md_file_path.exists():
                    try:
                        with open(md_file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if content.strip():
                            combined_content += f"\n\n=== {filename}.md ===\n{content}"
                            logger.debug(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì„±ê³µ: {filename}.md ({len(content)} ë¬¸ì)")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ .md ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {filename}.md")
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ .md ì½ê¸° ì‹¤íŒ¨: {e}")
                else:
                    if attach_force and md_file_path.exists():
                        logger.info(f"--attach-force: ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì¬ë³€í™˜: {file_path.name}")
                    else:
                        logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹œì‘: {file_path.name}")
                        
                    try:
                        content = attachment_processor.process_single_file(file_path)
                        
                        if content and content.strip():
                            combined_content += f"\n\n=== {file_path.name} ===\n{content}"
                            logger.info(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì„±ê³µ: {file_path.name} ({len(content)} ë¬¸ì)")
                            
                            try:
                                with open(md_file_path, 'w', encoding='utf-8') as f:
                                    f.write(content)
                                logger.debug(f"ë³€í™˜ëœ ë‚´ìš©ì„ .mdë¡œ ì €ì¥: {md_file_path}")
                            except Exception as save_e:
                                logger.warning(f".md íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_e}")
                        else:
                            logger.warning(f"ì²¨ë¶€íŒŒì¼ì—ì„œ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {file_path.name}")
                        
                    except Exception as e:
                        logger.error(f"ì²¨ë¶€íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ ({file_path}): {e}")
        
        logger.info(f"ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(attachment_filenames)}ê°œ íŒŒì¼, {len(combined_content)} ë¬¸ì")
        return combined_content.strip(), attachment_filenames
    
    def _analyze_with_ollama(self, content: str, announcement_analyzer) -> Tuple[Optional[Dict[str, Any]], str]:
        """Ollamaë¥¼ í†µí•´ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            return announcement_analyzer.analyze_announcement(content)
        except Exception as e:
            logger.error(f"Ollama ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, ""
    
    def _determine_final_status(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]]) -> str:
        """1ì°¨, 2ì°¨ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ìƒíƒœë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        
        def has_valid_target(response):
            if not response:
                return False
            target = response.get("EXTRACTED_TARGET", "")
            return target and target not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        if has_valid_target(first_response) or has_valid_target(second_response):
            return "ì„±ê³µ"
        
        first_no_info = not first_response or not has_valid_target(first_response)
        second_no_info = not second_response or not has_valid_target(second_response)
        
        if first_no_info and second_no_info:
            return "completed"
        
        return "ollama"
    
    def _get_best_value_from_responses(self, first_response: Optional[Dict[str, Any]], second_response: Optional[Dict[str, Any]], key: str) -> str:
        """first_responseì™€ second_response ì¤‘ì—ì„œ ìœ íš¨í•œ ê°’ì´ ìˆëŠ” ê²ƒì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        def is_valid_value(value):
            return value and value not in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]
        
        if first_response and key in first_response:
            first_value = first_response.get(key, "")
            if is_valid_value(first_value):
                logger.debug(f"{key} ê°’ì„ first_responseì—ì„œ ì‚¬ìš©: {first_value}")
                return first_value
        
        if second_response and key in second_response:
            second_value = second_response.get(key, "")
            if is_valid_value(second_value):
                logger.debug(f"{key} ê°’ì„ second_responseì—ì„œ ì‚¬ìš©: {second_value}")
                return second_value
        
        return ""
    
    def _format_date_to_standard(self, date_str: str) -> Optional[str]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        import re

        if not date_str or date_str in ["ì •ë³´ ì—†ìŒ", "í•´ë‹¹ì—†ìŒ", ""]:
            return None

        # ë§ˆí¬ë‹¤ìš´ ë³¼ë“œ(**) ë¨¼ì € ì œê±°
        date_str = re.sub(r'\*+', '', date_str).strip()

        clean_date = re.sub(r'[^\d\.\-/]', '', date_str.strip())
        
        if re.match(r'^\d{4}-\d{2}-\d{2}$', clean_date):
            return clean_date
        
        match = re.match(r'^(\d{4})\.(\d{2})\.(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        match = re.match(r'^(\d{4})(\d{2})(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        match = re.match(r'^(\d{4})/(\d{2})/(\d{2})$', clean_date)
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        year_month_day = re.search(r'(\d{4})ë…„?\s*(\d{1,2})ì›”?\s*(\d{1,2})ì¼?', date_str)
        if year_month_day:
            year = year_month_day.group(1)
            month = year_month_day.group(2).zfill(2)
            day = year_month_day.group(3).zfill(2)
            return f"{year}-{month}-{day}"
        
        numbers_only = re.sub(r'[^\d]', '', date_str)
        if len(numbers_only) == 8:
            return f"{numbers_only[:4]}-{numbers_only[4:6]}-{numbers_only[6:8]}"
        
        logger.debug(f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: '{date_str}' -> None")
        return None
    
    # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë©”ì„œë“œë“¤ (ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•´ db_manager íŒŒë¼ë¯¸í„° ì¶”ê°€)
    def _save_processing_result(
        self, 
        folder_name: str, 
        site_code: str, 
        content_md: str, 
        combined_content: str,
        attachment_filenames: List[str] = None,
        status: str = "ollama",
        exclusion_keywords: List[str] = None,
        exclusion_reason: str = None,
        error_message: str = None,
        force: bool = False,
        db_manager=None
    ) -> Optional[int]:
        """ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with db_manager.SessionLocal() as session:
                if force:
                    sql = text("""
                        INSERT INTO announcement_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                        ON DUPLICATE KEY UPDATE
                            content_md = VALUES(content_md),
                            combined_content = VALUES(combined_content),
                            attachment_filenames = VALUES(attachment_filenames),
                            exclusion_keyword = VALUES(exclusion_keyword),
                            exclusion_reason = VALUES(exclusion_reason),
                            processing_status = VALUES(processing_status),
                            error_message = VALUES(error_message),
                            updated_at = NOW()
                    """)
                else:
                    sql = text("""
                        INSERT INTO announcement_processing (
                            folder_name, site_code, content_md, combined_content,
                            attachment_filenames, exclusion_keyword, exclusion_reason, 
                            processing_status, error_message, created_at, updated_at
                        ) VALUES (
                            :folder_name, :site_code, :content_md, :combined_content,
                            :attachment_filenames, :exclusion_keyword, :exclusion_reason, 
                            :processing_status, :error_message, NOW(), NOW()
                        )
                    """)
                
                params = {
                    'folder_name': folder_name,
                    'site_code': site_code,
                    'content_md': content_md,
                    'combined_content': combined_content,
                    'attachment_filenames': ', '.join(attachment_filenames) if attachment_filenames else None,
                    'exclusion_keyword': ', '.join(exclusion_keywords) if exclusion_keywords else None,
                    'exclusion_reason': exclusion_reason,
                    'processing_status': status,
                    'error_message': error_message
                }
                
                result = session.execute(sql, params)
                session.commit()
                
                record_id = result.lastrowid
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                return record_id
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def _update_processing_result_simple(
        self,
        record_id: int,
        status: str = "ì„±ê³µ",
        error_message: str = None,
        db_manager=None
    ) -> bool:
        """ê°„ë‹¨í•œ ìƒíƒœ ì—…ë°ì´íŠ¸ (ì œëª© ê¸°ë°˜ ì²˜ë¦¬ìš©)"""
        try:
            from sqlalchemy import text
            
            with db_manager.SessionLocal() as session:
                sql = text("""
                    UPDATE announcement_processing SET
                        processing_status = :processing_status,
                        error_message = :error_message,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                params = {
                    'record_id': record_id,
                    'processing_status': status,
                    'error_message': error_message
                }
                
                session.execute(sql, params)
                session.commit()
                
                logger.info(f"ê°„ë‹¨í•œ ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                return True
                
        except Exception as e:
            logger.error(f"ê°„ë‹¨í•œ ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _update_processing_result(
        self,
        record_id: int,
        ollama_response: Optional[Dict[str, Any]],
        ollama_prompt: str,
        first_response: Optional[Dict[str, Any]] = None,
        status: str = "ollama",
        db_manager=None
    ) -> bool:
        """ê¸°ì¡´ ë ˆì½”ë“œì— Ollama ë¶„ì„ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            from sqlalchemy import text
            
            with db_manager.SessionLocal() as session:
                extracted_data = {}
                if ollama_response:
                    extracted_url = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_URL")
                    extracted_announcement_date = self._get_best_value_from_responses(first_response, ollama_response, "EXTRACTED_ANNOUNCEMENT_DATE")
                    
                    extracted_data = {
                        'extracted_title': ollama_response.get("EXTRACTED_TITLE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_target': ollama_response.get("EXTRACTED_TARGET", "ì •ë³´ ì—†ìŒ"),
                        'extracted_target_type': ollama_response.get("EXTRACTED_TARGET_TYPE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_amount': ollama_response.get("EXTRACTED_AMOUNT", "ì •ë³´ ì—†ìŒ"),
                        'extracted_period': ollama_response.get("EXTRACTED_PERIOD", "ì •ë³´ ì—†ìŒ"),
                        'extracted_schedule': ollama_response.get("EXTRACTED_SCHEDULE", "ì •ë³´ ì—†ìŒ"),
                        'extracted_content': ollama_response.get("EXTRACTED_CONTENT", "ì •ë³´ ì—†ìŒ"),
                        'extracted_announcement_date': extracted_announcement_date,
                        'original_url': extracted_url,
                        'formatted_announcement_date': self._format_date_to_standard(extracted_announcement_date)
                    }
                
                sql = text("""
                    UPDATE announcement_processing SET
                        ollama_first_response = :ollama_first_response,
                        ollama_response = :ollama_response,
                        ollama_prompt = :ollama_prompt,
                        extracted_title = :extracted_title,
                        extracted_target = :extracted_target,
                        extracted_target_type = :extracted_target_type,
                        extracted_amount = :extracted_amount,
                        extracted_period = :extracted_period,
                        extracted_schedule = :extracted_schedule,
                        extracted_content = :extracted_content,
                        extracted_announcement_date = :extracted_announcement_date,
                        original_url = :original_url,
                        formatted_announcement_date = :formatted_announcement_date,
                        processing_status = :processing_status,
                        updated_at = NOW()
                    WHERE id = :record_id
                """)
                
                params = {
                    'record_id': record_id,
                    'ollama_first_response': json.dumps(first_response, ensure_ascii=False) if first_response else None,
                    'ollama_response': json.dumps(ollama_response, ensure_ascii=False) if ollama_response else None,
                    'ollama_prompt': ollama_prompt,
                    'processing_status': status,
                    **extracted_data
                }
                
                session.execute(sql, params)
                session.commit()
                
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ID {record_id}, ìƒíƒœ: {status}")
                
                if ollama_response:
                    self._display_ollama_results(ollama_response)
                
                return True
                
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _display_ollama_results(self, ollama_response: Dict[str, Any]):
        """Ollama ë¶„ì„ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."""
        print("  ğŸ¤– Ollama ë¶„ì„ ê²°ê³¼:")
        if "EXTRACTED_TARGET" in ollama_response and ollama_response["EXTRACTED_TARGET"]:
            print(f"     ğŸ“Œ ì§€ì›ëŒ€ìƒ: {ollama_response['EXTRACTED_TARGET'][:100]}...")
        if "EXTRACTED_TARGET_TYPE" in ollama_response and ollama_response["EXTRACTED_TARGET_TYPE"]:
            print(f"     ğŸ·ï¸ ì§€ì›ëŒ€ìƒë¶„ë¥˜: {ollama_response['EXTRACTED_TARGET_TYPE'][:50]}...")
        if "EXTRACTED_AMOUNT" in ollama_response and ollama_response["EXTRACTED_AMOUNT"]:
            print(f"     ğŸ’° ì§€ì›ê¸ˆì•¡: {ollama_response['EXTRACTED_AMOUNT'][:100]}...")
        if "EXTRACTED_TITLE" in ollama_response and ollama_response["EXTRACTED_TITLE"]:
            print(f"     ğŸ“ ì œëª©: {ollama_response['EXTRACTED_TITLE'][:100]}...")
        if "EXTRACTED_ANNOUNCEMENT_DATE" in ollama_response and ollama_response["EXTRACTED_ANNOUNCEMENT_DATE"]:
            print(f"     ğŸ“… ë“±ë¡ì¼: {ollama_response['EXTRACTED_ANNOUNCEMENT_DATE'][:50]}...")


def get_directory_and_site_code(args) -> Tuple[Path, str]:
    """ëª…ë ¹í–‰ ì¸ì ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ë””ë ‰í† ë¦¬ì™€ ì‚¬ì´íŠ¸ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    if args.data:
        directory_name = args.data
    else:
        directory_name = os.getenv("DEFAULT_DIR", "data")
    
    if not args.site_code:
        logger.error("ì‚¬ì´íŠ¸ ì½”ë“œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    site_code = args.site_code
    
    current_dir = Path.cwd()
    base_directory = current_dir / directory_name
    
    if not base_directory.exists():
        logger.error(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_directory}")
        sys.exit(1)
    
    logger.info(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬: {base_directory}")
    logger.info(f"ì‚¬ì´íŠ¸ ì½”ë“œ: {site_code}")
    
    return base_directory, site_code


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ê³µê³  ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ë° ë¶„ì„ í”„ë¡œê·¸ë¨ - ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python announcement_processor_parallel.py --site-code acci --data data.enhanced
  python announcement_processor_parallel.py --site-code cbt --data data.origin --workers 4
  python announcement_processor_parallel.py --site-code acci  # í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ì‚¬ìš©
  python announcement_processor_parallel.py --site-code acci --data data.enhanced -r  # ì¬ê·€ì  ì²˜ë¦¬
  python announcement_processor_parallel.py --site-code acci --attach-force  # ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬
        """
    )
    
    parser.add_argument(
        "--data", 
        type=str,
        help="ë°ì´í„° ë””ë ‰í† ë¦¬ëª… (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ DEFAULT_DIR ë˜ëŠ” 'data')"
    )
    
    parser.add_argument(
        "--site-code", 
        type=str,
        required=True,
        help="ì‚¬ì´íŠ¸ ì½”ë“œ (í•„ìˆ˜, ì˜ˆ: acci, cbt, andongcci ë“±)"
    )
    
    parser.add_argument(
        "--workers", 
        type=int,
        default=2,
        help="ë³‘ë ¬ ì²˜ë¦¬ì— ì‚¬ìš©í•  ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 2, ê¶Œì¥: 2)"
    )
    
    parser.add_argument(
        "--skip-processed", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© ê±´ë„ˆë›°ê¸° (ê¸°ë³¸ ë™ì‘)"
    )
    
    parser.add_argument(
        "--force", 
        action="store_true", 
        help="ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë„ ë‹¤ì‹œ ì²˜ë¦¬"
    )
    
    parser.add_argument(
        "-r", "--recursive",
        action="store_true",
        help="í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ëª¨ë“  í•˜ìœ„ ê²½ë¡œì˜ content.mdë‚˜ attachmentsë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬)"
    )
    
    parser.add_argument(
        "--attach-force",
        action="store_true",
        help="ì²¨ë¶€íŒŒì¼ ê°•ì œ ì¬ì²˜ë¦¬ (ê¸°ì¡´ .md íŒŒì¼ ë¬´ì‹œí•˜ê³  ì›ë³¸ íŒŒì¼ì—ì„œ ë‹¤ì‹œ ë³€í™˜)"
    )
    
    args = parser.parse_args()
    
    try:
        # ë””ë ‰í† ë¦¬ì™€ ì‚¬ì´íŠ¸ì½”ë“œ ê²°ì •
        base_directory, site_code = get_directory_and_site_code(args)
        
        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        logger.info(f"ë³‘ë ¬ ê³µê³  ì²˜ë¦¬ í”„ë¡œê·¸ë¨ ì‹œì‘ (ì›Œì»¤ ìˆ˜: {args.workers})")
        processor = ParallelAnnouncementProcessor(
            attach_force=args.attach_force,
            max_workers=args.workers
        )
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        results = processor.process_site_directories_parallel(
            base_directory, site_code, args.recursive, args.force, args.attach_force
        )
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print(f"\n=== ìµœì¢… ìš”ì•½ ===")
        print(f"ì›Œì»¤ ìˆ˜: {args.workers}ê°œ")
        print(f"ì‚¬ì´íŠ¸ ì½”ë“œ: {site_code}")
        print(f"ì „ì²´ ëŒ€ìƒ: {results['total']}ê°œ")
        print(f"ì²˜ë¦¬ ì„±ê³µ: {results['success']}ê°œ") 
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {results['failed']}ê°œ")
        print(f"ê±´ë„ˆë›´ í•­ëª©: {results['skipped']}ê°œ")
        
        if results['failed'] > 0:
            print(f"\nì‹¤íŒ¨í•œ í•­ëª©ì´ {results['failed']}ê°œ ìˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
        else:
            print("\nğŸ‰ ëª¨ë“  ë³‘ë ¬ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            sys.exit(0)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()