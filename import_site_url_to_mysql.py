#!/usr/bin/env python3
import mysql.connector
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def connect_db():
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    try:
        conn = mysql.connector.connect(
            host=os.getenv('DB_HOST', '192.168.0.95'),
            port=int(os.getenv('DB_PORT', '3309')),
            user=os.getenv('DB_USER', 'root'),
            password=os.getenv('DB_PASSWORD'),
            database=os.getenv('DB_NAME', 'subvention')
        )
        print(f"âœ… MySQL ì—°ê²° ì„±ê³µ: {os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}")
        return conn
    except Exception as e:
        print(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def create_table(conn):
    """scraper_site_url í…Œì´ë¸” ìƒì„±"""
    try:
        cursor = conn.cursor()

        # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ì˜µì…˜)
        drop_table_query = "DROP TABLE IF EXISTS scraper_site_url"
        cursor.execute(drop_table_query)
        print("âœ… ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ (ì¡´ì¬í–ˆë‹¤ë©´)")

        # í…Œì´ë¸” ìƒì„±
        create_table_query = """
        CREATE TABLE scraper_site_url (
            id INT AUTO_INCREMENT PRIMARY KEY,
            site_code VARCHAR(100) NOT NULL,
            site_url VARCHAR(1000),
            scraper_path VARCHAR(500),
            scraper_name VARCHAR(200),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            INDEX idx_site_code (site_code),
            INDEX idx_scraper_name (scraper_name)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ìŠ¤í¬ë˜í¼ ì‚¬ì´íŠ¸ URL ì •ë³´'
        """

        cursor.execute(create_table_query)
        print("âœ… scraper_site_url í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

        cursor.close()
        conn.commit()
        return True
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def parse_site_url_file(file_path):
    """site_url.txt íŒŒì¼ íŒŒì‹±"""
    records = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f, 1):
                line = line.strip()

                # í—¤ë”ë‚˜ êµ¬ë¶„ì„  ê±´ë„ˆë›°ê¸°
                if i <= 2 or not line or line.startswith('-'):
                    continue

                site_code = None
                site_url = None
                scraper_path = None
                scraper_name = None

                # ë¨¼ì € íƒ­ìœ¼ë¡œ êµ¬ë¶„ ì‹œë„ (zium_scraper ë°ì´í„°)
                if '\t' in line:
                    parts = line.split('\t')
                    if len(parts) >= 4:
                        site_code = parts[0].strip()
                        site_url = parts[1].strip()
                        scraper_path = parts[2].strip()
                        scraper_name = parts[3].strip()
                # íŒŒì´í”„(|)ë¡œ êµ¬ë¶„ (ê¸°ë³¸ ìŠ¤í¬ë˜í¼ ë°ì´í„°)
                elif '|' in line:
                    parts = line.split('|')
                    if len(parts) >= 4:
                        site_code = parts[0].strip()
                        site_url = parts[1].strip()
                        scraper_path = parts[2].strip()
                        scraper_name = parts[3].strip()

                # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ê°€
                if site_code and site_url:
                    records.append({
                        'site_code': site_code,
                        'site_url': site_url,
                        'scraper_path': scraper_path if scraper_path else '',
                        'scraper_name': scraper_name if scraper_name else ''
                    })

        print(f"âœ… {len(records)}ê°œ ë ˆì½”ë“œ íŒŒì‹± ì™„ë£Œ")
        return records
    except Exception as e:
        print(f"âŒ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []

def insert_data(conn, records):
    """ë°ì´í„° ì‚½ì…"""
    try:
        cursor = conn.cursor()

        insert_query = """
        INSERT INTO scraper_site_url (site_code, site_url, scraper_path, scraper_name)
        VALUES (%s, %s, %s, %s)
        """

        # ë°°ì¹˜ ì‚½ì…
        inserted_count = 0
        failed_count = 0

        for record in records:
            try:
                cursor.execute(insert_query, (
                    record['site_code'],
                    record['site_url'],
                    record['scraper_path'],
                    record['scraper_name']
                ))
                inserted_count += 1
            except Exception as e:
                failed_count += 1
                print(f"âš ï¸  ì‚½ì… ì‹¤íŒ¨ ({record['site_code']}): {e}")

        conn.commit()
        cursor.close()

        print(f"âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ: {inserted_count}ê°œ ì„±ê³µ, {failed_count}ê°œ ì‹¤íŒ¨")
        return inserted_count
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì‚½ì… ì‹¤íŒ¨: {e}")
        return 0

def verify_data(conn):
    """ë°ì´í„° ê²€ì¦"""
    try:
        cursor = conn.cursor(dictionary=True)

        # ì´ ë ˆì½”ë“œ ìˆ˜
        cursor.execute("SELECT COUNT(*) as total FROM scraper_site_url")
        result = cursor.fetchone()
        total_count = result['total']

        print(f"\nâœ… ì´ {total_count}ê°œ ë ˆì½”ë“œê°€ í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
        cursor.execute("SELECT * FROM scraper_site_url LIMIT 5")
        sample_data = cursor.fetchall()

        print("\nğŸ“Š ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 5ê°œ):")
        for row in sample_data:
            print(f"  - {row['site_code']}: {row['site_url'][:80]}...")

        cursor.close()
        return True
    except Exception as e:
        print(f"âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

def main():
    print("="*80)
    print("site_url.txt ë°ì´í„°ë¥¼ MySQLë¡œ ê°€ì ¸ì˜¤ê¸°")
    print("="*80 + "\n")

    # 1. DB ì—°ê²°
    conn = connect_db()
    if not conn:
        return

    # 2. í…Œì´ë¸” ìƒì„±
    if not create_table(conn):
        conn.close()
        return

    # 3. íŒŒì¼ íŒŒì‹±
    file_path = '/Users/jin/classfy_scraper/site_url.txt'
    records = parse_site_url_file(file_path)

    if not records:
        print("âŒ íŒŒì‹±ëœ ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        conn.close()
        return

    # 4. ë°ì´í„° ì‚½ì…
    inserted_count = insert_data(conn, records)

    if inserted_count > 0:
        # 5. ë°ì´í„° ê²€ì¦
        verify_data(conn)

    # 6. ì—°ê²° ì¢…ë£Œ
    conn.close()
    print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    main()
